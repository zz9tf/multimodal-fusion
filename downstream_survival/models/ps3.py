import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from .clam_mlp import ClamMLP
from typing import Dict, List, Tuple

class PS3(ClamMLP):
    """
    PS3æ¨¡å‹ï¼Œä½¿ç”¨ Cross Attention æœºåˆ¶è¿›è¡Œå¤šæ¨¡æ€èåˆ
    
    é…ç½®å‚æ•°ï¼š
    - n_classes: ç±»åˆ«æ•°é‡
    - input_dim: è¾“å…¥ç»´åº¦
    - model_size: æ¨¡å‹å¤§å° ('small', 'big', '128*64', '64*32', '32*16', '16*8', '8*4', '4*2', '2*1')
    - dropout: dropoutç‡
    - gate: æ˜¯å¦ä½¿ç”¨é—¨æ§æ³¨æ„åŠ›
    - inst_number: æ­£è´Ÿæ ·æœ¬é‡‡æ ·æ•°é‡
    - instance_loss_fn: å®ä¾‹æŸå¤±å‡½æ•°
    - subtyping: æ˜¯å¦ä¸ºå­ç±»å‹é—®é¢˜
    - cross_attn_dim: Cross Attention çš„ç»´åº¦ï¼Œé»˜è®¤ä¸º output_dim
    - num_heads: æ³¨æ„åŠ›å¤´æ•°ï¼ˆå½“å‰å®ç°ä¸ºå•å¤´ï¼Œä¿ç•™ç”¨äºæœªæ¥æ‰©å±•ï¼‰
    - cross_attn_dropout: Cross Attention çš„ dropout ç‡ï¼Œé»˜è®¤ 0.1
    """
    
    def __init__(self, config):
        """
        åˆå§‹åŒ– PS3 æ¨¡å‹ï¼Œè®¾ç½® Cross Attention ç›¸å…³å‚æ•°
        
        @param {Dict} config - æ¨¡å‹é…ç½®å­—å…¸ï¼ŒåŒ…å«æ¨¡å‹æ‰€éœ€çš„æ‰€æœ‰å‚æ•°
        """
        super().__init__(config)
        self.modality_order = sorted(self.modalities_used_in_model)
        self.token_norm = nn.LayerNorm(self.output_dim).to(self.device)  # Token normalization
        self.qkv_proj = nn.Linear(self.output_dim, 3 * self.output_dim).to(self.device)
        self.modality_mlp_layers = nn.ModuleDict(
            {
                channel: nn.Linear(self.output_dim, self.output_dim) 
                for channel in self.modality_order
            }
        ).to(self.device)
        
        self.modality_fusion_layer = nn.Sequential(
                nn.Linear(len(self.modality_order) * self.output_dim, self.size[1]),
                nn.ReLU(),
                nn.Dropout(self.dropout),
                nn.Linear(self.size[1], self.n_classes)
        ).to(self.device)
        
    
    def forward(self, input_data, label):
        """
        ç»Ÿä¸€çš„å‰å‘ä¼ æ’­æ¥å£ï¼Œä½¿ç”¨ Cross Attention è¿›è¡Œå¤šæ¨¡æ€ç‰¹å¾èåˆ
        
        æµç¨‹ï¼š
        1. æå–å„æ¨¡æ€ç‰¹å¾ï¼ˆWSI/TMA ä½¿ç”¨ CLAMï¼Œå…¶ä»–æ¨¡æ€ä½¿ç”¨ transfer layerï¼‰
        2. ä¸ºæ¯ä¸ªæ¨¡æ€ç”Ÿæˆ Q, K, V æŠ•å½±
        3. å¯¹æ¯ä¸ªæ¨¡æ€ï¼Œä½¿ç”¨å…¶ Q æŸ¥è¯¢æ‰€æœ‰æ¨¡æ€çš„ Kï¼Œè®¡ç®—æ³¨æ„åŠ›æƒé‡
        4. ä½¿ç”¨æ³¨æ„åŠ›æƒé‡å¯¹æ‰€æœ‰æ¨¡æ€çš„ V è¿›è¡ŒåŠ æƒæ±‚å’Œ
        5. æ‹¼æ¥æ‰€æœ‰èåˆåçš„ç‰¹å¾ï¼Œé€šè¿‡ fusion_prediction è¿›è¡Œåˆ†ç±»
        
        @param {torch.Tensor|Dict[str, torch.Tensor]} input_data - è¾“å…¥æ•°æ®
            - torch.Tensor: å•æ¨¡æ€ç‰¹å¾ [N, D]
            - Dict[str, torch.Tensor]: å¤šæ¨¡æ€æ•°æ®å­—å…¸ï¼Œkey ä¸ºæ¨¡æ€åç§°
        @param {torch.Tensor} label - æ ‡ç­¾å¼ é‡ï¼Œç”¨äºå®ä¾‹è¯„ä¼° [1]
                
        @returns {Dict[str, Any]} ç»Ÿä¸€æ ¼å¼çš„ç»“æœå­—å…¸ï¼ŒåŒ…å«ï¼š
            - Y_prob: é¢„æµ‹æ¦‚ç‡ [1, n_classes]
            - Y_hat: é¢„æµ‹ç±»åˆ« [1, 1]
            - å„æ¨¡æ€çš„ CLAM ç›¸å…³ç»“æœï¼ˆå¦‚æœé€‚ç”¨ï¼‰
        """
        input_data, modalities_used_in_model = self._process_input_data(input_data)
        # åˆå§‹åŒ–ç»“æœå­—å…¸
        result_kwargs = {}
        
        # æ”¶é›†æ‰€æœ‰æ¨¡æ€çš„ç‰¹å¾
        modality_features = {}
        for channel in modalities_used_in_model:
            features = None
            if channel == 'wsi=features':
                clam_result_kwargs = self._clam_forward(channel, input_data[channel], label)
                modality_features[channel] = clam_result_kwargs['features'].detach()
                for key, value in clam_result_kwargs.items():
                    result_kwargs[f'{channel}_{key}'] = value
            elif channel == 'tma=features':
                clam_result_kwargs = self._clam_forward(channel, input_data[channel], label)
                modality_features[channel] = clam_result_kwargs['features'].detach()
                for key, value in clam_result_kwargs.items():
                    result_kwargs[f'{channel}_{key}'] = value
            else:
                if channel not in self.transfer_layer:
                    self.transfer_layer[channel] = self.create_transfer_layer(input_data[channel].shape[1])
                modality_features[channel] = self.transfer_layer[channel](input_data[channel])
        
        # æ”¶é›†æ‰€æœ‰æ¨¡æ€ç‰¹å¾å¹¶æ‹¼æ¥: [num_modalities, output_dim]
        # æ¯ä¸ª modality_features[channel] æ˜¯ [1, output_dim]ï¼Œä½¿ç”¨ cat åœ¨ dim=0 ä¸Šæ‹¼æ¥
        h = torch.cat([modality_features[channel] for channel in self.modality_order], dim=0)  # [num_modalities, output_dim]
        # ğŸ”¹ Step 1: Token Normalization (å¯¹æ¯ä¸ªæ¨¡æ€çš„ token è¿›è¡Œ normalization)
        h = self.token_norm(h)  # [num_modalities, output_dim]
        
        # ğŸ”¹ Step 2: QKV Projection (å¹¶è¡Œè®¡ç®—æ‰€æœ‰æ¨¡æ€çš„ Q, K, V)
        qkv_h = self.qkv_proj(h)  # [num_modalities, 3 * output_dim]
        # ğŸ”¹ Step 3: Split Q, K, V
        q, k, v = qkv_h.chunk(3, dim=-1)  # æ¯ä¸ªéƒ½æ˜¯ [num_modalities, output_dim]
        
        # ğŸ”¹ Step 4: Cross Attention è®¡ç®—
        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°: Q @ K^T / sqrt(d_k)
        # q: [num_modalities, output_dim], k: [num_modalities, output_dim]
        # è¾“å‡º: [num_modalities, num_modalities] (æ¯ä¸ªæ¨¡æ€å¯¹æ‰€æœ‰æ¨¡æ€çš„æ³¨æ„åŠ›åˆ†æ•°)
        attn_scores = torch.mm(q, k.transpose(0, 1)) / np.sqrt(self.output_dim)  # [num_modalities, num_modalities]
        
        # åº”ç”¨ softmax å¾—åˆ°æ³¨æ„åŠ›æƒé‡
        attention_weights = F.softmax(attn_scores, dim=-1)  # [num_modalities, num_modalities]
        
        # ä½¿ç”¨æ³¨æ„åŠ›æƒé‡å¯¹ V è¿›è¡ŒåŠ æƒæ±‚å’Œ
        # attention_weights: [num_modalities, num_modalities]
        # v: [num_modalities, output_dim]
        # è¾“å‡º: [num_modalities, output_dim] (æ¯ä¸ªæ¨¡æ€çš„èåˆåç‰¹å¾)
        h = torch.mm(attention_weights, v)  # [num_modalities, output_dim]
        
        # ğŸ”¹ Step 4.5: å¯¹æ¯ä¸ªæ¨¡æ€åº”ç”¨ç‹¬ç«‹çš„ MLP å’Œ normalization
        # ä¼˜åŒ–æ–¹æ¡ˆï¼šå…ˆåº”ç”¨æ‰€æœ‰ MLPï¼Œç„¶åä¸€æ¬¡æ€§åº”ç”¨ normalizationï¼ˆé«˜æ•ˆä¸”ç®€æ´ï¼‰
        # ç”±äºæ¯ä¸ªæ¨¡æ€çš„ MLP ä¸åŒï¼Œæ— æ³•å®Œå…¨å¹¶è¡ŒåŒ–ï¼Œä½† normalization å¯ä»¥æ‰¹é‡å¤„ç†
        # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ + cat æ¯”å¾ªç¯ + stack æ›´é«˜æ•ˆï¼ˆå‡å°‘ squeeze æ“ä½œï¼‰
        h_mlp_list = [
            self.modality_mlp_layers[channel](h[index:index+1, :])  # [1, output_dim]
            for index, channel in enumerate(self.modality_order)
        ]
        h_mlp = torch.cat(h_mlp_list, dim=0)  # [num_modalities, output_dim]
        # ä¸€æ¬¡æ€§å¯¹æ‰€æœ‰æ¨¡æ€åº”ç”¨ normalizationï¼ˆæ›´é«˜æ•ˆï¼Œä» num_modalities æ¬¡è°ƒç”¨å‡å°‘åˆ° 1 æ¬¡ï¼‰
        h = self.token_norm(h_mlp)  # [num_modalities, output_dim]
        
        # ğŸ”¹ Step 5: Flatten å¹¶æ‹¼æ¥æ‰€æœ‰æ¨¡æ€çš„èåˆç‰¹å¾
        h = h.view(1, -1)  # [1, num_modalities * output_dim]
        
        # ğŸ”¹ Step 6: é€šè¿‡èåˆé¢„æµ‹å±‚è¿›è¡Œåˆ†ç±»
        logits = self.modality_fusion_layer(h)  # [1, n_classes]
        Y_prob = F.softmax(logits, dim=1)
        Y_hat = torch.topk(logits, 1, dim=1)[1]
        
        # æ›´æ–°ç»“æœå­—å…¸
        result_kwargs['Y_prob'] = Y_prob
        result_kwargs['Y_hat'] = Y_hat
        
        return self._create_result_dict(logits, Y_prob, Y_hat, **result_kwargs)