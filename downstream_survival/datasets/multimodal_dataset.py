"""
çµæ´»çš„å¤šæ¨¡æ€æ•°æ®é›†ç±»
æ”¯æŒæŒ‰éœ€åŠ è½½channelsï¼ŒæŒ‰éœ€å¯¹é½ï¼Œè¿”å›å­—å…¸æ ¼å¼
"""
import os
import torch
import numpy as np
import pandas as pd
import h5py
import sys
import time
import random
import threading
from typing import Dict, List, Optional, Tuple
from torch.utils.data import Dataset
from typing import List, Dict, Optional, Union, Tuple

# æ·»åŠ multimodal-fusioné¡¹ç›®è·¯å¾„
sys.path.append('/home/zheng/zheng/multimodal-fusion/alignment')
try:
    from alignment_model import MultiModalAlignmentModel
    ALIGNMENT_AVAILABLE = True
except ImportError:
    ALIGNMENT_AVAILABLE = False
    print("âš ï¸ å¯¹é½æ¨¡å‹ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ ‡å‡†æ¨¡å¼")

# å…¨å±€æ–‡ä»¶é”å­—å…¸ï¼Œç”¨äºå¤„ç†HDF5å¹¶å‘è®¿é—®
_file_locks = {}
_lock_dict_lock = threading.Lock()

class MultimodalDataset(Dataset):
    """
    çµæ´»çš„å¤šæ¨¡æ€æ•°æ®é›†ç±»
    æ”¯æŒæŒ‰éœ€åŠ è½½channelsï¼ŒæŒ‰éœ€å¯¹é½ï¼Œè¿”å›å­—å…¸æ ¼å¼
    """
    
    def __init__(self,
                 csv_path: str,
                 data_root_dir: str,
                 channels: List[str] = None,
                 align_channels: Dict[str, str] = None,
                 alignment_model_path: Optional[str] = None,
                 device: str = 'auto',
                 print_info: bool = True):
        """
        åˆå§‹åŒ–çµæ´»çš„å¤šæ¨¡æ€æ•°æ®é›†
        
        Args:
            csv_path: åŒ…å« patient_id, case_id, label, h5_file_path çš„ CSV æ–‡ä»¶
            data_root_dir: æ•°æ®æ ¹ç›®å½•ï¼Œç”¨äºæ‹¼æ¥ç›¸å¯¹è·¯å¾„
            channels: éœ€è¦åŠ è½½çš„channelåˆ—è¡¨ï¼Œå¦‚ ['features', 'tma_CD3', 'tma_CD8', ...]
            align_channels: éœ€è¦å¯¹é½çš„channelæ˜ å°„ï¼Œå¦‚ {"tma_CD3": "CD3", "tma_CD8": "CD8"}
            alignment_model_path: å¯¹é½æ¨¡å‹è·¯å¾„
            device: è®¾å¤‡é€‰æ‹©ï¼Œ'auto'è‡ªåŠ¨é€‰æ‹©ï¼Œ'cpu'å¼ºåˆ¶CPUï¼Œ'cuda'å¼ºåˆ¶GPU
            print_info: æ˜¯å¦æ‰“å°ä¿¡æ¯
        """
        super().__init__()
        
        # åŸºæœ¬è®¾ç½®
        self.data_root_dir = data_root_dir
        self.channels = channels
        self.align_channels = align_channels or {}  # é»˜è®¤ä¸å¯¹é½
        self.print_info = print_info
        
        # è®¾å¤‡é€‰æ‹©
        if device == 'auto':
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            self.device = device
        
        # åŠ è½½CSVæ•°æ®
        self.data_df = pd.read_csv(csv_path)
        
        # éªŒè¯CSVæ–‡ä»¶ç»“æ„
        required_columns = ['patient_id', 'case_id', 'label', 'h5_file_path']
        missing_columns = [col for col in required_columns if col not in self.data_df.columns]
        if missing_columns:
            raise ValueError(f"CSVæ–‡ä»¶ç¼ºå°‘å¿…éœ€åˆ—: {missing_columns}")
        
        # åˆ›å»ºæ˜ å°„
        self.case_to_file = {}
        self.case_to_label = {}
        for _, row in self.data_df.iterrows():
            case_id = row['case_id']
            file_path = row['h5_file_path']
            label = row['label']
            
            # å¤„ç†è·¯å¾„ï¼šå¦‚æœæä¾›äº† data_root_dirï¼Œåˆ™æ‹¼æ¥è·¯å¾„
            file_path = os.path.join(self.data_root_dir, file_path)
            
            self.case_to_file[case_id] = file_path
            self.case_to_label[case_id] = label
        
        # è·å–æ‰€æœ‰case_idåˆ—è¡¨
        self.case_ids = list(self.case_to_file.keys())
        
        # å¯¹é½æ¨¡å‹è®¾ç½®
        self.alignment_model = None
        if alignment_model_path and os.path.exists(alignment_model_path) and ALIGNMENT_AVAILABLE:
            self._load_alignment_model(alignment_model_path)
            if print_info:
                print(f"âœ… æ•°æ®é›†åŠ è½½å¯¹é½æ¨¡å‹: {alignment_model_path}")
        
        # éªŒè¯channelså’Œalign_channels
        self._validate_channels()
        
        # è¿‡æ»¤ç¼ºå¤±æ•°æ®
        self._filter_missing_data()
        
        # å»ºç«‹æ ‡ç­¾æ˜ å°„å­—å…¸
        self._build_label_mapping()
        
        if print_info:
            self._print_summary()
    
    def _build_label_mapping(self):
        """å»ºç«‹æ ‡ç­¾åˆ°æ•°å­—çš„æ˜ å°„å­—å…¸"""
        # è·å–æ‰€æœ‰å”¯ä¸€çš„æ ‡ç­¾
        unique_labels = set(self.case_to_label.values())
        
        # åˆ›å»ºæ ‡ç­¾åˆ°æ•°å­—çš„æ˜ å°„ï¼ˆæŒ‰å­—æ¯é¡ºåºæ’åºç¡®ä¿ä¸€è‡´æ€§ï¼‰
        self.label_to_int = {label: idx for idx, label in enumerate(sorted(unique_labels))}
        self.int_to_label = {idx: label for label, idx in self.label_to_int.items()}
        
        if self.print_info:
            print(f"ğŸ·ï¸ æ ‡ç­¾æ˜ å°„: {self.label_to_int}")
    
    def _validate_channels(self):
        """éªŒè¯channelså’Œalign_channelsçš„åˆç†æ€§"""
        if not self.channels:
            raise ValueError("channelsä¸èƒ½ä¸ºç©º")
        
        # æ£€æŸ¥align_channelsçš„keysæ˜¯å¦éƒ½åœ¨channelsä¸­
        if self.align_channels:
            missing_align = [ch for ch in self.align_channels.keys() if ch not in self.channels]
            if missing_align:
                raise ValueError(f"align_channelsä¸­çš„channelsä¸åœ¨channelsä¸­: {missing_align}")
        
        if self.print_info:
            print(f"ğŸ“‹ Channelsé…ç½®:")
            print(f"  åŠ è½½channels: {self.channels}")
            print(f"  å¯¹é½channels: {self.align_channels}")
    
    def _load_alignment_model(self, alignment_model_path: str):
        """åŠ è½½é¢„è®­ç»ƒçš„å¯¹é½æ¨¡å‹"""
        # ä½¿ç”¨æŒ‡å®šçš„è®¾å¤‡
        checkpoint = torch.load(alignment_model_path, map_location=self.device)
        state_dict = checkpoint['model_state_dict'] if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint else checkpoint

        # æ¨æ–­æ¨¡æ€åç§°
        ckpt_modalities = []
        if isinstance(state_dict, dict):
            for k in state_dict.keys():
                if isinstance(k, str) and k.startswith('alignment_layers.'):
                    parts = k.split('.')
                    if len(parts) >= 3:
                        ckpt_modalities.append(parts[1])
            # å»é‡ä¿æŒé¡ºåº
            seen = set()
            ckpt_modalities = [m for m in ckpt_modalities if not (m in seen or seen.add(m))]

        # ä½¿ç”¨align_channelsçš„valuesä½œä¸ºæ¨¡å‹æ¨¡æ€ï¼Œå¦‚æœä¸ºç©ºåˆ™ä½¿ç”¨ckpt_modalities
        if self.align_channels:
            model_modalities = list(self.align_channels.values())
        else:
            model_modalities = ckpt_modalities if ckpt_modalities else []
        
        self.alignment_modalities = model_modalities
        
        if model_modalities:
            self.alignment_model = MultiModalAlignmentModel(
                modality_names=model_modalities,
                feature_dim=1024,
                num_layers=2
            )

            # åªåŠ è½½åŒ¹é…çš„æƒé‡
            filtered_state_dict = {}
            for key, value in state_dict.items():
                # è·³è¿‡ mlp_predictorï¼Œå› ä¸ºå®ƒä¾èµ–äºç‰¹å®šçš„æ¨¡æ€æ•°é‡
                if 'mlp_predictor' in key:
                    continue
                
                # æ£€æŸ¥è¿™ä¸ªæƒé‡æ˜¯å¦å±äºæˆ‘ä»¬éœ€è¦çš„æ¨¡æ€
                should_include = True
                for modality in model_modalities:
                    if f'alignment_layers.{modality}.' in key:
                        should_include = True
                        break
                    elif 'alignment_layers.' in key:
                        # å¦‚æœè¿™ä¸ªkeyåŒ…å«å…¶ä»–æ¨¡æ€ï¼Œåˆ™è·³è¿‡
                        ckpt_modality = key.split('.')[1]
                        if ckpt_modality not in model_modalities:
                            should_include = False
                            break
                
                if should_include:
                    filtered_state_dict[key] = value

            missing, unexpected = self.alignment_model.load_state_dict(filtered_state_dict, strict=False)
            self.alignment_model.eval()
            
            if self.print_info:
                print(f"ğŸ¯ å¯¹é½æ¨¡å‹åŠ è½½æˆåŠŸ | modalities={self.alignment_modalities}")
                print(f"   åŠ è½½çš„æƒé‡æ•°é‡: {len(filtered_state_dict)}")
                if missing:
                    print(f"   ç¼ºå¤±çš„æƒé‡: {len(missing)}")
                if unexpected:
                    print(f"   å¤šä½™çš„æƒé‡: {len(unexpected)}")
        else:
            if self.print_info:
                print("âš ï¸ æ²¡æœ‰æŒ‡å®šalign_channelsï¼Œå¯¹é½æ¨¡å‹å°†ä¸ä¼šè¢«ä½¿ç”¨")
            self.alignment_model = None

    def _filter_missing_data(self):
        """è¿‡æ»¤æ‰æ²¡æœ‰æŒ‡å®šchannelsæ•°æ®çš„æ ·æœ¬"""
        if not self.print_info:
            return
            
        print(f"ğŸ” æ£€æŸ¥æ•°æ®å®Œæ•´æ€§ï¼Œchannels: {self.channels}")
        
        valid_cases = []
        missing_count = 0
        
        for case_id in self.case_ids:
            file_path = self.case_to_file[case_id]
            
            if os.path.exists(file_path):
                try:
                    with h5py.File(file_path, 'r') as f:
                        missing_channels = []
                        if self.channels is None:
                            self.channels = list(f.keys())
                        for channel in self.channels:
                            channel_parts = channel.split('=')
                            if len(channel_parts) == 2:
                                if channel_parts[0] not in f or channel_parts[1] not in f[channel_parts[0]]:
                                    missing_channels.append(channel)
                            elif len(channel_parts) == 3:
                                if channel_parts[0] not in f or channel_parts[1] not in f[channel_parts[0]] or channel_parts[2] not in f[channel_parts[0]][channel_parts[1]]:
                                    missing_channels.append(channel)
                            else:
                                assert False, f"âš ï¸ Channel {channel} æ ¼å¼é”™è¯¯"
                        
                        if missing_channels:
                            missing_count += 1
                            if missing_count <= 5:
                                print(f"  âš ï¸  {case_id}: ç¼ºå°‘ {missing_channels}")
                        else:
                            valid_cases.append(case_id)
                except Exception as e:
                    missing_count += 1
                    if missing_count <= 5:
                        print(f"  âŒ {case_id}: è¯»å–å¤±è´¥ - {e}")
            else:
                missing_count += 1
                if missing_count <= 5:
                    print(f"  âŒ {case_id}: æ–‡ä»¶ä¸å­˜åœ¨")
        
        # æ›´æ–°æ•°æ®
        original_count = len(self.case_ids)
        self.case_ids = valid_cases
        
        if self.print_info:
            new_count = len(self.case_ids)
            print(f"ğŸ“Š æ•°æ®è¿‡æ»¤ç»“æœ: {original_count} -> {new_count} ({new_count/original_count*100:.1f}%)")

    def _print_summary(self):
        """æ‰“å°æ•°æ®é›†æ‘˜è¦"""
        print(f"ğŸ“Š æ•°æ®é›†æ‘˜è¦:")
        print(f"  æ€»æ ·æœ¬æ•°: {len(self.case_ids)}")
        print(f"  åŠ è½½channels: {self.channels}")
        print(f"  å¯¹é½channels: {self.align_channels}")
        print(f"  ä½¿ç”¨å¯¹é½: {True if self.alignment_model is not None else False}")
        
        # æ ‡ç­¾ç»Ÿè®¡
        labels = [self.case_to_label[case_id] for case_id in self.case_ids]
        unique_labels, counts = np.unique(labels, return_counts=True)
        for label, count in zip(unique_labels, counts):
            print(f"  {label}: {count}")

    def __len__(self) -> int:
        """è¿”å›æ•°æ®é›†å¤§å°"""
        return len(self.case_ids)

    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """
        è·å–å•ä¸ªæ ·æœ¬ï¼Œè¿”å›å­—å…¸æ ¼å¼
        
        Args:
            idx: æ ·æœ¬ç´¢å¼•
            
        Returns:
            Dict[str, torch.Tensor]: {
                "channel_name": embeddings,
                "aligned_channel_name": embeddings,
                ...
            }
        """
        case_id = self.case_ids[idx]
        file_path = self.case_to_file[case_id]
        
        if not os.path.exists(file_path):
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return self._get_fallback_data()
        
        # è·å–æ–‡ä»¶é”ï¼Œç¡®ä¿åŒä¸€æ–‡ä»¶ä¸ä¼šè¢«å¤šä¸ªçº¿ç¨‹åŒæ—¶è®¿é—®
        file_lock = self._get_file_lock(file_path)
        
        try:
            with file_lock:  # ä½¿ç”¨æ–‡ä»¶é”ä¿æŠ¤HDF5æ–‡ä»¶è®¿é—®
                with h5py.File(file_path, 'r') as hdf5_file:
                    # åŠ è½½æ‰€æœ‰æŒ‡å®šçš„channels
                    channel_data = {}
                    for channel in self.channels:
                        data = self._read_with_retry(hdf5_file, channel, max_retries=3)
                        if data is not None:
                            channel_data[channel] = torch.from_numpy(self._standardize_array(data))
                        else:
                            assert False, f"âš ï¸ Channel {channel} è¯»å–å¤±è´¥"
                
                # å¦‚æœéœ€è¦å¯¹é½ä¸”å¯¹é½æ¨¡å‹å¯ç”¨
                if self.alignment_model is not None and self.align_channels:
                    try:
                        # å‡†å¤‡å¯¹é½æ•°æ®ï¼Œä½¿ç”¨align_channelsçš„æ˜ å°„
                        align_data = {}
                        for channel, modality_name in self.align_channels.items():
                            if channel in channel_data:
                                align_data[modality_name] = channel_data[channel]
                        
                        if align_data:
                            with torch.no_grad():
                                aligned_features = self.alignment_model(align_data)
                            
                            # å°†å¯¹é½åçš„ç‰¹å¾æ·»åŠ åˆ°ç»“æœä¸­
                            for modality_name, aligned_feat in aligned_features.items():
                                if isinstance(aligned_feat, torch.Tensor) and aligned_feat.numel() > 0:
                                    # æ‰¾åˆ°å¯¹åº”çš„åŸå§‹channel
                                    original_channel = None
                                    for ch, mod in self.align_channels.items():
                                        if mod == modality_name:
                                            original_channel = ch
                                            break
                                    
                                    if original_channel:
                                        # æ·»åŠ å¯¹é½åçš„ç‰¹å¾ï¼Œä½¿ç”¨ "aligned_" å‰ç¼€
                                        aligned_key = f"aligned_{original_channel}"
                                        channel_data[aligned_key] = aligned_feat
                            
                            if self.print_info and idx == 0:  # åªåœ¨ç¬¬ä¸€ä¸ªæ ·æœ¬æ—¶æ‰“å°
                                print(f"ğŸ¯ å¯¹é½å®Œæˆï¼Œç”Ÿæˆäº† {len(aligned_features)} ä¸ªå¯¹é½ç‰¹å¾")
                    
                    except Exception as e:
                        if self.print_info:
                            print(f"âš ï¸ å¯¹é½å¤±è´¥: {e}")
                
                # è·å–æ ‡ç­¾å¹¶è½¬æ¢ä¸ºæ•°å­—
                label_str = self.case_to_label[case_id]
                label = torch.tensor(self.label_to_int[label_str], dtype=torch.long)
                return channel_data, label
                
        except Exception as e:
            print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            raise e

    def _standardize_array(self, arr) -> np.ndarray:
        """æ ‡å‡†åŒ–æ•°ç»„ä¸ºäºŒç»´æ ¼å¼"""
        if arr is None:
            return np.zeros((0, 0), dtype=np.float32)
        arr = np.asarray(arr)
        if arr.ndim == 1:
            arr = arr.reshape(1, arr.shape[0])
        elif arr.ndim > 2:
            arr = arr.reshape(arr.shape[0], -1)
        return arr.astype(np.float32, copy=False)
    
    def _read_with_retry(self, hdf5_file, channel: str, max_retries: int = 3) -> np.ndarray:
        """
        å¸¦é‡è¯•æœºåˆ¶çš„æ•°æ®è¯»å–ï¼Œè§£å†³HDF5å¹¶å‘è®¿é—®é—®é¢˜
        
        Args:
            hdf5_file: HDF5æ–‡ä»¶å¯¹è±¡
            channel: æ•°æ®é›†åç§°
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        Returns:
            è¯»å–çš„æ•°æ®æ•°ç»„
        """
        channel = channel.split('=')
        for attempt in range(max_retries + 1):
            try:
                # å°è¯•è¯»å–æ•°æ®
                if len(channel) == 2:
                    # WSI
                    data = hdf5_file[channel[0]][channel[1]][:]
                elif len(channel) == 3:
                    data = hdf5_file[channel[0]][channel[1]][channel[2]][:]
                else:
                    assert False, f"âš ï¸ Channel {channel} æ ¼å¼é”™è¯¯"
                return data
                
            except Exception as e:
                if attempt < max_retries:
                    # è®¡ç®—é€€é¿æ—¶é—´ï¼šæŒ‡æ•°é€€é¿ + éšæœºæŠ–åŠ¨
                    base_delay = 0.1 * (2 ** attempt)  # 0.1s, 0.2s, 0.4s
                    jitter = random.uniform(0, 0.1)  # 0-0.1séšæœºæŠ–åŠ¨
                    delay = base_delay + jitter
                    
                    print(f"âš ï¸ è¯»å– {channel} å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries + 1}): {e}")
                    print(f"ğŸ”„ ç­‰å¾… {delay:.2f}s åé‡è¯•...")
                    time.sleep(delay)
                else:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                    print(f"âŒ è¯»å– {channel} æœ€ç»ˆå¤±è´¥: {e}")
                    raise e
    
    def _get_file_lock(self, file_path: str) -> threading.Lock:
        """
        è·å–æ–‡ä»¶é”ï¼Œç¡®ä¿åŒä¸€æ–‡ä»¶ä¸ä¼šè¢«å¤šä¸ªçº¿ç¨‹åŒæ—¶è®¿é—®
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ–‡ä»¶å¯¹åº”çš„é”å¯¹è±¡
        """
        with _lock_dict_lock:
            if file_path not in _file_locks:
                _file_locks[file_path] = threading.Lock()
            return _file_locks[file_path]

    def get_label(self, idx: int) -> str:
        """è·å–æŒ‡å®šç´¢å¼•çš„æ ‡ç­¾"""
        case_id = self.case_ids[idx]
        return self.case_to_label[case_id]

    def split_by_ids(self, id_groups: Dict[str, List[str]]) -> Dict[str, 'MultimodalDatasetView']:
        """
        æ ¹æ®case_idåˆ—è¡¨åˆ‡åˆ†æ•°æ®é›†
        
        Args:
            id_groups: {'train': [case_id1, ...], 'val': [...], 'test': [...]}
            
        Returns:
            {'train': FlexibleMultimodalDatasetView, 'val': ..., 'test': ...}
        """
        splits = {}
        for split_name, case_ids in id_groups.items():
            splits[split_name] = MultimodalDatasetView(
                parent=self,
                case_ids=case_ids
            )
        return splits


class MultimodalDatasetView(Dataset):
    """
    æ•°æ®é›†å­è§†å›¾
    """
    
    def __init__(self, parent: MultimodalDataset, case_ids: List[str]):
        """
        åˆå§‹åŒ–å­è§†å›¾
        
        Args:
            parent: çˆ¶æ•°æ®é›†
            case_ids: å­é›†çš„case_idåˆ—è¡¨
        """
        self.parent = parent
        # è¿‡æ»¤å‡ºå­˜åœ¨çš„case_id
        self.case_ids = [case_id for case_id in case_ids if case_id in parent.case_to_file]
        
        # ç»§æ‰¿çˆ¶æ•°æ®é›†çš„å±æ€§
        self.channels = parent.channels
        self.align_channels = parent.align_channels
        self.alignment_model = parent.alignment_model
        self.alignment_modalities = getattr(parent, 'alignment_modalities', [])

    def __len__(self) -> int:
        """è¿”å›å­è§†å›¾å¤§å°"""
        return len(self.case_ids)

    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """è·å–å­è§†å›¾ä¸­çš„æ ·æœ¬"""
        case_id = self.case_ids[idx]
        file_path = self.parent.case_to_file[case_id]
        
        if not os.path.exists(file_path):
            return self.parent._get_fallback_data()
        
        try:
            with h5py.File(file_path, 'r') as hdf5_file:
                # åŠ è½½æ‰€æœ‰æŒ‡å®šçš„channels
                channel_data = {}
                for channel in self.channels:
                    if channel in hdf5_file:
                        data = hdf5_file[channel][:]
                        channel_data[channel] = torch.from_numpy(self.parent._standardize_array(data))
                    else:
                        channel_data[channel] = torch.zeros((0, 0), dtype=torch.float32)
                
                # å¦‚æœéœ€è¦å¯¹é½ä¸”å¯¹é½æ¨¡å‹å¯ç”¨
                if self.alignment_model is not None and self.align_channels:
                    try:
                        # å‡†å¤‡å¯¹é½æ•°æ®ï¼Œä½¿ç”¨align_channelsçš„æ˜ å°„
                        align_data = {}
                        for channel, modality_name in self.align_channels.items():
                            if channel in channel_data:
                                align_data[modality_name] = channel_data[channel]
                        
                        if align_data:
                            with torch.no_grad():
                                aligned_features = self.alignment_model(align_data)
                            
                            # å°†å¯¹é½åçš„ç‰¹å¾æ·»åŠ åˆ°ç»“æœä¸­
                            for modality_name, aligned_feat in aligned_features.items():
                                if isinstance(aligned_feat, torch.Tensor) and aligned_feat.numel() > 0:
                                    # æ‰¾åˆ°å¯¹åº”çš„åŸå§‹channel
                                    original_channel = None
                                    for ch, mod in self.align_channels.items():
                                        if mod == modality_name:
                                            original_channel = ch
                                            break
                                    
                                    if original_channel:
                                        # æ·»åŠ å¯¹é½åçš„ç‰¹å¾ï¼Œä½¿ç”¨ "aligned_" å‰ç¼€
                                        aligned_key = f"aligned_{original_channel}"
                                        channel_data[aligned_key] = aligned_feat
                    
                    except Exception:
                        pass  # å¯¹é½å¤±è´¥æ—¶å¿½ç•¥
                
                return channel_data
                
        except Exception:
            return self.parent._get_fallback_data()

    def get_label(self, idx: int) -> str:
        """è·å–æŒ‡å®šç´¢å¼•çš„æ ‡ç­¾"""
        case_id = self.case_ids[idx]
        return self.parent.case_to_label[case_id]


def create_multimodal_dataset(
    csv_path: str,
    channels: List[str],
    align_channels: Dict[str, str] = None,
    alignment_model_path: Optional[str] = None,
    device: str = 'auto',
    print_info: bool = True
) -> MultimodalDataset:
    """
    åˆ›å»ºçµæ´»å¤šæ¨¡æ€æ•°æ®é›†çš„ä¾¿æ·å‡½æ•°
    
    Args:
        csv_path: CSVæ–‡ä»¶è·¯å¾„
        channels: éœ€è¦åŠ è½½çš„channelåˆ—è¡¨ï¼ˆå¿…éœ€ï¼‰
        align_channels: éœ€è¦å¯¹é½çš„channelæ˜ å°„ï¼Œå¦‚ {"tma_CD3": "CD3", "tma_CD8": "CD8"}
        alignment_model_path: å¯¹é½æ¨¡å‹è·¯å¾„
        print_info: æ˜¯å¦æ‰“å°ä¿¡æ¯
    
    Returns:
        FlexibleMultimodalDatasetå®ä¾‹
    """
    return MultimodalDataset(
        csv_path=csv_path,
        channels=channels,
        align_channels=align_channels,
        alignment_model_path=alignment_model_path,
        device=device,
        print_info=print_info
    )

