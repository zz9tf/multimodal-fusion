#!/bin/bash

# =============================================================================
# Environment Setup
# =============================================================================
source ~/zheng/miniconda3/etc/profile.d/conda.sh
conda activate multimodal-fusion
cd /home/zheng/zheng/multimodal-fusion/downstream_survival

CUDA_DEVICE=1
export CUDA_VISIBLE_DEVICES="$CUDA_DEVICE"

# ğŸ”¬ Dropout å‚æ•°æ¶ˆèç ”ç©¶
# åŸºäºæ ‡å‡†ä»»åŠ¡è¿›è¡Œ dropout å‚æ•°çš„ç³»ç»Ÿæ€§è°ƒæ•´

echo "ğŸš€ å¼€å§‹ Dropout å‚æ•°æ¶ˆèç ”ç©¶..."
echo "â° å¼€å§‹æ—¶é—´: $(date)"
echo "=" * 50

# Data-related parameters
DATA_ROOT_DIR="/home/zheng/zheng/public/hancock_data/WSI_UNI_encodings/WSI_PrimaryTumor"
RESULTS_DIR="/home/zheng/zheng/multimodal-fusion/downstream_survival/results"
CSV_PATH="/home/zheng/zheng/multimodal-fusion/downstream_survival/dataset_csv/survival_dataset.csv"
ALIGNMENT_MODEL_PATH="/home/zheng/zheng/multimodal-fusion/alignment/results/test_svd/test_multimodal_alignment_model.pth"
ALIGNED_CHANNELS="tma_CD3=CD3 tma_CD8=CD8 tma_CD56=CD56 tma_CD68=CD68 tma_CD163=CD163 tma_HE=HE tma_MHC1=MHC1 tma_PDL1=PDL1"
TARGET_CHANNELS="tma_CD3 tma_CD8 tma_CD56 tma_CD68 tma_CD163 tma_HE tma_MHC1 tma_PDL1"

# Experiment & Training parameters
SEED=5678
K_FOLDS=10
MAX_EPOCHS=200
LEARNING_RATE=1e-4
WEIGHT_DECAY=1e-5
OPTIMIZER="adam"
EARLY_STOPPING="--early_stopping"
BATCH_SIZE=1

# æ¨¡å‹å‚æ•°
MODEL_TYPE="clam"
INPUT_DIM=1024
N_CLASSES=2
BASE_LOSS_FN="ce"

# CLAMç‰¹å®šå‚æ•°
GATE="--gate"
BASE_WEIGHT=0.9
INST_LOSS_FN="ce"
MODEL_SIZE="64*32"
SUBTYPING="--subtyping"
INST_NUMBER=8
CHANNELS_USED_IN_MODEL="aligned_tma_CD3 aligned_tma_CD8 aligned_tma_CD56 aligned_tma_CD68 aligned_tma_CD163 aligned_tma_HE aligned_tma_MHC1 aligned_tma_PDL1"

# åŸºç¡€å‘½ä»¤æ¨¡æ¿
BASE_COMMAND="python main.py \
    --data_root_dir \"$DATA_ROOT_DIR\" \
    --results_dir \"$RESULTS_DIR\" \
    --csv_path \"$CSV_PATH\" \
    --target_channel $TARGET_CHANNELS \
    --alignment_model_path \"$ALIGNMENT_MODEL_PATH\" \
    --aligned_channels $ALIGNED_CHANNELS \
    --seed $SEED \
    --k $K_FOLDS \
    --max_epochs $MAX_EPOCHS \
    --lr $LEARNING_RATE \
    --reg $WEIGHT_DECAY \
    --opt $OPTIMIZER \
    $EARLY_STOPPING \
    --batch_size $BATCH_SIZE \
    --model_type $MODEL_TYPE \
    --input_dim $INPUT_DIM \
    --n_classes $N_CLASSES \
    --base_loss_fn $BASE_LOSS_FN \
    --gate $GATE \
    --base_weight $BASE_WEIGHT \
    --inst_loss_fn $INST_LOSS_FN \
    --model_size $MODEL_SIZE \
    --subtyping $SUBTYPING \
    --inst_number $INST_NUMBER \
    --channels_used_in_model $CHANNELS_USED_IN_MODEL"

# Dropout å€¼æ•°ç»„ (10ä¸ªä¸åŒçš„å€¼)
DROPOUT_VALUES=(0.05 0.1 0.2 0.4 0.8)

# åˆ›å»ºç»“æœç›®å½•
RESULTS_DIR="./results/dropout_ablation_$(date +%Y%m%d_%H%M%S)"
mkdir -p $RESULTS_DIR

# å¾ªç¯æ‰§è¡Œæ¯ä¸ª dropout å€¼çš„å®éªŒ
for i in "${!DROPOUT_VALUES[@]}"; do
    dropout=${DROPOUT_VALUES[$i]}
    exp_name="dropout_${dropout}_exp_$((i+1))"
    
    echo ""
    echo "ğŸ§ª å®éªŒ $((i+1))/${#DROPOUT_VALUES[@]}: æµ‹è¯• dropout = $dropout"
    echo "ğŸ“ å®éªŒåç§°: $exp_name"
    echo "ğŸ• å¼€å§‹æ—¶é—´: $(date)"
    
    # æ„å»ºå®Œæ•´å‘½ä»¤
    FULL_COMMAND="$BASE_COMMAND --dropout $dropout --exp_code ${exp_name} --results_dir ${RESULTS_DIR}"
    
    echo "ğŸ’» æ‰§è¡Œå‘½ä»¤: $FULL_COMMAND"
    
    # æ‰§è¡Œè®­ç»ƒ
    eval $FULL_COMMAND
    
    if [ $? -eq 0 ]; then
        echo "âœ… å®éªŒ $((i+1)) å®Œæˆ (dropout=$dropout)"
    else
        echo "âŒ å®éªŒ $((i+1)) å¤±è´¥ (dropout=$dropout)"
    fi
    
    echo "ğŸ•‘ ç»“æŸæ—¶é—´: $(date)"
    echo "-" * 30
done

echo ""
echo "ğŸ‰ Dropout å‚æ•°æ¶ˆèç ”ç©¶å®Œæˆ!"
echo "ğŸ“ ç»“æœä¿å­˜åœ¨: $RESULTS_DIR"
echo "â° æ€»ç»“æŸæ—¶é—´: $(date)"

# ç”Ÿæˆç»“æœæ‘˜è¦
echo ""
echo "ğŸ“Š å®éªŒå‚æ•°æ‘˜è¦:"
echo "å‚æ•°ç±»å‹: Dropout"
echo "æµ‹è¯•å€¼: ${DROPOUT_VALUES[*]}"
echo "å®éªŒæ€»æ•°: ${#DROPOUT_VALUES[@]}"
echo "ç»“æœç›®å½•: $RESULTS_DIR"
