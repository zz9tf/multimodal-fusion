#!/bin/bash

# =============================================================================
# Dynamic Gate + Random Loss å®éªŒè„šæœ¬ï¼ˆå°½é‡ä¸å¯ç”¨ SVD çš„å½±å“ï¼‰
# è¯´æ˜ï¼šå½“å‰æ¨¡å‹é»˜è®¤å¯ç”¨SVDï¼Œä¸ºå°½é‡éš”ç¦»å…¶å½±å“ï¼Œå°†SVDæŸå¤±æƒé‡è®¾ä¸º0ï¼Œå¹¶å¢å¤§tauã€‚
# =============================================================================

# ç¯å¢ƒè®¾ç½®
source ~/zheng/miniconda3/etc/profile.d/conda.sh
conda activate multimodal-fusion
cd /home/zheng/zheng/multimodal-fusion/downstream_survival

CUDA_DEVICE=0
export CUDA_VISIBLE_DEVICES="$CUDA_DEVICE"

# æ•°æ®ç›¸å…³å‚æ•°
DATA_ROOT_DIR="/home/zheng/zheng/public/1"
RESULTS_DIR="/home/zheng/zheng/multimodal-fusion/downstream_survival/results"
CSV_PATH="/home/zheng/zheng/multimodal-fusion/downstream_survival/dataset_csv/survival_dataset.csv"
TARGET_CHANNELS="wsi tma clinical pathological blood icd tma_cell_density"

# å®éªŒ & è®­ç»ƒå‚æ•°
EXP_CODE="dynamic_random_clam"
SEED=5678
K_FOLDS=10
SPLIT_MODE="random"
MAX_EPOCHS=200
LEARNING_RATE=1e-4
LR_SCHEDULER="plateau"
LR_SCHEDULER_PARAMS='{"mode": "min", "patience": 15, "factor": 0.5}'
WEIGHT_DECAY=1e-5
OPTIMIZER="adam"
EARLY_STOPPING="--early_stopping"
BATCH_SIZE=64

# æ¨¡å‹ä¸CLAMå‚æ•°
MODEL_TYPE="svd_gate_random_clam"
INPUT_DIM=1024
DROPOUT=0.25
N_CLASSES=2
BASE_LOSS_FN="ce"
GATE="--gate"
BASE_WEIGHT=0.9
INST_LOSS_FN="ce"
MODEL_SIZE="64*32"
SUBTYPING="--subtyping"
INST_NUMBER=8
CHANNELS_USED_IN_MODEL="wsi tma clinical pathological blood icd tma_cell_density"
OUTPUT_DIM=128

# ä¸ºå°½é‡å‰Šå¼±SVDå½±å“ï¼šå¯¹é½å±‚æ•°ç½®0ï¼ŒæŸå¤±æƒé‡ç½®0ï¼Œæ¸©åº¦å¢å¤§
ALIGNMENT_LAYER_NUM=0
LAMBDA1=0.0
LAMBDA2=0.0
TAU1=1e6
TAU2=1e6

# Dynamic Gateå‚æ•°
ENABLE_DYNAMIC_GATE="--enable_dynamic_gate"
CONFIDENCE_WEIGHT=0.1
FEATURE_WEIGHT_WEIGHT=0.1

# Random Losså‚æ•°
ENABLE_RANDOM_LOSS="--enable_random_loss"
WEIGHT_RANDOM_LOSS=0.1

echo "ğŸš€ å¼€å§‹ Dynamic Gate + Random Loss å®éªŒ..."

python main.py \
    --data_root_dir "$DATA_ROOT_DIR" \
    --results_dir "$RESULTS_DIR" \
    --csv_path "$CSV_PATH" \
    --target_channel $TARGET_CHANNELS \
    --exp_code "$EXP_CODE" \
    --seed $SEED \
    --k $K_FOLDS \
    --split_mode $SPLIT_MODE \
    --max_epochs $MAX_EPOCHS \
    --lr $LEARNING_RATE \
    --lr_scheduler $LR_SCHEDULER \
    --lr_scheduler_params "$LR_SCHEDULER_PARAMS" \
    --reg $WEIGHT_DECAY \
    --opt $OPTIMIZER \
    $EARLY_STOPPING \
    --batch_size $BATCH_SIZE \
    --model_type $MODEL_TYPE \
    --input_dim $INPUT_DIM \
    --dropout $DROPOUT \
    --n_classes $N_CLASSES \
    --base_loss_fn $BASE_LOSS_FN \
    --gate $GATE \
    --base_weight $BASE_WEIGHT \
    --inst_loss_fn $INST_LOSS_FN \
    --model_size $MODEL_SIZE \
    --subtyping $SUBTYPING \
    --inst_number $INST_NUMBER \
    --channels_used_in_model $CHANNELS_USED_IN_MODEL \
    --output_dim $OUTPUT_DIM \
    --alignment_layer_num $ALIGNMENT_LAYER_NUM \
    --lambda1 $LAMBDA1 \
    --lambda2 $LAMBDA2 \
    --tau1 $TAU1 \
    --tau2 $TAU2 \
    $ENABLE_DYNAMIC_GATE \
    --confidence_weight $CONFIDENCE_WEIGHT \
    --feature_weight_weight $FEATURE_WEIGHT_WEIGHT \
    $ENABLE_RANDOM_LOSS \
    --weight_random_loss $WEIGHT_RANDOM_LOSS

echo "âœ… Dynamic Gate + Random Loss å®éªŒå®Œæˆ!"
