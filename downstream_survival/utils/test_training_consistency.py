#!/usr/bin/env python3
"""
æµ‹è¯•è®­ç»ƒè¿‡ç¨‹ä¸€è‡´æ€§
éªŒè¯åœ¨ç›¸åŒseedå’Œç›¸åŒæ•°æ®çš„æƒ…å†µä¸‹ï¼Œä¸¤ä¸ªæ¨¡å‹è®­ç»ƒåæ˜¯å¦ä¼šäº§ç”Ÿç›¸åŒçš„æƒé‡
"""

import os
import sys
import torch
import numpy as np
import json
from pathlib import Path
from torch.utils.data import Subset

# æ·»åŠ é¡¹ç›®è·¯å¾„
root_dir = '/home/zheng/zheng/multimodal-fusion/downstream_survival'
sys.path.append(root_dir)

from trainer import Trainer, get_split_loader, Logger, get_optim
from main import seed_torch, create_k_fold_splits
from datasets.multimodal_dataset import MultimodalDataset
from utils.test_model_init_consistency import compare_model_weights


def test_training_consistency(results_dir: str, num_epochs: int = 10, fold_idx: int = 0):
    """
    æµ‹è¯•è®­ç»ƒè¿‡ç¨‹ä¸€è‡´æ€§
    
    Args:
        results_dir: ç»“æœç›®å½•è·¯å¾„
        num_epochs: è®­ç»ƒepochæ•°
        fold_idx: foldç´¢å¼•
    """
    results_dir = Path(results_dir)
    configs_file = results_dir / 'configs_svd_random_clam_detach.json'
    
    if not configs_file.exists():
        # å°è¯•æŸ¥æ‰¾å…¶ä»–é…ç½®æ–‡ä»¶
        config_files = list(results_dir.glob('configs_*.json'))
        if config_files:
            configs_file = config_files[0]
        else:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶: {results_dir}")
    
    # åŠ è½½é…ç½®
    with open(configs_file, 'r') as f:
        configs = json.load(f)
    
    print(f"ğŸ“‹ åŠ è½½é…ç½®æ–‡ä»¶: {configs_file}")
    print(f"ğŸ“‹ æ¨¡å‹ç±»å‹: {configs['model_config']['model_type']}")
    
    # è·å–seed
    seed = configs['experiment_config'].get('seed', 5678)
    print(f"ğŸŒ± ä½¿ç”¨éšæœºç§å­: {seed}")
    
    # åŠ è½½æ•°æ®é›†
    experiment_config = configs['experiment_config']
    print(f"\nğŸ“¦ åŠ è½½æ•°æ®é›†...")
    print(f"   data_root_dir: {experiment_config['data_root_dir']}")
    print(f"   csv_path: {experiment_config['csv_path']}")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    dataset = MultimodalDataset(
        csv_path=experiment_config['csv_path'],
        data_root_dir=experiment_config['data_root_dir'],
        channels=experiment_config['target_channels'],
        align_channels={},
        alignment_model_path=experiment_config['alignment_model_path'],
        device=device,
        print_info=True
    )
    
    print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆï¼Œå…± {len(dataset)} ä¸ªæ ·æœ¬")
    
    # åˆ›å»ºk-foldåˆ†å‰²ï¼ˆä½¿ç”¨ç›¸åŒçš„seedï¼‰
    print(f"\nğŸ“Š åˆ›å»ºæ•°æ®é›†åˆ†å‰²...")
    splits = create_k_fold_splits(dataset, k=10, seed=seed, fixed_test_split=None)
    split = splits[fold_idx]
    
    train_idx = split['train']
    val_idx = split['val']
    test_idx = split['test']
    
    print(f"   Train samples: {len(train_idx)}")
    print(f"   Val samples: {len(val_idx)}")
    print(f"   Test samples: {len(test_idx)}")
    
    # åˆ›å»ºå­æ•°æ®é›†
    train_dataset = Subset(dataset, train_idx)
    val_dataset = Subset(dataset, val_idx)
    test_dataset = Subset(dataset, test_idx)
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = Trainer(
        configs=configs,
        log_dir=str(results_dir / 'training_logs')
    )
    
    # ========== åˆå§‹åŒ–ç¬¬ä¸€ä¸ªæ¨¡å‹ ==========
    print(f"\n{'='*60}")
    print("åˆå§‹åŒ–ç¬¬ä¸€ä¸ªæ¨¡å‹")
    print(f"{'='*60}")
    
    seed_torch(seed)
    model1 = trainer._init_model()
    trainer.loss_fn = model1.loss_fn  # è®¾ç½®æŸå¤±å‡½æ•°
    optimizer1 = get_optim(model1, trainer.opt, trainer.lr, trainer.reg)
    
    print(f"âœ… æ¨¡å‹1åˆå§‹åŒ–å®Œæˆ")
    print(f"   æ€»å‚æ•°æ•°é‡: {sum(p.numel() for p in model1.parameters()):,}")
    
    # ========== åˆå§‹åŒ–ç¬¬äºŒä¸ªæ¨¡å‹ ==========
    print(f"\n{'='*60}")
    print("åˆå§‹åŒ–ç¬¬äºŒä¸ªæ¨¡å‹ï¼ˆç›¸åŒseedï¼‰")
    print(f"{'='*60}")
    
    seed_torch(seed)
    model2 = trainer._init_model()
    # æ³¨æ„ï¼šmodel2.loss_fn åº”è¯¥å’Œ model1.loss_fn ç›¸åŒï¼Œä½†ä¸ºäº†å®‰å…¨èµ·è§ï¼Œæˆ‘ä»¬ä¹Ÿè®¾ç½®ä¸€ä¸‹
    if trainer.loss_fn is None:
        trainer.loss_fn = model2.loss_fn
    optimizer2 = get_optim(model2, trainer.opt, trainer.lr, trainer.reg)
    
    print(f"âœ… æ¨¡å‹2åˆå§‹åŒ–å®Œæˆ")
    print(f"   æ€»å‚æ•°æ•°é‡: {sum(p.numel() for p in model2.parameters()):,}")
    
    # éªŒè¯åˆå§‹åŒ–æ—¶ä¸¤ä¸ªæ¨¡å‹æ˜¯å¦ä¸€è‡´
    print(f"\nğŸ” éªŒè¯åˆå§‹åŒ–æ—¶ä¸¤ä¸ªæ¨¡å‹æ˜¯å¦ä¸€è‡´...")
    init_comparison = compare_model_weights(model1, model2, tolerance=1e-6)
    if init_comparison['different_elements'] == 0:
        print(f"âœ… åˆå§‹åŒ–æ—¶ä¸¤ä¸ªæ¨¡å‹å®Œå…¨ä¸€è‡´")
    else:
        print(f"âŒ åˆå§‹åŒ–æ—¶ä¸¤ä¸ªæ¨¡å‹ä¸ä¸€è‡´ï¼")
        print(f"   ä¸åŒçš„å…ƒç´ : {init_comparison['different_elements']:,}")
        return
    
    # ========== åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆç¡®ä¿é¡ºåºä¸€è‡´ï¼‰ ==========
    print(f"\n{'='*60}")
    print("åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆç¡®ä¿é¡ºåºä¸€è‡´ï¼‰")
    print(f"{'='*60}")
    
    # âš ï¸ é‡è¦ï¼šä½¿ç”¨å›ºå®šseedçš„generatorç¡®ä¿WeightedRandomSamplerçš„é‡‡æ ·é¡ºåºä¸€è‡´
    print(f"   åˆ›å»ºä¸¤ä¸ªæ•°æ®åŠ è½½å™¨ï¼ˆä½¿ç”¨å›ºå®šseedçš„generatorç¡®ä¿é‡‡æ ·é¡ºåºä¸€è‡´ï¼‰...")
    seed_torch(seed)
    
    # åˆ›å»ºä¸¤ä¸ªå›ºå®šseedçš„generatorï¼Œç¡®ä¿WeightedRandomSamplerçš„é‡‡æ ·é¡ºåºä¸€è‡´
    generator1 = torch.Generator()
    generator1.manual_seed(seed)
    
    generator2 = torch.Generator()
    generator2.manual_seed(seed)
    
    # åˆ›å»ºä¸¤ä¸ªç‹¬ç«‹çš„DataLoaderï¼Œéƒ½ä½¿ç”¨ç›¸åŒçš„generator seed
    train_loader1 = get_split_loader(train_dataset, training=True, weighted=True, batch_size=1, generator=generator1)
    train_loader2 = get_split_loader(train_dataset, training=True, weighted=True, batch_size=1, generator=generator2)
    
    # å°†DataLoaderè½¬æ¢ä¸ºåˆ—è¡¨ï¼Œç¡®ä¿ä¸¤ä¸ªæ¨¡å‹ä½¿ç”¨å®Œå…¨ç›¸åŒçš„æ•°æ®åºåˆ—
    print(f"   å°†DataLoaderè½¬æ¢ä¸ºåˆ—è¡¨ï¼Œç¡®ä¿æ•°æ®é¡ºåºä¸€è‡´...")
    train_loader1_list = list(train_loader1)
    train_loader2_list = list(train_loader2)
    
    print(f"   âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ")
    print(f"   Train batches (model1): {len(train_loader1_list)}")
    print(f"   Train batches (model2): {len(train_loader2_list)}")
    print(f"   âš ï¸ ä¸¤ä¸ªæ¨¡å‹ä½¿ç”¨ç›¸åŒseedçš„generatorï¼Œç¡®ä¿é‡‡æ ·é¡ºåºä¸€è‡´")
    
    # ========== è®­ç»ƒä¸¤ä¸ªæ¨¡å‹ ==========
    print(f"\n{'='*60}")
    print(f"è®­ç»ƒä¸¤ä¸ªæ¨¡å‹ï¼ˆ{num_epochs} ä¸ªepochï¼‰")
    print(f"{'='*60}")
    
    logger1 = Logger(trainer.model_config['n_classes'])
    logger2 = Logger(trainer.model_config['n_classes'])
    
    for epoch in range(num_epochs):
        print(f"\n{'='*60}")
        print(f"Epoch {epoch + 1}/{num_epochs}")
        print(f"{'='*60}")
        
        # ========== è®­ç»ƒæ¨¡å‹1ï¼ˆå®Œæ•´çš„ä¸€ä¸ªepochï¼‰ ==========
        print(f"\nğŸ“Š è®­ç»ƒæ¨¡å‹1ï¼ˆå®Œæ•´çš„ä¸€ä¸ªepochï¼‰...")
        seed_torch(seed + epoch)  # æ¯ä¸ªepochä½¿ç”¨ä¸åŒçš„seedï¼Œä½†ä¸¤ä¸ªæ¨¡å‹ä½¿ç”¨ç›¸åŒçš„seed
        model1.train()
        logger1.reset_epoch_stats()
        
        batch_size = trainer.experiment_config['batch_size']
        total_loss1 = 0
        
        # é‡ç½®æ¨¡å‹çš„groupç›¸å…³çŠ¶æ€ï¼Œç¡®ä¿è®­ç»ƒæ—¶ä»å¹²å‡€çŠ¶æ€å¼€å§‹
        if hasattr(model1, 'alignment_features'):
            model1.alignment_features = []
        if hasattr(model1, 'group_logits'):
            model1.group_logits = []
        if hasattr(model1, 'group_labels'):
            model1.group_labels = []
        
        # ğŸ“Š åˆå§‹åŒ–resultsåˆ—è¡¨ï¼Œç”¨äºç§¯ç´¯æ¯ä¸ªsampleçš„ç»“æœï¼ˆbatch_size=1ï¼Œæ‰€ä»¥æ¯ä¸ªbatchå°±æ˜¯ä¸€ä¸ªsampleï¼‰
        if not hasattr(model1, '_epoch_results'):
            model1._epoch_results = []
        model1._epoch_results = []  # æ¯ä¸ªepochå¼€å§‹æ—¶æ¸…ç©º
        
        for batch_idx, (data, label) in enumerate(train_loader1_list):
            seed_torch(seed + epoch * 10000 + batch_idx)
            
            label = label.to(device)
            for channel in data:
                data[channel] = data[channel].to(device)
            
            results1 = model1(data, label)
            Y_prob1 = results1['probabilities']
            Y_hat1 = results1['predictions']
            
            # ğŸ“Š ä¿å­˜æ¯ä¸ªsampleçš„å®Œæ•´resultsï¼ˆåŒ…æ‹¬æ‰€æœ‰ä¸­é—´æ­¥éª¤ï¼‰
            # æ³¨æ„ï¼šresultsä¸­çš„tensoréœ€è¦cloneå¹¶ç§»åˆ°CPUï¼Œé¿å…åç»­è®­ç»ƒæ—¶è¢«ä¿®æ”¹
            sample_result = {
                'epoch': epoch + 1,
                'sample_idx': batch_idx + 1,  # å› ä¸ºbatch_size=1ï¼Œæ‰€ä»¥sample_idxå°±æ˜¯batch_idx+1
                'results': {}
            }
            
            # ä¿å­˜resultsä¸­çš„æ‰€æœ‰å†…å®¹ï¼ˆè½¬æ¢ä¸ºCPU tensoræˆ–ä¿æŒåŸæ ·ï¼‰
            for key, value in results1.items():
                if isinstance(value, torch.Tensor):
                    sample_result['results'][key] = value.detach().clone().cpu()
                elif isinstance(value, dict):
                    sample_result['results'][key] = {}
                    for sub_key, sub_value in value.items():
                        if isinstance(sub_value, torch.Tensor):
                            sample_result['results'][key][sub_key] = sub_value.detach().clone().cpu()
                        else:
                            sample_result['results'][key][sub_key] = sub_value
                elif isinstance(value, (list, tuple)):
                    sample_result['results'][key] = [
                        v.detach().clone().cpu() if isinstance(v, torch.Tensor) else v
                        for v in value
                    ]
                else:
                    sample_result['results'][key] = value
            
            model1._epoch_results.append(sample_result)
            
            # è®¡ç®—æŸå¤±ï¼ˆå®Œå…¨æŒ‰ç…§trainer.pyçš„é€»è¾‘ï¼‰
            results1['labels'] = label
            loss1 = trainer.loss_fn(results1['logits'], results1['labels'], results1)
            total_loss1 += loss1
            
            # è®°å½•æŒ‡æ ‡
            logger1.log_batch(Y_hat1, label, Y_prob1, loss1)
            
            if (batch_idx + 1) % batch_size == 0:
                # åå‘ä¼ æ’­ï¼ˆå®Œå…¨æŒ‰ç…§trainer.pyçš„é€»è¾‘ï¼‰
                if hasattr(model1, 'group_loss_fn'):
                    results1['group_loss'] = model1.group_loss_fn(results1)
                    total_loss1 += results1['group_loss']
                total_loss1 = total_loss1 / batch_size
                results1['total_loss'] = total_loss1.item()
                total_loss1.backward()
                optimizer1.step()
                optimizer1.zero_grad()
                if hasattr(model1, 'verbose_items'):
                    items = model1.verbose_items(results1)
                    if len(items) > 0:
                        print(f'   æ¨¡å‹1 - Batch {batch_idx + 1}/{len(train_loader1_list)}: ' + ' '.join([f'{key}: {value:.4f}' for key, value in items]))
                total_loss1 = 0
        
        if len(train_loader1_list) % batch_size != 0:
            # è®¡ç®—å‰©ä½™batchçš„æ•°é‡ï¼ˆå®Œå…¨æŒ‰ç…§trainer.pyçš„é€»è¾‘ï¼‰
            remaining_batches = len(train_loader1_list) % batch_size
            # åå‘ä¼ æ’­
            if hasattr(model1, 'group_loss_fn'):
                results1['group_loss'] = model1.group_loss_fn(results1)
                total_loss1 += results1['group_loss']
            total_loss1 = total_loss1 / remaining_batches
            results1['total_loss'] = total_loss1.item()
            total_loss1.backward()
            optimizer1.step()
            optimizer1.zero_grad()
            if hasattr(model1, 'verbose_items'):
                items = model1.verbose_items(results1)
                if len(items) > 0:
                    print(f'   æ¨¡å‹1 - Final batch: ' + ' '.join([f'{key}: {value:.4f}' for key, value in items]))
            total_loss1 = 0
        
        train_loss1 = logger1.batch_log['loss'] / len(train_loader1_list)
        train_acc1 = logger1.get_overall_accuracy()
        print(f"   æ¨¡å‹1 - Epoch {epoch + 1}: Loss={train_loss1:.4f}, Acc={train_acc1:.4f}")
        
        # ========== è®­ç»ƒæ¨¡å‹2ï¼ˆå®Œæ•´çš„ä¸€ä¸ªepochï¼‰ ==========
        print(f"\nğŸ“Š è®­ç»ƒæ¨¡å‹2ï¼ˆå®Œæ•´çš„ä¸€ä¸ªepochï¼‰...")
        seed_torch(seed + epoch)  # ä½¿ç”¨ç›¸åŒçš„seed
        model2.train()
        logger2.reset_epoch_stats()
        
        total_loss2 = 0
        
        # é‡ç½®æ¨¡å‹çš„groupç›¸å…³çŠ¶æ€ï¼Œç¡®ä¿è®­ç»ƒæ—¶ä»å¹²å‡€çŠ¶æ€å¼€å§‹
        if hasattr(model2, 'alignment_features'):
            model2.alignment_features = []
        if hasattr(model2, 'group_logits'):
            model2.group_logits = []
        if hasattr(model2, 'group_labels'):
            model2.group_labels = []
        
        # ğŸ“Š åˆå§‹åŒ–resultsåˆ—è¡¨ï¼Œç”¨äºç§¯ç´¯æ¯ä¸ªsampleçš„ç»“æœï¼ˆbatch_size=1ï¼Œæ‰€ä»¥æ¯ä¸ªbatchå°±æ˜¯ä¸€ä¸ªsampleï¼‰
        if not hasattr(model2, '_epoch_results'):
            model2._epoch_results = []
        model2._epoch_results = []  # æ¯ä¸ªepochå¼€å§‹æ—¶æ¸…ç©º
        
        for batch_idx, (data, label) in enumerate(train_loader2_list):
            # åœ¨æ¯ä¸ªsampleå¼€å§‹å‰é‡ç½®seedï¼Œç¡®ä¿éšæœºæ“ä½œçš„ä¸€è‡´æ€§ï¼ˆä½¿ç”¨ç›¸åŒçš„seedï¼‰
            # ä½¿ç”¨ç‹¬ç«‹çš„seedç¡®ä¿æ¯ä¸ªbatchçš„éšæœºçŠ¶æ€æ˜¯ç‹¬ç«‹çš„
            seed_torch(seed + epoch * 10000 + batch_idx)
            
            label = label.to(device)
            for channel in data:
                data[channel] = data[channel].to(device)
            
            results2 = model2(data, label)
            Y_prob2 = results2['probabilities']
            Y_hat2 = results2['predictions']
            
            # ğŸ“Š ä¿å­˜æ¯ä¸ªsampleçš„å®Œæ•´resultsï¼ˆåŒ…æ‹¬æ‰€æœ‰ä¸­é—´æ­¥éª¤ï¼‰
            # æ³¨æ„ï¼šresultsä¸­çš„tensoréœ€è¦cloneå¹¶ç§»åˆ°CPUï¼Œé¿å…åç»­è®­ç»ƒæ—¶è¢«ä¿®æ”¹
            sample_result = {
                'epoch': epoch + 1,
                'sample_idx': batch_idx + 1,  # å› ä¸ºbatch_size=1ï¼Œæ‰€ä»¥sample_idxå°±æ˜¯batch_idx+1
                'results': {}
            }
            
            # ä¿å­˜resultsä¸­çš„æ‰€æœ‰å†…å®¹ï¼ˆè½¬æ¢ä¸ºCPU tensoræˆ–ä¿æŒåŸæ ·ï¼‰
            for key, value in results2.items():
                if isinstance(value, torch.Tensor):
                    sample_result['results'][key] = value.detach().clone().cpu()
                elif isinstance(value, dict):
                    sample_result['results'][key] = {}
                    for sub_key, sub_value in value.items():
                        if isinstance(sub_value, torch.Tensor):
                            sample_result['results'][key][sub_key] = sub_value.detach().clone().cpu()
                        else:
                            sample_result['results'][key][sub_key] = sub_value
                elif isinstance(value, (list, tuple)):
                    sample_result['results'][key] = [
                        v.detach().clone().cpu() if isinstance(v, torch.Tensor) else v
                        for v in value
                    ]
                else:
                    sample_result['results'][key] = value
            
            model2._epoch_results.append(sample_result)
            
            # è®¡ç®—æŸå¤±ï¼ˆå®Œå…¨æŒ‰ç…§trainer.pyçš„é€»è¾‘ï¼‰
            results2['labels'] = label
            loss2 = trainer.loss_fn(results2['logits'], results2['labels'], results2)
            total_loss2 += loss2
            
            # è®°å½•æŒ‡æ ‡
            logger2.log_batch(Y_hat2, label, Y_prob2, loss2)
            
            if (batch_idx + 1) % batch_size == 0:
                # åå‘ä¼ æ’­ï¼ˆå®Œå…¨æŒ‰ç…§trainer.pyçš„é€»è¾‘ï¼‰
                if hasattr(model2, 'group_loss_fn'):
                    results2['group_loss'] = model2.group_loss_fn(results2)
                    total_loss2 += results2['group_loss']
                total_loss2 = total_loss2 / batch_size
                results2['total_loss'] = total_loss2.item()
                total_loss2.backward()
                optimizer2.step()
                optimizer2.zero_grad()
                if hasattr(model2, 'verbose_items'):
                    items = model2.verbose_items(results2)
                    if len(items) > 0:
                        print(f'   æ¨¡å‹2 - Batch {batch_idx + 1}/{len(train_loader2_list)}: ' + ' '.join([f'{key}: {value:.4f}' for key, value in items]))
                total_loss2 = 0
        
        if len(train_loader2_list) % batch_size != 0:
            # è®¡ç®—å‰©ä½™batchçš„æ•°é‡ï¼ˆå®Œå…¨æŒ‰ç…§trainer.pyçš„é€»è¾‘ï¼‰
            remaining_batches = len(train_loader2_list) % batch_size
            # åå‘ä¼ æ’­
            if hasattr(model2, 'group_loss_fn'):
                results2['group_loss'] = model2.group_loss_fn(results2)
                total_loss2 += results2['group_loss']
            total_loss2 = total_loss2 / remaining_batches
            results2['total_loss'] = total_loss2.item()
            total_loss2.backward()
            optimizer2.step()
            optimizer2.zero_grad()
            if hasattr(model2, 'verbose_items'):
                items = model2.verbose_items(results2)
                if len(items) > 0:
                    print(f'   æ¨¡å‹2 - Final batch: ' + ' '.join([f'{key}: {value:.4f}' for key, value in items]))
            total_loss2 = 0
        
        train_loss2 = logger2.batch_log['loss'] / len(train_loader2_list)
        train_acc2 = logger2.get_overall_accuracy()
        print(f"   æ¨¡å‹2 - Epoch {epoch + 1}: Loss={train_loss2:.4f}, Acc={train_acc2:.4f}")
        
        # ğŸ“Š æ¯”è¾ƒç§¯ç´¯çš„resultsï¼Œæ‰¾å‡ºç¬¬ä¸€ä¸ªä¸ä¸€è‡´çš„æ­¥éª¤
        print(f"\nğŸ” æ¯”è¾ƒç§¯ç´¯çš„resultsï¼Œå®šä½ç¬¬ä¸€ä¸ªä¸ä¸€è‡´çš„æ­¥éª¤...")
        first_inconsistency = None
        
        if hasattr(model1, '_epoch_results') and hasattr(model2, '_epoch_results'):
            results1_list = model1._epoch_results
            results2_list = model2._epoch_results
            
            # ç¡®ä¿ä¸¤ä¸ªåˆ—è¡¨é•¿åº¦ç›¸åŒ
            min_len = min(len(results1_list), len(results2_list))
            print(f"   æ¯”è¾ƒ {min_len} ä¸ªsampleçš„results...")
            
            for i in range(min_len):
                item1 = results1_list[i]
                item2 = results2_list[i]
                
                # ç¡®ä¿æ˜¯åŒä¸€ä¸ªepochå’Œsample
                if item1['epoch'] != item2['epoch'] or item1['sample_idx'] != item2['sample_idx']:
                    print(f"   âš ï¸ Sample {i+1}: epochæˆ–sample_idxä¸åŒ¹é…")
                    continue
                
                results1 = item1['results']
                results2 = item2['results']
                
                # å®Œæ•´çš„resultsæ¯”è¾ƒé€»è¾‘
                inconsistency_info = []
                
                # éå†results1ä¸­çš„æ‰€æœ‰key
                for key in results1:
                    if key not in results2:
                        inconsistency_info.append(f"{key}")
                        inconsistency_info.append(f"{key} not in results2")
                        continue
                    
                    val1 = results1[key]
                    val2 = results2[key]
                    
                    # 1. å¤„ç†intç±»å‹
                    if isinstance(val1, int):
                        if val1 != val2:
                            inconsistency_info.append(f"{key}")
                            inconsistency_info.append(f"{key} value not equal: {val1} vs {val2}")
                    
                    # 2. å¤„ç†list/tupleç±»å‹
                    elif isinstance(val1, (list, tuple)):
                        if len(val1) != len(val2):
                            inconsistency_info.append(f"{key}")
                            inconsistency_info.append(f"{key} length not equal: {len(val1)} vs {len(val2)}")
                        else:
                            for idx in range(len(val1)):
                                if isinstance(val1[idx], torch.Tensor) and isinstance(val2[idx], torch.Tensor):
                                    if val1[idx].shape != val2[idx].shape:
                                        inconsistency_info.append(f"{key}[{idx}]")
                                        inconsistency_info.append(f"{key}[{idx}] shape not equal: {val1[idx].shape} vs {val2[idx].shape}")
                                    else:
                                        max_diff = torch.max(torch.abs(val1[idx] - val2[idx])).item()
                                        if max_diff > 1e-6:
                                            inconsistency_info.append(f"{key}[{idx}]")
                                            inconsistency_info.append(f"{key}[{idx}] value not equal: max_diff={max_diff:.2e}")
                                elif val1[idx] != val2[idx]:
                                    inconsistency_info.append(f"{key}[{idx}]")
                                    inconsistency_info.append(f"{key}[{idx}] value not equal: {val1[idx]} vs {val2[idx]}")
                    
                    # 3. å¤„ç†dictç±»å‹
                    elif isinstance(val1, dict):
                        keys1 = sorted(val1.keys())
                        keys2 = sorted(val2.keys())
                        if keys1 != keys2:
                            inconsistency_info.append(f"{key}")
                            inconsistency_info.append(f"{key} keysä¸ä¸€è‡´: {keys1} vs {keys2}")
                        else:
                            for sub_key in keys1:
                                sub_val1 = val1[sub_key]
                                sub_val2 = val2[sub_key]
                                
                                if isinstance(sub_val1, torch.Tensor) and isinstance(sub_val2, torch.Tensor):
                                    if sub_val1.shape != sub_val2.shape:
                                        inconsistency_info.append(f"{key}[{sub_key}]")
                                        inconsistency_info.append(f"{key}[{sub_key}] shape not equal: {sub_val1.shape} vs {sub_val2.shape}")
                                    else:
                                        # æ£€æŸ¥tensorçš„dtypeï¼Œå¦‚æœæ˜¯æ•´æ•°ç±»å‹ï¼Œåªæ¯”è¾ƒæ˜¯å¦ç›¸ç­‰
                                        if sub_val1.dtype in (torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8):
                                            if not torch.equal(sub_val1, sub_val2):
                                                diff_count = (sub_val1 != sub_val2).sum().item()
                                                inconsistency_info.append(f"{key}[{sub_key}]")
                                                inconsistency_info.append(f"{key}[{sub_key}] æ•´æ•°tensorä¸ä¸€è‡´ï¼Œ{diff_count} ä¸ªå…ƒç´ ä¸åŒ")
                                        else:
                                            # æµ®ç‚¹æ•°ç±»å‹ï¼šè®¡ç®—max_diff
                                            max_diff = torch.max(torch.abs(sub_val1 - sub_val2)).item()
                                            if max_diff > 1e-6:
                                                inconsistency_info.append(f"{key}[{sub_key}]")
                                                inconsistency_info.append(f"{key}[{sub_key}] value not equal: max_diff={max_diff:.2e}")
                                elif sub_val1 != sub_val2:
                                    inconsistency_info.append(f"{key}[{sub_key}]")
                                    inconsistency_info.append(f"{key}[{sub_key}] value not equal: {sub_val1} vs {sub_val2}")
                    
                    # 4. å¤„ç†tensorç±»å‹
                    elif isinstance(val1, torch.Tensor) and isinstance(val2, torch.Tensor):
                        if val1.shape != val2.shape:
                            inconsistency_info.append(f"{key}")
                            inconsistency_info.append(f"{key} shape not equal: {val1.shape} vs {val2.shape}")
                        else:
                            # æ£€æŸ¥tensorçš„dtypeï¼Œå¦‚æœæ˜¯æ•´æ•°ç±»å‹ï¼Œåªæ¯”è¾ƒæ˜¯å¦ç›¸ç­‰
                            if val1.dtype in (torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8):
                                if not torch.equal(val1, val2):
                                    diff_count = (val1 != val2).sum().item()
                                    inconsistency_info.append(f"{key}")
                                    inconsistency_info.append(f"{key} æ•´æ•°tensorä¸ä¸€è‡´ï¼Œ{diff_count} ä¸ªå…ƒç´ ä¸åŒ")
                            else:
                                # æµ®ç‚¹æ•°ç±»å‹ï¼šè®¡ç®—max_diff
                                max_diff = torch.max(torch.abs(val1 - val2)).item()
                                if max_diff > 1e-6:
                                    inconsistency_info.append(f"{key}")
                                    inconsistency_info.append(f"{key} value not equal: max_diff={max_diff:.2e}")
                    
                    # 5. å¤„ç†np.ndarrayç±»å‹
                    elif isinstance(val1, np.ndarray) and isinstance(val2, np.ndarray):
                        if val1.shape != val2.shape:
                            inconsistency_info.append(f"{key}")
                            inconsistency_info.append(f"{key} shape not equal: {val1.shape} vs {val2.shape}")
                        else:
                            max_diff = np.max(np.abs(val1 - val2))
                            if max_diff > 1e-6:
                                inconsistency_info.append(f"{key}")
                                inconsistency_info.append(f"{key} value not equal: max_diff={max_diff:.2e}")
                    
                    # 6. å¤„ç†å…¶ä»–ç±»å‹
                    else:
                        print(f'{key} {type(val1)} {type(val2)} {val1} {val2}')
                        if val1 != val2:
                            inconsistency_info.append(f"{key}")
                            inconsistency_info.append(f"{key} value not equal: {val1} vs {val2}")
                
                # æ£€æŸ¥results2ä¸­æ˜¯å¦æœ‰results1ä¸­æ²¡æœ‰çš„key
                for key in results2:
                    if key not in results1:
                        inconsistency_info.append(f"{key}")
                        inconsistency_info.append(f"{key} not in results1")
                
                # å¦‚æœå‘ç°ä¸ä¸€è‡´ï¼Œè®°å½•ç¬¬ä¸€ä¸ª
                if inconsistency_info and first_inconsistency is None:
                    first_inconsistency = {
                        'epoch': item1['epoch'],
                        'sample_idx': item1['sample_idx'],
                        'results1': results1,
                        'results2': results2,
                        'info': inconsistency_info
                    }
                    print(f"\n   âŒ å‘ç°ç¬¬ä¸€ä¸ªä¸ä¸€è‡´ï¼")
                    print(f"      Epoch: {first_inconsistency['epoch']}")
                    print(f"      Sample: {first_inconsistency['sample_idx']}")
                    print(f"      ä¸ä¸€è‡´çš„æ­¥éª¤:")
                    for info in inconsistency_info:
                        print(f"        - {info}")
                    break
            
            # æ˜¾ç¤ºç¬¬ä¸€ä¸ªä¸ä¸€è‡´çš„è¯¦ç»†ä¿¡æ¯
            if first_inconsistency:
                print(f"\n   ğŸ” ç¬¬ä¸€ä¸ªä¸ä¸€è‡´çš„è¯¦ç»†ä¿¡æ¯:")
                print(f"      Epoch: {first_inconsistency['epoch']}, Sample: {first_inconsistency['sample_idx']}")
                results1 = first_inconsistency['results1']
                results2 = first_inconsistency['results2']
                
                # è¯¦ç»†æ¯”è¾ƒæ¯ä¸ªkey
                all_keys = sorted(set(results1.keys()) | set(results2.keys()))
                for key in all_keys:
                    if key not in results1:
                        print(f"      âŒ {key}: åªåœ¨results2ä¸­å­˜åœ¨")
                        continue
                    if key not in results2:
                        print(f"      âŒ {key}: åªåœ¨results1ä¸­å­˜åœ¨")
                        continue
                    
                    val1 = results1[key]
                    val2 = results2[key]
                    
                    if isinstance(val1, dict) and isinstance(val2, dict):
                        print(f"      {key}:")
                        sub_keys = sorted(set(val1.keys()) | set(val2.keys()))
                        for sub_key in sub_keys:
                            if sub_key in val1 and sub_key in val2:
                                if isinstance(val1[sub_key], torch.Tensor) and isinstance(val2[sub_key], torch.Tensor):
                                    if val1[sub_key].shape == val2[sub_key].shape:
                                        # æ£€æŸ¥tensorçš„dtypeï¼Œå¦‚æœæ˜¯æ•´æ•°ç±»å‹ï¼Œåªæ¯”è¾ƒæ˜¯å¦ç›¸ç­‰
                                        if val1[sub_key].dtype in (torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8):
                                            if not torch.equal(val1[sub_key], val2[sub_key]):
                                                diff_count = (val1[sub_key] != val2[sub_key]).sum().item()
                                                total_count = val1[sub_key].numel()
                                                print(f"         âŒ [{sub_key}]: æ•´æ•°tensorä¸ä¸€è‡´ï¼Œ{diff_count}/{total_count} ä¸ªå…ƒç´ ä¸åŒ")
                                            else:
                                                print(f"         âœ… [{sub_key}]: ä¸€è‡´")
                                        else:
                                            # æµ®ç‚¹æ•°ç±»å‹ï¼šè®¡ç®—max_diff
                                            max_diff = torch.max(torch.abs(val1[sub_key] - val2[sub_key])).item()
                                            if max_diff > 1e-6:
                                                print(f"         âŒ [{sub_key}]: max_diff={max_diff:.2e}")
                                            else:
                                                print(f"         âœ… [{sub_key}]: ä¸€è‡´")
                                    else:
                                        print(f"         âŒ [{sub_key}]: å½¢çŠ¶ä¸ä¸€è‡´ {val1[sub_key].shape} vs {val2[sub_key].shape}")
                                else:
                                    if val1[sub_key] == val2[sub_key]:
                                        print(f"         âœ… [{sub_key}]: ä¸€è‡´")
                                    else:
                                        print(f"         âŒ [{sub_key}]: ä¸ä¸€è‡´ {val1[sub_key]} vs {val2[sub_key]}")
                            elif sub_key in val1:
                                print(f"         âŒ [{sub_key}]: åªåœ¨results1ä¸­å­˜åœ¨")
                            else:
                                print(f"         âŒ [{sub_key}]: åªåœ¨results2ä¸­å­˜åœ¨")
                    elif isinstance(val1, torch.Tensor) and isinstance(val2, torch.Tensor):
                        if val1.shape == val2.shape:
                            # æ£€æŸ¥tensorçš„dtypeï¼Œå¦‚æœæ˜¯æ•´æ•°ç±»å‹ï¼Œéœ€è¦è½¬æ¢ä¸ºfloatæ‰èƒ½è®¡ç®—mean
                            if val1.dtype in (torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8):
                                # æ•´æ•°ç±»å‹ï¼šåªæ¯”è¾ƒæ˜¯å¦ç›¸ç­‰
                                if not torch.equal(val1, val2):
                                    # è®¡ç®—ä¸ç›¸ç­‰å…ƒç´ çš„æ•°é‡
                                    diff_count = (val1 != val2).sum().item()
                                    total_count = val1.numel()
                                    print(f"      âŒ {key}: æ•´æ•°tensorä¸ä¸€è‡´ï¼Œ{diff_count}/{total_count} ä¸ªå…ƒç´ ä¸åŒ")
                                else:
                                    print(f"      âœ… {key}: ä¸€è‡´")
                            else:
                                # æµ®ç‚¹æ•°ç±»å‹ï¼šè®¡ç®—max_diffå’Œmean_diff
                                max_diff = torch.max(torch.abs(val1 - val2)).item()
                                mean_diff = torch.mean(torch.abs(val1 - val2)).item()
                                if max_diff > 1e-6:
                                    print(f"      âŒ {key}: max_diff={max_diff:.2e}, mean_diff={mean_diff:.2e}")
                                else:
                                    print(f"      âœ… {key}: ä¸€è‡´")
                        else:
                            print(f"      âŒ {key}: å½¢çŠ¶ä¸ä¸€è‡´ {val1.shape} vs {val2.shape}")
                    else:
                        if val1 == val2:
                            print(f"      âœ… {key}: ä¸€è‡´")
                        else:
                            print(f"      âŒ {key}: ä¸ä¸€è‡´ {val1} vs {val2}")
                
                # å‘ç°ç¬¬ä¸€ä¸ªä¸ä¸€è‡´åç«‹å³é€€å‡º
                print(f"\n{'='*60}")
                print(f"âŒ å‘ç°ä¸ä¸€è‡´ï¼Œç¨‹åºé€€å‡º")
                print(f"{'='*60}")
                sys.exit(1)
            else:
                print(f"   âœ… æ‰€æœ‰sampleçš„resultséƒ½ä¸€è‡´")
        
        # æ¸…ç©ºresultsåˆ—è¡¨ï¼Œå‡†å¤‡ä¸‹ä¸€ä¸ªepoch
        if hasattr(model1, '_epoch_results'):
            model1._epoch_results = []
        if hasattr(model2, '_epoch_results'):
            model2._epoch_results = []
        
        # æ¯”è¾ƒè®­ç»ƒåçš„æƒé‡
        print(f"\nğŸ” æ¯”è¾ƒè®­ç»ƒåçš„æƒé‡...")
        epoch_comparison = compare_model_weights(model1, model2, tolerance=1e-6)
        
        print(f"   ğŸ“ˆ Epoch {epoch + 1} æ¯”è¾ƒç»“æœ:")
        print(f"      å‚æ•°å…ƒç´ æ€»æ•°: {epoch_comparison['total_param_elements']:,}")
        print(f"      åŒ¹é…çš„å…ƒç´ : {epoch_comparison['matching_elements']:,} ({100*epoch_comparison['matching_elements']/epoch_comparison['total_param_elements']:.2f}%)")
        print(f"      ä¸åŒçš„å…ƒç´ : {epoch_comparison['different_elements']:,} ({100*epoch_comparison['different_elements']/epoch_comparison['total_param_elements']:.2f}%)")
        print(f"      å…¨å±€æœ€å¤§ç»å¯¹å·®: {epoch_comparison['global_max_abs_diff']:.6e}")
        print(f"      å…¨å±€å¹³å‡ç»å¯¹å·®: {epoch_comparison['global_mean_abs_diff']:.6e}")
        
        if epoch_comparison['different_elements'] > 0:
            print(f"   âš ï¸ Epoch {epoch + 1} åä¸¤ä¸ªæ¨¡å‹ä¸ä¸€è‡´ï¼")
            if epoch_comparison['different_keys']:
                print(f"      æœ‰å·®å¼‚çš„å‚æ•°å¼ é‡: {len(epoch_comparison['different_keys'])} ä¸ª")
                for diff_info in epoch_comparison['different_keys'][:5]:
                    if isinstance(diff_info, dict):
                        print(f"        - {diff_info['key']}: max_diff={diff_info['max_diff']:.6e}")
        else:
            print(f"   âœ… Epoch {epoch + 1} åä¸¤ä¸ªæ¨¡å‹å®Œå…¨ä¸€è‡´ï¼")
    
    # ========== æœ€ç»ˆæ¯”è¾ƒ ==========
    print(f"\n{'='*60}")
    print("æœ€ç»ˆæ¯”è¾ƒ")
    print(f"{'='*60}")
    
    final_comparison = compare_model_weights(model1, model2, tolerance=1e-6)
    
    print(f"\nğŸ“Š æœ€ç»ˆæ¯”è¾ƒç»“æœ:")
    print(f"   å‚æ•°å…ƒç´ æ€»æ•°: {final_comparison['total_param_elements']:,}")
    print(f"   åŒ¹é…çš„å…ƒç´ : {final_comparison['matching_elements']:,} ({100*final_comparison['matching_elements']/final_comparison['total_param_elements']:.2f}%)")
    print(f"   ä¸åŒçš„å…ƒç´ : {final_comparison['different_elements']:,} ({100*final_comparison['different_elements']/final_comparison['total_param_elements']:.2f}%)")
    print(f"   å®Œå…¨åŒ¹é…çš„å¼ é‡: {final_comparison['matching_param_tensors']}")
    print(f"   æœ‰å·®å¼‚çš„å¼ é‡: {final_comparison['different_param_tensors']}")
    print(f"   å…¨å±€æœ€å¤§ç»å¯¹å·®: {final_comparison['global_max_abs_diff']:.6e}")
    print(f"   å…¨å±€å¹³å‡ç»å¯¹å·®: {final_comparison['global_mean_abs_diff']:.6e}")
    
    if final_comparison['different_keys']:
        print(f"\n   âš ï¸ æœ‰å·®å¼‚çš„å‚æ•°å¼ é‡ ({len(final_comparison['different_keys'])} ä¸ª):")
        for diff_info in final_comparison['different_keys'][:10]:
            if isinstance(diff_info, dict):
                print(f"     - {diff_info['key']}:")
                print(f"       shape: {diff_info['shape']}, numel: {diff_info['numel']:,}")
                print(f"       åŒ¹é…å…ƒç´ : {diff_info['matching_elements']:,}, ä¸åŒå…ƒç´ : {diff_info['different_elements']:,}")
                print(f"       max_diff: {diff_info['max_diff']:.6e}, mean_diff: {diff_info['mean_diff']:.6e}")
    
    # åˆ¤æ–­æ˜¯å¦ä¸€è‡´
    is_consistent = (
        final_comparison['different_elements'] == 0 and
        len(final_comparison['missing_keys_1']) == 0 and
        len(final_comparison['missing_keys_2']) == 0 and
        final_comparison['global_max_abs_diff'] < 1e-6
    )
    
    print(f"\n{'='*60}")
    if is_consistent:
        print("âœ… ç»“è®º: è®­ç»ƒåä¸¤ä¸ªæ¨¡å‹æƒé‡å®Œå…¨ä¸€è‡´ï¼")
        print(f"   - è®­ç»ƒè¿‡ç¨‹æ˜¯ç¡®å®šæ€§çš„")
        print(f"   - æ‰€æœ‰ {final_comparison['total_param_elements']:,} ä¸ªå‚æ•°å…ƒç´ å®Œå…¨åŒ¹é…")
    else:
        print("âŒ ç»“è®º: è®­ç»ƒåä¸¤ä¸ªæ¨¡å‹æƒé‡ä¸ä¸€è‡´ï¼")
        print(f"   - ä¸åŒçš„å…ƒç´ : {final_comparison['different_elements']:,}")
        print(f"   - å¯èƒ½çš„åŸå› :")
        print(f"     1. è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨äº†éç¡®å®šæ€§æ“ä½œï¼ˆå¦‚dropoutåœ¨è®­ç»ƒæ¨¡å¼ï¼‰")
        print(f"     2. CUDAæ“ä½œçš„éç¡®å®šæ€§")
        print(f"     3. æµ®ç‚¹æ•°è¿ç®—çš„ç´¯ç§¯è¯¯å·®")
        print(f"     4. æŸäº›éšæœºæ“ä½œæœªè®¾ç½®seed")
    print(f"{'='*60}")
    
    return {
        'init_comparison': init_comparison,
        'final_comparison': final_comparison,
        'is_consistent': is_consistent
    }


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='æµ‹è¯•è®­ç»ƒè¿‡ç¨‹ä¸€è‡´æ€§')
    parser.add_argument('--results_dir', type=str, required=True,
                        help='ç»“æœç›®å½•è·¯å¾„')
    parser.add_argument('--num_epochs', type=int, default=10,
                        help='è®­ç»ƒepochæ•° (default: 10)')
    parser.add_argument('--fold_idx', type=int, default=0,
                        help='foldç´¢å¼• (default: 0)')
    
    args = parser.parse_args()
    
    try:
        results = test_training_consistency(
            args.results_dir,
            args.num_epochs,
            args.fold_idx
        )
        
        if not results['is_consistent']:
            sys.exit(1)
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

