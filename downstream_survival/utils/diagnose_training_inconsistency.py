#!/usr/bin/env python3
"""
è¯Šæ–­è®­ç»ƒä¸ä¸€è‡´çš„åŸå› 
é‡ç‚¹æ£€æŸ¥setè½¬listå’Œå­—å…¸é”®é¡ºåºçš„é—®é¢˜
"""

import os
import sys
import torch
import numpy as np
import json
from pathlib import Path
from torch.utils.data import Subset

# æ·»åŠ é¡¹ç›®è·¯å¾„
root_dir = '/home/zheng/zheng/multimodal-fusion/downstream_survival'
sys.path.append(root_dir)

from trainer import Trainer, get_split_loader
from main import seed_torch, create_k_fold_splits
from datasets.multimodal_dataset import MultimodalDataset


def diagnose_training_inconsistency(results_dir: str, fold_idx: int = 0):
    """
    è¯Šæ–­è®­ç»ƒä¸ä¸€è‡´çš„åŸå› 
    """
    results_dir = Path(results_dir)
    configs_file = results_dir / 'configs_svd_random_clam_detach.json'
    
    if not configs_file.exists():
        config_files = list(results_dir.glob('configs_*.json'))
        if config_files:
            configs_file = config_files[0]
        else:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶: {results_dir}")
    
    # åŠ è½½é…ç½®
    with open(configs_file, 'r') as f:
        configs = json.load(f)
    
    print(f"ğŸ“‹ åŠ è½½é…ç½®æ–‡ä»¶: {configs_file}")
    
    # è·å–seed
    seed = configs['experiment_config'].get('seed', 5678)
    print(f"ğŸŒ± ä½¿ç”¨éšæœºç§å­: {seed}")
    
    # åŠ è½½æ•°æ®é›†
    experiment_config = configs['experiment_config']
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    dataset = MultimodalDataset(
        csv_path=experiment_config['csv_path'],
        data_root_dir=experiment_config['data_root_dir'],
        channels=experiment_config['target_channels'],
        align_channels={},
        alignment_model_path=experiment_config['alignment_model_path'],
        device=device,
        print_info=False
    )
    
    # åˆ›å»ºk-foldåˆ†å‰²
    splits = create_k_fold_splits(dataset, k=10, seed=seed, fixed_test_split=None)
    split = splits[fold_idx]
    train_idx = split['train']
    train_dataset = Subset(dataset, train_idx)
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = Trainer(
        configs=configs,
        log_dir=str(results_dir / 'training_logs')
    )
    
    # åˆå§‹åŒ–ä¸¤ä¸ªæ¨¡å‹
    seed_torch(seed)
    model1 = trainer._init_model()
    trainer.loss_fn = model1.loss_fn
    
    seed_torch(seed)
    model2 = trainer._init_model()
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    seed_torch(seed)
    train_loader = get_split_loader(train_dataset, training=True, weighted=True, batch_size=1)
    train_loader_list = list(train_loader)
    
    print(f"\n{'='*60}")
    print("è¯Šæ–­è®­ç»ƒä¸ä¸€è‡´çš„åŸå› ")
    print(f"{'='*60}")
    
    # è·å–ç¬¬ä¸€ä¸ªbatch
    data, label = train_loader_list[0]
    label = label.to(device)
    for channel in data:
        data[channel] = data[channel].to(device)
    
    print(f"\nğŸ“Š ç¬¬ä¸€ä¸ªbatchçš„æ•°æ®:")
    print(f"   channels: {list(data.keys())}")
    print(f"   channelsé¡ºåº: {list(data.keys())}")
    
    # æ£€æŸ¥_process_input_dataè¿”å›çš„modalities_used_in_model
    print(f"\nğŸ” æ£€æŸ¥ _process_input_data è¿”å›çš„ modalities_used_in_model:")
    
    seed_torch(seed + 10000)
    input_data1, modalities_used_in_model1 = model1._process_input_data(data.copy())
    print(f"   æ¨¡å‹1 - modalities_used_in_modelç±»å‹: {type(modalities_used_in_model1)}")
    print(f"   æ¨¡å‹1 - modalities_used_in_model: {modalities_used_in_model1}")
    print(f"   æ¨¡å‹1 - modalities_used_in_modelé¡ºåº: {list(modalities_used_in_model1)}")
    
    seed_torch(seed + 10000)
    input_data2, modalities_used_in_model2 = model2._process_input_data(data.copy())
    print(f"   æ¨¡å‹2 - modalities_used_in_modelç±»å‹: {type(modalities_used_in_model2)}")
    print(f"   æ¨¡å‹2 - modalities_used_in_model: {modalities_used_in_model2}")
    print(f"   æ¨¡å‹2 - modalities_used_in_modelé¡ºåº: {list(modalities_used_in_model2)}")
    
    # æ£€æŸ¥é¡ºåºæ˜¯å¦ä¸€è‡´
    list1 = list(modalities_used_in_model1)
    list2 = list(modalities_used_in_model2)
    if list1 == list2:
        print(f"   âœ… modalities_used_in_modelé¡ºåºä¸€è‡´")
    else:
        print(f"   âŒ modalities_used_in_modelé¡ºåºä¸ä¸€è‡´ï¼")
        print(f"      æ¨¡å‹1: {list1}")
        print(f"      æ¨¡å‹2: {list2}")
    
    # æ£€æŸ¥features_dictçš„æ„å»ºé¡ºåº
    print(f"\nğŸ” æ£€æŸ¥ features_dict çš„æ„å»ºé¡ºåº:")
    
    seed_torch(seed + 10000)
    features_dict1 = {}
    for channel in modalities_used_in_model1:
        if channel == 'wsi=features':
            features_dict1[channel] = torch.randn(1, 128)  # æ¨¡æ‹Ÿ
        elif channel == 'tma=features':
            features_dict1[channel] = torch.randn(1, 128)  # æ¨¡æ‹Ÿ
        else:
            features_dict1[channel] = torch.randn(1, 128)  # æ¨¡æ‹Ÿ
    
    seed_torch(seed + 10000)
    features_dict2 = {}
    for channel in modalities_used_in_model2:
        if channel == 'wsi=features':
            features_dict2[channel] = torch.randn(1, 128)  # æ¨¡æ‹Ÿ
        elif channel == 'tma=features':
            features_dict2[channel] = torch.randn(1, 128)  # æ¨¡æ‹Ÿ
        else:
            features_dict2[channel] = torch.randn(1, 128)  # æ¨¡æ‹Ÿ
    
    print(f"   æ¨¡å‹1 - features_dict keys: {list(features_dict1.keys())}")
    print(f"   æ¨¡å‹2 - features_dict keys: {list(features_dict2.keys())}")
    
    if list(features_dict1.keys()) == list(features_dict2.keys()):
        print(f"   âœ… features_dict keysé¡ºåºä¸€è‡´")
    else:
        print(f"   âŒ features_dict keysé¡ºåºä¸ä¸€è‡´ï¼")
        print(f"      æ¨¡å‹1: {list(features_dict1.keys())}")
        print(f"      æ¨¡å‹2: {list(features_dict2.keys())}")
    
    # æ£€æŸ¥random.sampleå’Œrandom.randintçš„ä½¿ç”¨
    print(f"\nğŸ” æ£€æŸ¥ random.sample å’Œ random.randint çš„ä½¿ç”¨:")
    
    import random
    
    seed_torch(seed + 10000)
    keys1 = list(features_dict1.keys())
    n1 = random.randint(1, len(keys1) - 1)
    drop1 = random.sample(keys1, n1)
    print(f"   æ¨¡å‹1 - features_dict keys: {keys1}")
    print(f"   æ¨¡å‹1 - random.randint(1, {len(keys1)-1}): {n1}")
    print(f"   æ¨¡å‹1 - random.sampleç»“æœ: {drop1}")
    
    seed_torch(seed + 10000)
    keys2 = list(features_dict2.keys())
    n2 = random.randint(1, len(keys2) - 1)
    drop2 = random.sample(keys2, n2)
    print(f"   æ¨¡å‹2 - features_dict keys: {keys2}")
    print(f"   æ¨¡å‹2 - random.randint(1, {len(keys2)-1}): {n2}")
    print(f"   æ¨¡å‹2 - random.sampleç»“æœ: {drop2}")
    
    if keys1 == keys2 and n1 == n2 and set(drop1) == set(drop2):
        print(f"   âœ… randomæ“ä½œç»“æœä¸€è‡´")
    else:
        print(f"   âŒ randomæ“ä½œç»“æœä¸ä¸€è‡´ï¼")
        if keys1 != keys2:
            print(f"      features_dict keysé¡ºåºä¸åŒ: {keys1} vs {keys2}")
        if n1 != n2:
            print(f"      random.randintç»“æœä¸åŒ: {n1} vs {n2}")
        if set(drop1) != set(drop2):
            print(f"      random.sampleç»“æœä¸åŒ: {drop1} vs {drop2}")
    
    # æ£€æŸ¥forå¾ªç¯çš„é¡ºåº
    print(f"\nğŸ” æ£€æŸ¥ for modality in features_dict.keys() çš„é¡ºåº:")
    
    seed_torch(seed + 10000)
    order1 = []
    for modality in features_dict1.keys():
        order1.append(modality)
    print(f"   æ¨¡å‹1 - forå¾ªç¯é¡ºåº: {order1}")
    
    seed_torch(seed + 10000)
    order2 = []
    for modality in features_dict2.keys():
        order2.append(modality)
    print(f"   æ¨¡å‹2 - forå¾ªç¯é¡ºåº: {order2}")
    
    if order1 == order2:
        print(f"   âœ… forå¾ªç¯é¡ºåºä¸€è‡´")
    else:
        print(f"   âŒ forå¾ªç¯é¡ºåºä¸ä¸€è‡´ï¼")
        print(f"      æ¨¡å‹1: {order1}")
        print(f"      æ¨¡å‹2: {order2}")
    
    # å®é™…è¿è¡Œforwardæ£€æŸ¥
    print(f"\nğŸ” å®é™…è¿è¡Œforwardæ£€æŸ¥:")
    
    # é‡ç½®æ¨¡å‹çŠ¶æ€
    if hasattr(model1, 'alignment_features'):
        model1.alignment_features = []
    if hasattr(model2, 'alignment_features'):
        model2.alignment_features = []
    
    # å®é™…è¿è¡Œforward
    seed_torch(seed + 10000)
    model1.eval()
    with torch.no_grad():
        results1 = model1(data.copy(), label)
    
    seed_torch(seed + 10000)
    model2.eval()
    with torch.no_grad():
        results2 = model2(data.copy(), label)
    
    # æ£€æŸ¥alignment_features
    if hasattr(model1, 'alignment_features') and len(model1.alignment_features) > 0:
        print(f"   æ¨¡å‹1 - alignment_features[0] keys: {list(model1.alignment_features[0].keys())}")
    if hasattr(model2, 'alignment_features') and len(model2.alignment_features) > 0:
        print(f"   æ¨¡å‹2 - alignment_features[0] keys: {list(model2.alignment_features[0].keys())}")
    
    if (hasattr(model1, 'alignment_features') and len(model1.alignment_features) > 0 and
        hasattr(model2, 'alignment_features') and len(model2.alignment_features) > 0):
        keys1 = list(model1.alignment_features[0].keys())
        keys2 = list(model2.alignment_features[0].keys())
        if keys1 == keys2:
            print(f"   âœ… alignment_features keysé¡ºåºä¸€è‡´")
        else:
            print(f"   âŒ alignment_features keysé¡ºåºä¸ä¸€è‡´ï¼")
            print(f"      æ¨¡å‹1: {keys1}")
            print(f"      æ¨¡å‹2: {keys2}")
    
    # æ£€æŸ¥align_forwardä¸­features.items()çš„é¡ºåº
    print(f"\nğŸ” æ£€æŸ¥ align_forward ä¸­ features.items() çš„é¡ºåº:")
    
    # åˆ›å»ºæµ‹è¯•ç”¨çš„features_dict
    test_features1 = {}
    test_features2 = {}
    for channel in sorted(modalities_used_in_model1):  # ä½¿ç”¨sortedç¡®ä¿é¡ºåºä¸€è‡´
        test_features1[channel] = torch.randn(1, 128)
        test_features2[channel] = torch.randn(1, 128)
    
    seed_torch(seed + 20000)
    aligned1 = model1.align_forward(test_features1)
    keys1_aligned = list(aligned1.keys())
    print(f"   æ¨¡å‹1 - align_forwardå keys: {keys1_aligned}")
    
    seed_torch(seed + 20000)
    aligned2 = model2.align_forward(test_features2)
    keys2_aligned = list(aligned2.keys())
    print(f"   æ¨¡å‹2 - align_forwardå keys: {keys2_aligned}")
    
    if keys1_aligned == keys2_aligned:
        print(f"   âœ… align_forwardå keysé¡ºåºä¸€è‡´")
    else:
        print(f"   âŒ align_forwardå keysé¡ºåºä¸ä¸€è‡´ï¼")
        print(f"      æ¨¡å‹1: {keys1_aligned}")
        print(f"      æ¨¡å‹2: {keys2_aligned}")
    
    # æ£€æŸ¥group_loss_fnä¸­alignment_featuresçš„é¡ºåº
    print(f"\nğŸ” æ£€æŸ¥ group_loss_fn ä¸­ alignment_features çš„é¡ºåº:")
    
    if hasattr(model1, 'group_loss_fn'):
        # åˆ›å»ºæµ‹è¯•ç”¨çš„alignment_features
        model1.alignment_features = []
        model2.alignment_features = []
        
        for i in range(3):
            features_dict_batch1 = {}
            features_dict_batch2 = {}
            for channel in sorted(modalities_used_in_model1):  # ä½¿ç”¨sortedç¡®ä¿é¡ºåºä¸€è‡´
                features_dict_batch1[channel] = torch.randn(1, 128)
                features_dict_batch2[channel] = torch.randn(1, 128)
            
            model1.alignment_features.append(features_dict_batch1)
            model2.alignment_features.append(features_dict_batch2)
        
        # æ£€æŸ¥group_loss_fnä¸­çš„keysé¡ºåº
        if len(model1.alignment_features) > 0:
            keys1_group = sorted(model1.alignment_features[0].keys())
            print(f"   æ¨¡å‹1 - alignment_features[0] keys (sorted): {keys1_group}")
        
        if len(model2.alignment_features) > 0:
            keys2_group = sorted(model2.alignment_features[0].keys())
            print(f"   æ¨¡å‹2 - alignment_features[0] keys (sorted): {keys2_group}")
        
        if keys1_group == keys2_group:
            print(f"   âœ… group_loss_fnä¸­keysé¡ºåºä¸€è‡´ï¼ˆä½¿ç”¨sortedï¼‰")
        else:
            print(f"   âŒ group_loss_fnä¸­keysé¡ºåºä¸ä¸€è‡´ï¼")
            print(f"      æ¨¡å‹1: {keys1_group}")
            print(f"      æ¨¡å‹2: {keys2_group}")
    
    # æ£€æŸ¥å®é™…è®­ç»ƒæ—¶çš„forwardï¼ˆå¤šä¸ªbatchï¼‰
    print(f"\nğŸ” æ£€æŸ¥å®é™…è®­ç»ƒæ—¶çš„forwardï¼ˆè®­ç»ƒæ¨¡å¼ï¼Œå¤šä¸ªbatchï¼‰:")
    
    # é‡ç½®æ¨¡å‹çŠ¶æ€
    if hasattr(model1, 'alignment_features'):
        model1.alignment_features = []
    if hasattr(model2, 'alignment_features'):
        model2.alignment_features = []
    
    # è¿è¡Œå¤šä¸ªbatchï¼Œæ£€æŸ¥alignment_featuresçš„ç´¯ç§¯é¡ºåº
    for batch_idx in range(5):
        seed_torch(seed + 30000 + batch_idx)
        model1.train()
        results1_train = model1(data.copy(), label)
        
        seed_torch(seed + 30000 + batch_idx)
        model2.train()
        results2_train = model2(data.copy(), label)
        
        # æ£€æŸ¥alignment_featuresä¸­æ¯ä¸ªå­—å…¸çš„keysé¡ºåº
        if (hasattr(model1, 'alignment_features') and len(model1.alignment_features) > batch_idx and
            hasattr(model2, 'alignment_features') and len(model2.alignment_features) > batch_idx):
            keys1_batch = list(model1.alignment_features[batch_idx].keys())
            keys2_batch = list(model2.alignment_features[batch_idx].keys())
            
            if keys1_batch != keys2_batch:
                print(f"   âŒ Batch {batch_idx+1} - alignment_features keysé¡ºåºä¸ä¸€è‡´ï¼")
                print(f"      æ¨¡å‹1: {keys1_batch}")
                print(f"      æ¨¡å‹2: {keys2_batch}")
            else:
                print(f"   âœ… Batch {batch_idx+1} - alignment_features keysé¡ºåºä¸€è‡´: {keys1_batch}")
    
    # æ£€æŸ¥group_loss_fnä¸­çš„keysé¡ºåºï¼ˆä½¿ç”¨sortedï¼‰
    if hasattr(model1, 'group_loss_fn') and hasattr(model1, 'alignment_features') and len(model1.alignment_features) > 0:
        keys1_sorted = sorted(model1.alignment_features[0].keys())
        keys2_sorted = sorted(model2.alignment_features[0].keys())
        print(f"\n   æ¨¡å‹1 - sorted(alignment_features[0].keys()): {keys1_sorted}")
        print(f"   æ¨¡å‹2 - sorted(alignment_features[0].keys()): {keys2_sorted}")
        
        if keys1_sorted == keys2_sorted:
            print(f"   âœ… group_loss_fnä¸­sorted keysé¡ºåºä¸€è‡´")
        else:
            print(f"   âŒ group_loss_fnä¸­sorted keysé¡ºåºä¸ä¸€è‡´ï¼")
    
    # æ£€æŸ¥features_dictåœ¨forwardè¿‡ç¨‹ä¸­çš„å®é™…é¡ºåº
    print(f"\nğŸ” æ£€æŸ¥å®é™…forwardè¿‡ç¨‹ä¸­features_dictçš„é¡ºåºï¼ˆé€šè¿‡hookï¼‰:")
    
    # ä½¿ç”¨hookæ•è·forwardè¿‡ç¨‹ä¸­çš„features_dict
    captured_features_dict1 = []
    captured_features_dict2 = []
    
    def capture_features_dict1(module, input, output):
        # è¿™é‡Œæˆ‘ä»¬éœ€è¦åœ¨forwardä¸­æ•è·ï¼Œä½†hookå¯èƒ½ä¸å¤Ÿ
        pass
    
    # å®é™…è¿è¡Œforwardï¼Œæ‰‹åŠ¨æ£€æŸ¥
    print(f"   æ‰‹åŠ¨æ£€æŸ¥forwardè¿‡ç¨‹ä¸­features_dictçš„æ„å»ºé¡ºåº:")
    
    seed_torch(seed + 40000)
    input_data1, modalities_used_in_model1_forward = model1._process_input_data(data.copy())
    print(f"   æ¨¡å‹1 - modalities_used_in_modelé¡ºåº: {list(modalities_used_in_model1_forward)}")
    
    features_dict1_forward = {}
    for channel in modalities_used_in_model1_forward:
        if channel == 'wsi=features':
            features_dict1_forward[channel] = torch.randn(1, 128)
        elif channel == 'tma=features':
            features_dict1_forward[channel] = torch.randn(1, 128)
        else:
            features_dict1_forward[channel] = torch.randn(1, 128)
    
    print(f"   æ¨¡å‹1 - features_dictæ„å»ºé¡ºåº: {list(features_dict1_forward.keys())}")
    
    seed_torch(seed + 40000)
    input_data2, modalities_used_in_model2_forward = model2._process_input_data(data.copy())
    print(f"   æ¨¡å‹2 - modalities_used_in_modelé¡ºåº: {list(modalities_used_in_model2_forward)}")
    
    features_dict2_forward = {}
    for channel in modalities_used_in_model2_forward:
        if channel == 'wsi=features':
            features_dict2_forward[channel] = torch.randn(1, 128)
        elif channel == 'tma=features':
            features_dict2_forward[channel] = torch.randn(1, 128)
        else:
            features_dict2_forward[channel] = torch.randn(1, 128)
    
    print(f"   æ¨¡å‹2 - features_dictæ„å»ºé¡ºåº: {list(features_dict2_forward.keys())}")
    
    if list(features_dict1_forward.keys()) != list(features_dict2_forward.keys()):
        print(f"   âŒ features_dictæ„å»ºé¡ºåºä¸ä¸€è‡´ï¼")
        print(f"      æ¨¡å‹1: {list(features_dict1_forward.keys())}")
        print(f"      æ¨¡å‹2: {list(features_dict2_forward.keys())}")
    else:
        print(f"   âœ… features_dictæ„å»ºé¡ºåºä¸€è‡´")
    
    # æ£€æŸ¥align_forwardåfeatures_dictçš„é¡ºåº
    if hasattr(model1, 'align_forward'):
        seed_torch(seed + 40000)
        aligned_features1 = model1.align_forward(features_dict1_forward)
        print(f"   æ¨¡å‹1 - align_forwardå keys: {list(aligned_features1.keys())}")
        
        seed_torch(seed + 40000)
        aligned_features2 = model2.align_forward(features_dict2_forward)
        print(f"   æ¨¡å‹2 - align_forwardå keys: {list(aligned_features2.keys())}")
        
        if list(aligned_features1.keys()) != list(aligned_features2.keys()):
            print(f"   âŒ align_forwardå keysé¡ºåºä¸ä¸€è‡´ï¼")
        else:
            print(f"   âœ… align_forwardå keysé¡ºåºä¸€è‡´")
    
    # æ€»ç»“
    print(f"\n{'='*60}")
    print("è¯Šæ–­æ€»ç»“")
    print(f"{'='*60}")
    print(f"å¯èƒ½çš„é—®é¢˜:")
    print(f"1. modalities_used_in_modelæ˜¯setï¼Œéå†é¡ºåºä¸ç¡®å®š")
    print(f"2. features_dict.keys()çš„é¡ºåºå¯èƒ½ä¸åŒï¼ˆå¦‚æœæ„å»ºé¡ºåºä¸åŒï¼‰")
    print(f"3. random.sample(list(features_dict.keys()), ...)çš„é¡ºåºä¾èµ–keysçš„é¡ºåº")
    print(f"4. for modality in features_dict.keys()çš„é¡ºåºå¯èƒ½ä¸åŒ")
    print(f"5. alignment_featuresä¸­å­—å…¸çš„keysé¡ºåºå¯èƒ½ä¸åŒ")
    print(f"{'='*60}")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='è¯Šæ–­è®­ç»ƒä¸ä¸€è‡´çš„åŸå› ')
    parser.add_argument('--results_dir', type=str, required=True,
                        help='ç»“æœç›®å½•è·¯å¾„')
    parser.add_argument('--fold_idx', type=int, default=0,
                        help='foldç´¢å¼• (default: 0)')
    
    args = parser.parse_args()
    
    try:
        diagnose_training_inconsistency(
            args.results_dir,
            args.fold_idx
        )
    except Exception as e:
        print(f"âŒ è¯Šæ–­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

