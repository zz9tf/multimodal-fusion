#!/usr/bin/env python3
"""
è¯Šæ–­setè½¬listå¯¼è‡´çš„ä¸ä¸€è‡´é—®é¢˜
é‡ç‚¹æ£€æŸ¥modalities_used_in_modelæ˜¯setï¼Œéå†é¡ºåºä¸ç¡®å®šçš„é—®é¢˜
"""

import os
import sys
import torch
import numpy as np
import json
from pathlib import Path
from torch.utils.data import Subset

# æ·»åŠ é¡¹ç›®è·¯å¾„
root_dir = '/home/zheng/zheng/multimodal-fusion/downstream_survival'
sys.path.append(root_dir)

from trainer import Trainer, get_split_loader
from main import seed_torch, create_k_fold_splits
from datasets.multimodal_dataset import MultimodalDataset


def diagnose_set_to_list_issue(results_dir: str, fold_idx: int = 0):
    """
    è¯Šæ–­setè½¬listå¯¼è‡´çš„ä¸ä¸€è‡´é—®é¢˜
    """
    results_dir = Path(results_dir)
    configs_file = results_dir / 'configs_svd_random_clam_detach.json'
    
    if not configs_file.exists():
        config_files = list(results_dir.glob('configs_*.json'))
        if config_files:
            configs_file = config_files[0]
        else:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶: {results_dir}")
    
    # åŠ è½½é…ç½®
    with open(configs_file, 'r') as f:
        configs = json.load(f)
    
    print(f"ğŸ“‹ åŠ è½½é…ç½®æ–‡ä»¶: {configs_file}")
    
    # è·å–seed
    seed = configs['experiment_config'].get('seed', 5678)
    print(f"ğŸŒ± ä½¿ç”¨éšæœºç§å­: {seed}")
    
    # åŠ è½½æ•°æ®é›†
    experiment_config = configs['experiment_config']
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    dataset = MultimodalDataset(
        csv_path=experiment_config['csv_path'],
        data_root_dir=experiment_config['data_root_dir'],
        channels=experiment_config['target_channels'],
        align_channels={},
        alignment_model_path=experiment_config['alignment_model_path'],
        device=device,
        print_info=False
    )
    
    # åˆ›å»ºk-foldåˆ†å‰²
    splits = create_k_fold_splits(dataset, k=10, seed=seed, fixed_test_split=None)
    split = splits[fold_idx]
    train_idx = split['train']
    train_dataset = Subset(dataset, train_idx)
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = Trainer(
        configs=configs,
        log_dir=str(results_dir / 'training_logs')
    )
    
    # åˆå§‹åŒ–ä¸¤ä¸ªæ¨¡å‹
    seed_torch(seed)
    model1 = trainer._init_model()
    
    seed_torch(seed)
    model2 = trainer._init_model()
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    seed_torch(seed)
    train_loader = get_split_loader(train_dataset, training=True, weighted=True, batch_size=1)
    train_loader_list = list(train_loader)
    
    print(f"\n{'='*60}")
    print("è¯Šæ–­setè½¬listå¯¼è‡´çš„ä¸ä¸€è‡´é—®é¢˜")
    print(f"{'='*60}")
    
    # è·å–ç¬¬ä¸€ä¸ªbatch
    data, label = train_loader_list[0]
    label = label.to(device)
    for channel in data:
        data[channel] = data[channel].to(device)
    
    print(f"\nğŸ“Š ç¬¬ä¸€ä¸ªbatchçš„æ•°æ®:")
    print(f"   channels: {list(data.keys())}")
    
    # æ£€æŸ¥å¤šæ¬¡è°ƒç”¨_process_input_dataè¿”å›çš„modalities_used_in_modelé¡ºåº
    print(f"\nğŸ” æ£€æŸ¥å¤šæ¬¡è°ƒç”¨ _process_input_data è¿”å›çš„ modalities_used_in_model é¡ºåº:")
    
    all_orders = []
    for i in range(10):
        seed_torch(seed + 10000 + i)
        input_data, modalities_used_in_model = model1._process_input_data(data.copy())
        order = list(modalities_used_in_model)
        all_orders.append(order)
        print(f"   è°ƒç”¨ {i+1}: {order}")
    
    # æ£€æŸ¥é¡ºåºæ˜¯å¦ä¸€è‡´
    if len(set(tuple(order) for order in all_orders)) == 1:
        print(f"   âœ… æ‰€æœ‰è°ƒç”¨çš„é¡ºåºä¸€è‡´")
    else:
        print(f"   âŒ é¡ºåºä¸ä¸€è‡´ï¼")
        unique_orders = set(tuple(order) for order in all_orders)
        print(f"      å‘ç° {len(unique_orders)} ç§ä¸åŒçš„é¡ºåº")
        for idx, order in enumerate(unique_orders):
            print(f"      é¡ºåº {idx+1}: {list(order)}")
    
    # æ£€æŸ¥features_dictçš„æ„å»ºé¡ºåº
    print(f"\nğŸ” æ£€æŸ¥ features_dict çš„æ„å»ºé¡ºåºï¼ˆåŸºäº modalities_used_in_model çš„éå†é¡ºåºï¼‰:")
    
    all_features_dict_orders = []
    for i in range(10):
        seed_torch(seed + 20000 + i)
        input_data, modalities_used_in_model = model1._process_input_data(data.copy())
        
        # æ¨¡æ‹Ÿfeatures_dictçš„æ„å»ºè¿‡ç¨‹
        features_dict = {}
        for channel in modalities_used_in_model:  # è¿™é‡Œéå†setï¼Œé¡ºåºä¸ç¡®å®š
            if channel == 'wsi=features':
                features_dict[channel] = torch.randn(1, 128)
            elif channel == 'tma=features':
                features_dict[channel] = torch.randn(1, 128)
            else:
                features_dict[channel] = torch.randn(1, 128)
        
        order = list(features_dict.keys())
        all_features_dict_orders.append(order)
        print(f"   è°ƒç”¨ {i+1}: {order}")
    
    # æ£€æŸ¥é¡ºåºæ˜¯å¦ä¸€è‡´
    if len(set(tuple(order) for order in all_features_dict_orders)) == 1:
        print(f"   âœ… æ‰€æœ‰è°ƒç”¨çš„features_dict keysé¡ºåºä¸€è‡´")
    else:
        print(f"   âŒ features_dict keysé¡ºåºä¸ä¸€è‡´ï¼")
        unique_orders = set(tuple(order) for order in all_features_dict_orders)
        print(f"      å‘ç° {len(unique_orders)} ç§ä¸åŒçš„é¡ºåº")
        for idx, order in enumerate(unique_orders):
            print(f"      é¡ºåº {idx+1}: {list(order)}")
    
    # æ£€æŸ¥random.sampleçš„ç»“æœ
    print(f"\nğŸ” æ£€æŸ¥ random.sample(list(features_dict.keys()), ...) çš„ç»“æœ:")
    
    all_random_sample_results = []
    for i in range(10):
        seed_torch(seed + 30000 + i)
        input_data, modalities_used_in_model = model1._process_input_data(data.copy())
        
        # æ¨¡æ‹Ÿfeatures_dictçš„æ„å»ºè¿‡ç¨‹
        features_dict = {}
        for channel in modalities_used_in_model:
            if channel == 'wsi=features':
                features_dict[channel] = torch.randn(1, 128)
            elif channel == 'tma=features':
                features_dict[channel] = torch.randn(1, 128)
            else:
                features_dict[channel] = torch.randn(1, 128)
        
        # æ¨¡æ‹Ÿrandom.sample
        import random
        keys_list = list(features_dict.keys())
        n = random.randint(1, len(keys_list) - 1)
        drop_modality = random.sample(keys_list, n)
        
        result = {
            'keys_list': keys_list,
            'n': n,
            'drop_modality': sorted(drop_modality)  # æ’åºä»¥ä¾¿æ¯”è¾ƒ
        }
        all_random_sample_results.append(result)
        print(f"   è°ƒç”¨ {i+1}: keys_list={keys_list}, n={n}, drop_modality={sorted(drop_modality)}")
    
    # æ£€æŸ¥keys_listæ˜¯å¦ä¸€è‡´
    keys_lists = [result['keys_list'] for result in all_random_sample_results]
    if len(set(tuple(keys) for keys in keys_lists)) == 1:
        print(f"   âœ… æ‰€æœ‰è°ƒç”¨çš„keys_listé¡ºåºä¸€è‡´")
    else:
        print(f"   âŒ keys_listé¡ºåºä¸ä¸€è‡´ï¼")
        unique_keys_lists = set(tuple(keys) for keys in keys_lists)
        print(f"      å‘ç° {len(unique_keys_lists)} ç§ä¸åŒçš„keys_listé¡ºåº")
    
    # æ£€æŸ¥drop_modalityæ˜¯å¦ä¸€è‡´ï¼ˆå³ä½¿keys_listé¡ºåºä¸åŒï¼Œå¦‚æœrandom seedç›¸åŒï¼Œdrop_modalityåº”è¯¥ä¸€è‡´ï¼‰
    drop_modalities = [result['drop_modality'] for result in all_random_sample_results]
    if len(set(tuple(drop) for drop in drop_modalities)) == 1:
        print(f"   âœ… æ‰€æœ‰è°ƒç”¨çš„drop_modalityä¸€è‡´ï¼ˆå³ä½¿keys_listé¡ºåºä¸åŒï¼‰")
    else:
        print(f"   âŒ drop_modalityä¸ä¸€è‡´ï¼")
        unique_drop_modalities = set(tuple(drop) for drop in drop_modalities)
        print(f"      å‘ç° {len(unique_drop_modalities)} ç§ä¸åŒçš„drop_modality")
    
    # æ£€æŸ¥ä¸¤ä¸ªæ¨¡å‹åœ¨ç›¸åŒseedä¸‹çš„è¡Œä¸º
    print(f"\nğŸ” æ£€æŸ¥ä¸¤ä¸ªæ¨¡å‹åœ¨ç›¸åŒseedä¸‹çš„è¡Œä¸º:")
    
    seed_torch(seed + 40000)
    input_data1, modalities_used_in_model1 = model1._process_input_data(data.copy())
    features_dict1 = {}
    for channel in modalities_used_in_model1:
        if channel == 'wsi=features':
            features_dict1[channel] = torch.randn(1, 128)
        elif channel == 'tma=features':
            features_dict1[channel] = torch.randn(1, 128)
        else:
            features_dict1[channel] = torch.randn(1, 128)
    
    seed_torch(seed + 40000)
    input_data2, modalities_used_in_model2 = model2._process_input_data(data.copy())
    features_dict2 = {}
    for channel in modalities_used_in_model2:
        if channel == 'wsi=features':
            features_dict2[channel] = torch.randn(1, 128)
        elif channel == 'tma=features':
            features_dict2[channel] = torch.randn(1, 128)
        else:
            features_dict2[channel] = torch.randn(1, 128)
    
    keys1 = list(features_dict1.keys())
    keys2 = list(features_dict2.keys())
    
    print(f"   æ¨¡å‹1 - modalities_used_in_modelé¡ºåº: {list(modalities_used_in_model1)}")
    print(f"   æ¨¡å‹2 - modalities_used_in_modelé¡ºåº: {list(modalities_used_in_model2)}")
    print(f"   æ¨¡å‹1 - features_dict keysé¡ºåº: {keys1}")
    print(f"   æ¨¡å‹2 - features_dict keysé¡ºåº: {keys2}")
    
    if keys1 == keys2:
        print(f"   âœ… ä¸¤ä¸ªæ¨¡å‹çš„features_dict keysé¡ºåºä¸€è‡´")
    else:
        print(f"   âŒ ä¸¤ä¸ªæ¨¡å‹çš„features_dict keysé¡ºåºä¸ä¸€è‡´ï¼")
        print(f"      è¿™æ˜¯å¯¼è‡´è®­ç»ƒä¸ä¸€è‡´çš„æ ¹æœ¬åŸå› ï¼")
    
    # æ£€æŸ¥random.sampleåœ¨ä¸¤ä¸ªæ¨¡å‹ä¸Šçš„ç»“æœ
    import random
    seed_torch(seed + 40000)
    n1 = random.randint(1, len(keys1) - 1)
    drop1 = random.sample(keys1, n1)
    
    seed_torch(seed + 40000)
    n2 = random.randint(1, len(keys2) - 1)
    drop2 = random.sample(keys2, n2)
    
    print(f"\n   æ¨¡å‹1 - random.sample({keys1}, {n1}): {sorted(drop1)}")
    print(f"   æ¨¡å‹2 - random.sample({keys2}, {n2}): {sorted(drop2)}")
    
    if sorted(drop1) == sorted(drop2):
        print(f"   âœ… random.sampleç»“æœä¸€è‡´ï¼ˆå³ä½¿keysé¡ºåºä¸åŒï¼‰")
    else:
        print(f"   âŒ random.sampleç»“æœä¸ä¸€è‡´ï¼")
        print(f"      å³ä½¿random seedç›¸åŒï¼Œä½†ç”±äºkeysé¡ºåºä¸åŒï¼Œrandom.sampleçš„ç»“æœä¹Ÿä¸åŒï¼")
    
    # æ€»ç»“
    print(f"\n{'='*60}")
    print("è¯Šæ–­æ€»ç»“")
    print(f"{'='*60}")
    print(f"é—®é¢˜æ ¹æº:")
    print(f"1. modalities_used_in_model æ˜¯ set()ï¼Œéå†é¡ºåºä¸ç¡®å®š")
    print(f"2. for channel in modalities_used_in_model: æ„å»º features_dict æ—¶ï¼Œkeysé¡ºåºä¸ç¡®å®š")
    print(f"3. random.sample(list(features_dict.keys()), ...) ä¾èµ– keys çš„é¡ºåº")
    print(f"4. å³ä½¿ random seed ç›¸åŒï¼Œå¦‚æœ keys é¡ºåºä¸åŒï¼Œrandom.sample çš„ç»“æœä¹Ÿä¼šä¸åŒ")
    print(f"5. è¿™å¯¼è‡´ä¸¤ä¸ªæ¨¡å‹åœ¨ç›¸åŒ seed ä¸‹ï¼Œforward çš„ç»“æœä¸åŒï¼Œè¿›è€Œå¯¼è‡´è®­ç»ƒä¸ä¸€è‡´")
    print(f"{'='*60}")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='è¯Šæ–­setè½¬listå¯¼è‡´çš„ä¸ä¸€è‡´é—®é¢˜')
    parser.add_argument('--results_dir', type=str, required=True,
                        help='ç»“æœç›®å½•è·¯å¾„')
    parser.add_argument('--fold_idx', type=int, default=0,
                        help='foldç´¢å¼• (default: 0)')
    
    args = parser.parse_args()
    
    try:
        diagnose_set_to_list_issue(
            args.results_dir,
            args.fold_idx
        )
    except Exception as e:
        print(f"âŒ è¯Šæ–­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)



