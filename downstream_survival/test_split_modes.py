#!/usr/bin/env python3
"""
æµ‹è¯•æ•°æ®é›†åˆ†å‰²æ¨¡å¼çš„æ­£ç¡®æ€§
éªŒè¯éšæœºåˆ†å‰²å’Œå›ºå®šæµ‹è¯•é›†åˆ†å‰²ä¸¤ç§æ¨¡å¼
"""

import os
import sys
import json
import numpy as np
import pandas as pd
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
root_dir = '/home/zheng/zheng/multimodal-fusion/downstream_survival'
sys.path.append(root_dir)

# å¯¼å…¥main.pyä¸­çš„å‡½æ•°
import importlib.util
spec = importlib.util.spec_from_file_location("main_module", "/home/zheng/zheng/multimodal-fusion/downstream_survival/main.py")
main_module = importlib.util.module_from_spec(spec)

# åªå¯¼å…¥æˆ‘ä»¬éœ€è¦çš„å‡½æ•°ï¼Œé¿å…æ‰§è¡Œmain.pyçš„å‚æ•°è§£æéƒ¨åˆ†
def load_dataset_split(dataset_split_path):
    """
    ä»JSONæ–‡ä»¶åŠ è½½æ•°æ®é›†åˆ†å‰²ä¿¡æ¯
    
    Args:
        dataset_split_path (str): æ•°æ®é›†åˆ†å‰²JSONæ–‡ä»¶è·¯å¾„
        
    Returns:
        dict: åŒ…å«train/teståˆ†å‰²çš„å­—å…¸ï¼Œæ ¼å¼ä¸º {'train': [patient_ids], 'test': [patient_ids]}
    """
    if not os.path.exists(dataset_split_path):
        raise FileNotFoundError(f"æ•°æ®é›†åˆ†å‰²æ–‡ä»¶ä¸å­˜åœ¨: {dataset_split_path}")
    
    with open(dataset_split_path, 'r') as f:
        split_data = json.load(f)
    
    # å°†JSONæ•°æ®è½¬æ¢ä¸ºtrain/teståˆ†å‰²
    train_patients = []
    test_patients = []
    
    for item in split_data:
        patient_id = item['patient_id']
        dataset_type = item['dataset']
        
        if dataset_type == 'training':
            train_patients.append(patient_id)
        elif dataset_type == 'test':
            test_patients.append(patient_id)
    
    return {
        'train': train_patients,
        'test': test_patients
    }

def create_k_fold_splits(dataset, k=10, seed=42, fixed_test_split=None):
    """
    åˆ›å»ºk-foldäº¤å‰éªŒè¯åˆ†å‰²
    
    Args:
        dataset: æ•°æ®é›†å¯¹è±¡
        k (int): foldæ•°é‡
        seed (int): éšæœºç§å­
        fixed_test_split (dict, optional): å›ºå®šçš„æµ‹è¯•é›†åˆ†å‰²ï¼Œæ ¼å¼ä¸º {'train': [patient_ids], 'test': [patient_ids]}
    
    Returns:
        list: åŒ…å«æ¯ä¸ªfoldçš„train/val/testç´¢å¼•çš„åˆ—è¡¨
    """
    from sklearn.model_selection import StratifiedKFold
    
    # è·å–æ‰€æœ‰æ ·æœ¬çš„æ ‡ç­¾å’Œæ‚£è€…ID
    labels = []
    patient_ids = []
    
    for i in range(len(dataset)):
        # ä»æ•°æ®é›†ä¸­è·å–æ ‡ç­¾
        if hasattr(dataset, 'get_label'):
            label = dataset.get_label(i)
        else:
            # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼Œè·å–label
            sample = dataset[i]
            if isinstance(sample, dict) and 'label' in sample:
                label = sample['label']
            else:
                # å‡è®¾æ˜¯å…ƒç»„æ ¼å¼ (data, label)
                _, label = sample
        labels.append(label)
        
        # è·å–æ‚£è€…IDï¼ˆå‡è®¾æ•°æ®é›†æœ‰get_patient_idæ–¹æ³•ï¼Œæˆ–è€…ä»æ ·æœ¬ä¸­è·å–ï¼‰
        if hasattr(dataset, 'get_patient_id'):
            patient_id = dataset.get_patient_id(i)
        elif isinstance(sample, dict) and 'patient_id' in sample:
            patient_id = sample['patient_id']
        else:
            # å¦‚æœæ²¡æœ‰æ‚£è€…IDï¼Œä½¿ç”¨ç´¢å¼•ä½œä¸ºID
            patient_id = str(i)
        patient_ids.append(patient_id)
    
    labels = np.array(labels)
    patient_ids = np.array(patient_ids)
    
    splits = []
    
    if fixed_test_split is not None:
        # ä½¿ç”¨å›ºå®šçš„æµ‹è¯•é›†åˆ†å‰²
        print(f"ğŸ”’ ä½¿ç”¨å›ºå®šæµ‹è¯•é›†åˆ†å‰²")
        print(f"ğŸ“Š å›ºå®šè®­ç»ƒé›†æ‚£è€…æ•°: {len(fixed_test_split['train'])}")
        print(f"ğŸ“Š å›ºå®šæµ‹è¯•é›†æ‚£è€…æ•°: {len(fixed_test_split['test'])}")
        
        # æ‰¾åˆ°æµ‹è¯•é›†å¯¹åº”çš„ç´¢å¼•
        test_indices = []
        for test_patient_id in fixed_test_split['test']:
            test_idx = np.where(patient_ids == test_patient_id)[0]
            if len(test_idx) > 0:
                test_indices.extend(test_idx)
        
        test_indices = np.array(test_indices)
        
        # æ‰¾åˆ°è®­ç»ƒé›†å¯¹åº”çš„ç´¢å¼•
        train_indices = []
        for train_patient_id in fixed_test_split['train']:
            train_idx = np.where(patient_ids == train_patient_id)[0]
            if len(train_idx) > 0:
                train_indices.extend(train_idx)
        
        train_indices = np.array(train_indices)
        
        # åœ¨è®­ç»ƒé›†ä¸Šè¿›è¡Œk-foldäº¤å‰éªŒè¯
        train_labels = labels[train_indices]
        
        # åˆ›å»ºåˆ†å±‚k-foldåˆ†å‰²
        skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)
        
        for fold_idx, (fold_train_idx, fold_val_idx) in enumerate(skf.split(train_indices, train_labels)):
            # è½¬æ¢ä¸ºå®é™…ç´¢å¼•
            actual_train_idx = train_indices[fold_train_idx]
            actual_val_idx = train_indices[fold_val_idx]
            
            splits.append({
                'train': actual_train_idx,
                'val': actual_val_idx,
                'test': test_indices  # æµ‹è¯•é›†å§‹ç»ˆç›¸åŒ
            })
    else:
        # åŸå§‹çš„åˆ†å‰²æ–¹å¼ï¼šå°†æµ‹è¯•é›†è¿›ä¸€æ­¥åˆ†ä¸ºéªŒè¯é›†å’Œæµ‹è¯•é›†
        print(f"ğŸ”„ ä½¿ç”¨ä¼ ç»Ÿk-foldåˆ†å‰²")
        
        # åˆ›å»ºåˆ†å±‚k-foldåˆ†å‰²
        skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)
        
        for fold_idx, (train_idx, test_idx) in enumerate(skf.split(range(len(dataset)), labels)):
            # å°†æµ‹è¯•é›†è¿›ä¸€æ­¥åˆ†ä¸ºéªŒè¯é›†å’Œæµ‹è¯•é›†
            test_labels = labels[test_idx]
            val_test_skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=seed)
            val_idx, test_idx_final = next(val_test_skf.split(test_idx, test_labels))
            
            # è½¬æ¢ä¸ºå®é™…ç´¢å¼•
            val_idx = test_idx[val_idx]
            test_idx_final = test_idx[test_idx_final]
            
            splits.append({
                'train': train_idx,
                'val': val_idx, 
                'test': test_idx_final
            })
    
    return splits

class MockDataset:
    """æ¨¡æ‹Ÿæ•°æ®é›†ç±»ï¼Œç”¨äºæµ‹è¯•"""
    
    def __init__(self, patient_ids, labels):
        self.patient_ids = patient_ids
        self.labels = labels
    
    def __len__(self):
        return len(self.patient_ids)
    
    def __getitem__(self, idx):
        return {
            'patient_id': self.patient_ids[idx],
            'label': self.labels[idx]
        }
    
    def get_patient_id(self, idx):
        return self.patient_ids[idx]
    
    def get_label(self, idx):
        return self.labels[idx]

def create_test_dataset():
    """åˆ›å»ºæµ‹è¯•æ•°æ®é›†"""
    # åˆ›å»º763ä¸ªæ‚£è€…çš„æ•°æ®
    patient_ids = [f"{i:03d}" for i in range(1, 764)]  # 001-763
    
    # åˆ›å»ºæ ‡ç­¾ï¼ˆå‡è®¾70%ä¸ºç±»åˆ«0ï¼Œ30%ä¸ºç±»åˆ«1ï¼‰
    np.random.seed(42)
    labels = np.random.choice([0, 1], size=763, p=[0.7, 0.3])
    
    return MockDataset(patient_ids, labels)

def test_load_dataset_split():
    """æµ‹è¯•åŠ è½½æ•°æ®é›†åˆ†å‰²åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•1: åŠ è½½æ•°æ®é›†åˆ†å‰²åŠŸèƒ½")
    print("-" * 40)
    
    dataset_split_path = "/home/zheng/zheng/multimodal-fusion/downstream_survival/dataset_csv/dataset_split_in.json"
    
    try:
        split_data = load_dataset_split(dataset_split_path)
        
        print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®é›†åˆ†å‰²")
        print(f"ğŸ“Š è®­ç»ƒé›†æ‚£è€…æ•°: {len(split_data['train'])}")
        print(f"ğŸ“Š æµ‹è¯•é›†æ‚£è€…æ•°: {len(split_data['test'])}")
        print(f"ğŸ“Š æ€»æ‚£è€…æ•°: {len(split_data['train']) + len(split_data['test'])}")
        
        # éªŒè¯æ‚£è€…IDæ ¼å¼
        train_sample = split_data['train'][:5]
        test_sample = split_data['test'][:5]
        print(f"ğŸ“‹ è®­ç»ƒé›†æ ·æœ¬: {train_sample}")
        print(f"ğŸ“‹ æµ‹è¯•é›†æ ·æœ¬: {test_sample}")
        
        return True  # è¿”å›Trueè¡¨ç¤ºæµ‹è¯•é€šè¿‡
        
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®é›†åˆ†å‰²å¤±è´¥: {e}")
        return False

def test_random_split_mode():
    """æµ‹è¯•éšæœºåˆ†å‰²æ¨¡å¼"""
    print("\nğŸ§ª æµ‹è¯•2: éšæœºåˆ†å‰²æ¨¡å¼")
    print("-" * 40)
    
    dataset = create_test_dataset()
    
    try:
        splits = create_k_fold_splits(dataset, k=5, seed=42, fixed_test_split=None)
        
        print(f"âœ… æˆåŠŸåˆ›å»º {len(splits)} ä¸ªfold")
        
        # æ£€æŸ¥æ¯ä¸ªfoldçš„ç»“æ„
        for i, split in enumerate(splits):
            train_size = len(split['train'])
            val_size = len(split['val'])
            test_size = len(split['test'])
            total_size = train_size + val_size + test_size
            
            print(f"ğŸ“Š Fold {i+1}: Train={train_size}, Val={val_size}, Test={test_size}, Total={total_size}")
            
            # éªŒè¯ç´¢å¼•ä¸é‡å¤
            all_indices = set(split['train']) | set(split['val']) | set(split['test'])
            if len(all_indices) != total_size:
                print(f"âŒ Fold {i+1}: ç´¢å¼•é‡å¤!")
                return False
        
        # æ£€æŸ¥ä¸åŒfoldçš„æµ‹è¯•é›†æ˜¯å¦ä¸åŒ
        test_sets = [set(split['test']) for split in splits]
        all_different = all(len(set.intersection(*test_sets[i:i+2])) == 0 
                           for i in range(len(test_sets)-1))
        
        if all_different:
            print("âœ… ä¸åŒfoldçš„æµ‹è¯•é›†ç¡®å®ä¸åŒ")
        else:
            print("âš ï¸  ä¸åŒfoldçš„æµ‹è¯•é›†æœ‰é‡å ")
        
        return True
        
    except Exception as e:
        print(f"âŒ éšæœºåˆ†å‰²æ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_fixed_split_mode():
    """æµ‹è¯•å›ºå®šæµ‹è¯•é›†åˆ†å‰²æ¨¡å¼"""
    print("\nğŸ§ª æµ‹è¯•3: å›ºå®šæµ‹è¯•é›†åˆ†å‰²æ¨¡å¼")
    print("-" * 40)
    
    # åŠ è½½çœŸå®çš„åˆ†å‰²æ•°æ®
    dataset_split_path = "/home/zheng/zheng/multimodal-fusion/downstream_survival/dataset_csv/dataset_split_in.json"
    
    try:
        fixed_test_split = load_dataset_split(dataset_split_path)
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®é›†ï¼ˆåªåŒ…å«åˆ†å‰²ä¸­çš„æ‚£è€…ï¼‰
        all_patients = fixed_test_split['train'] + fixed_test_split['test']
        
        # åˆ›å»ºæ ‡ç­¾ï¼ˆéšæœºç”Ÿæˆï¼Œç”¨äºæµ‹è¯•ï¼‰
        np.random.seed(42)
        labels = np.random.choice([0, 1], size=len(all_patients), p=[0.7, 0.3])
        
        dataset = MockDataset(all_patients, labels)
        
        splits = create_k_fold_splits(dataset, k=5, seed=42, fixed_test_split=fixed_test_split)
        
        print(f"âœ… æˆåŠŸåˆ›å»º {len(splits)} ä¸ªfold")
        
        # æ£€æŸ¥æ¯ä¸ªfoldçš„ç»“æ„
        test_sets_are_same = True
        for i, split in enumerate(splits):
            train_size = len(split['train'])
            val_size = len(split['val'])
            test_size = len(split['test'])
            
            print(f"ğŸ“Š Fold {i+1}: Train={train_size}, Val={val_size}, Test={test_size}")
            
            # æ£€æŸ¥æµ‹è¯•é›†æ˜¯å¦ç›¸åŒ
            if i == 0:
                first_test_set = set(split['test'])
            else:
                current_test_set = set(split['test'])
                if first_test_set != current_test_set:
                    test_sets_are_same = False
        
        if test_sets_are_same:
            print("âœ… æ‰€æœ‰foldçš„æµ‹è¯•é›†éƒ½ç›¸åŒï¼ˆå›ºå®šæµ‹è¯•é›†ï¼‰")
        else:
            print("âŒ æµ‹è¯•é›†ä¸ä¸€è‡´!")
            return False
        
        # éªŒè¯æµ‹è¯•é›†å¤§å°
        expected_test_size = len(fixed_test_split['test'])
        actual_test_size = len(splits[0]['test'])
        
        if expected_test_size == actual_test_size:
            print(f"âœ… æµ‹è¯•é›†å¤§å°æ­£ç¡®: {actual_test_size}")
        else:
            print(f"âŒ æµ‹è¯•é›†å¤§å°ä¸åŒ¹é…: æœŸæœ›{expected_test_size}, å®é™…{actual_test_size}")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ å›ºå®šæµ‹è¯•é›†åˆ†å‰²æ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_patient_id_mapping():
    """æµ‹è¯•æ‚£è€…IDæ˜ å°„çš„æ­£ç¡®æ€§"""
    print("\nğŸ§ª æµ‹è¯•4: æ‚£è€…IDæ˜ å°„æ­£ç¡®æ€§")
    print("-" * 40)
    
    dataset_split_path = "/home/zheng/zheng/multimodal-fusion/downstream_survival/dataset_csv/dataset_split_in.json"
    
    try:
        fixed_test_split = load_dataset_split(dataset_split_path)
        
        # åˆ›å»ºåŒ…å«æ‰€æœ‰æ‚£è€…çš„æ¨¡æ‹Ÿæ•°æ®é›†
        all_patients = fixed_test_split['train'] + fixed_test_split['test']
        np.random.seed(42)
        labels = np.random.choice([0, 1], size=len(all_patients), p=[0.7, 0.3])
        
        dataset = MockDataset(all_patients, labels)
        
        splits = create_k_fold_splits(dataset, k=3, seed=42, fixed_test_split=fixed_test_split)
        
        # æ£€æŸ¥ç¬¬ä¸€ä¸ªfoldçš„æµ‹è¯•é›†æ‚£è€…ID
        test_indices = splits[0]['test']
        test_patient_ids = [dataset.get_patient_id(idx) for idx in test_indices]
        
        print(f"ğŸ“‹ æµ‹è¯•é›†æ‚£è€…IDæ ·æœ¬: {test_patient_ids[:10]}")
        print(f"ğŸ“‹ æœŸæœ›çš„æµ‹è¯•é›†æ‚£è€…IDæ ·æœ¬: {fixed_test_split['test'][:10]}")
        
        # éªŒè¯æ˜ å°„æ˜¯å¦æ­£ç¡®
        expected_test_ids = set(fixed_test_split['test'])
        actual_test_ids = set(test_patient_ids)
        
        if expected_test_ids == actual_test_ids:
            print("âœ… æ‚£è€…IDæ˜ å°„æ­£ç¡®")
            return True
        else:
            print("âŒ æ‚£è€…IDæ˜ å°„é”™è¯¯")
            missing = expected_test_ids - actual_test_ids
            extra = actual_test_ids - expected_test_ids
            if missing:
                print(f"   ç¼ºå¤±çš„æ‚£è€…ID: {list(missing)[:5]}...")
            if extra:
                print(f"   å¤šä½™çš„æ‚£è€…ID: {list(extra)[:5]}...")
            return False
        
    except Exception as e:
        print(f"âŒ æ‚£è€…IDæ˜ å°„æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•æ•°æ®é›†åˆ†å‰²æ¨¡å¼")
    print("=" * 50)
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        test_load_dataset_split,
        test_random_split_mode,
        test_fixed_split_mode,
        test_patient_id_mapping
    ]
    
    results = []
    for test_func in tests:
        try:
            result = test_func()
            results.append(result if isinstance(result, bool) else False)
        except Exception as e:
            print(f"âŒ æµ‹è¯• {test_func.__name__} å‡ºç°å¼‚å¸¸: {e}")
            results.append(False)
    
    # æ€»ç»“æµ‹è¯•ç»“æœ
    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
    print("=" * 50)
    
    passed = sum(results)
    total = len(results)
    
    test_names = [
        "åŠ è½½æ•°æ®é›†åˆ†å‰²åŠŸèƒ½",
        "éšæœºåˆ†å‰²æ¨¡å¼",
        "å›ºå®šæµ‹è¯•é›†åˆ†å‰²æ¨¡å¼", 
        "æ‚£è€…IDæ˜ å°„æ­£ç¡®æ€§"
    ]
    
    for i, (name, result) in enumerate(zip(test_names, results)):
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{i+1}. {name}: {status}")
    
    print(f"\nğŸ¯ æ€»ä½“ç»“æœ: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼åˆ†å‰²æ¨¡å¼åŠŸèƒ½æ­£å¸¸ã€‚")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ã€‚")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
