# -*- coding: utf-8 -*-
"""
VAEè®­ç»ƒè„šæœ¬
è®­ç»ƒVAEæ¨¡å‹æ¥å‹ç¼©WSI embeddingsï¼Œåªä½¿ç”¨livingç—…äººçš„æ•°æ®
"""
import os
import sys
import argparse
import torch
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from datetime import datetime
from typing import Dict, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from models import VAE, Encoder, Decoder
from loss import vae_loss
from dataset import WSIVAEDataset


class VAETrainer:
    """
    VAEè®­ç»ƒå™¨ç±»
    """
    
    def __init__(self,
                 model: VAE,
                 train_loader: DataLoader,
                 val_loader: Optional[DataLoader] = None,
                 device: str = 'cuda',
                 learning_rate: float = 1e-4,
                 save_dir: str = './checkpoints',
                 log_dir: str = './logs'):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            model: VAEæ¨¡å‹
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨ï¼ˆå¯é€‰ï¼‰
            device: è®¾å¤‡
            learning_rate: å­¦ä¹ ç‡
            save_dir: æ¨¡å‹ä¿å­˜ç›®å½•
            log_dir: æ—¥å¿—ä¿å­˜ç›®å½•
        """
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        
        # ä¼˜åŒ–å™¨
        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)
        
        # ä¿å­˜å’Œæ—¥å¿—ç›®å½•
        self.save_dir = save_dir
        self.log_dir = log_dir
        os.makedirs(save_dir, exist_ok=True)
        os.makedirs(log_dir, exist_ok=True)
        
        # TensorBoard writer
        self.writer = SummaryWriter(log_dir=log_dir)
        
        # è®­ç»ƒå†å²
        self.train_history = {
            'loss': [],
            'recon_loss': [],
            'kld_loss': []
        }
        self.val_history = {
            'loss': [],
            'recon_loss': [],
            'kld_loss': []
        }
    
    def train_epoch(self, epoch: int) -> Dict[str, float]:
        """
        è®­ç»ƒä¸€ä¸ªepoch
        
        Args:
            epoch: å½“å‰epochç¼–å·
            
        Returns:
            è®­ç»ƒæŒ‡æ ‡å­—å…¸
        """
        self.model.train()
        total_loss = 0.0
        total_recon_loss = 0.0
        total_kld_loss = 0.0
        num_batches = 0
        
        for batch_idx, patch_features in enumerate(self.train_loader):
            # å°†patch featuresç§»åŠ¨åˆ°è®¾å¤‡
            # patch_featureså½¢çŠ¶: (batch_size, feature_dim)
            
            # ç¡®ä¿æ˜¯2Då¼ é‡ (batch_size, feature_dim)
            if patch_features.dim() == 1:
                patch_features = patch_features.unsqueeze(0)
            
            embeddings = patch_features.to(self.device)
            
            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            x_hat, z, mean, log_var = self.model(embeddings)
            
            # è®¡ç®—æŸå¤±ï¼ˆä½¿ç”¨KLDæŸå¤±ï¼Œç¬¦åˆè®ºæ–‡è¦æ±‚ï¼‰
            loss, recon_loss, kld_loss = vae_loss(
                x=embeddings,
                x_hat=x_hat,
                mean=mean,
                log_var=log_var
            )
            
            # åå‘ä¼ æ’­
            loss.backward()
            self.optimizer.step()
            
            # ç´¯è®¡æŸå¤±
            total_loss += loss.item()
            total_recon_loss += recon_loss.item()
            total_kld_loss += kld_loss.item()
            num_batches += 1
            
            # æ‰“å°è¿›åº¦
            if batch_idx % 10 == 0:
                print(f'Epoch {epoch}, Batch {batch_idx}/{len(self.train_loader)}, '
                      f'Loss: {loss.item():.4f}, Recon: {recon_loss.item():.4f}, '
                      f'KLD: {kld_loss.item():.4f}')
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_loss = total_loss / num_batches
        avg_recon_loss = total_recon_loss / num_batches
        avg_kld_loss = total_kld_loss / num_batches
        
        # è®°å½•åˆ°TensorBoard
        self.writer.add_scalar('Train/Loss', avg_loss, epoch)
        self.writer.add_scalar('Train/ReconLoss', avg_recon_loss, epoch)
        self.writer.add_scalar('Train/KLDLoss', avg_kld_loss, epoch)
        
        # æ›´æ–°å†å²
        self.train_history['loss'].append(avg_loss)
        self.train_history['recon_loss'].append(avg_recon_loss)
        self.train_history['kld_loss'] = self.train_history.get('kld_loss', [])
        self.train_history['kld_loss'].append(avg_kld_loss)
        
        return {
            'loss': avg_loss,
            'recon_loss': avg_recon_loss,
            'kld_loss': avg_kld_loss
        }
    
    def validate(self, epoch: int) -> Optional[Dict[str, float]]:
        """
        éªŒè¯æ¨¡å‹
        
        Args:
            epoch: å½“å‰epochç¼–å·
            
        Returns:
            éªŒè¯æŒ‡æ ‡å­—å…¸ï¼Œå¦‚æœval_loaderä¸ºNoneåˆ™è¿”å›None
        """
        if self.val_loader is None:
            return None
        
        self.model.eval()
        total_loss = 0.0
        total_recon_loss = 0.0
        total_kld_loss = 0.0
        num_batches = 0
        
        with torch.no_grad():
            for patch_features in self.val_loader:
                # ç¡®ä¿æ˜¯2Då¼ é‡ (batch_size, feature_dim)
                if patch_features.dim() == 1:
                    patch_features = patch_features.unsqueeze(0)
                
                embeddings = patch_features.to(self.device)
                
                # å‰å‘ä¼ æ’­
                x_hat, z, mean, log_var = self.model(embeddings)
                
                # è®¡ç®—æŸå¤±ï¼ˆä½¿ç”¨KLDæŸå¤±ï¼‰
                loss, recon_loss, kld_loss = vae_loss(
                    x=embeddings,
                    x_hat=x_hat,
                    mean=mean,
                    log_var=log_var
                )
                
                total_loss += loss.item()
                total_recon_loss += recon_loss.item()
                total_kld_loss += kld_loss.item()
                num_batches += 1
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_loss = total_loss / num_batches
        avg_recon_loss = total_recon_loss / num_batches
        avg_kld_loss = total_kld_loss / num_batches
        
        # è®°å½•åˆ°TensorBoard
        self.writer.add_scalar('Val/Loss', avg_loss, epoch)
        self.writer.add_scalar('Val/ReconLoss', avg_recon_loss, epoch)
        self.writer.add_scalar('Val/KLDLoss', avg_kld_loss, epoch)
        
        # æ›´æ–°å†å²
        self.val_history['loss'].append(avg_loss)
        self.val_history['recon_loss'].append(avg_recon_loss)
        self.val_history['kld_loss'] = self.val_history.get('kld_loss', [])
        self.val_history['kld_loss'].append(avg_kld_loss)
        
        return {
            'loss': avg_loss,
            'recon_loss': avg_recon_loss,
            'kld_loss': avg_kld_loss
        }
    
    def save_checkpoint(self, epoch: int, is_best: bool = False):
        """
        ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹
        
        Args:
            epoch: å½“å‰epochç¼–å·
            is_best: æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
        """
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'train_history': self.train_history,
            'val_history': self.val_history
        }
        
        # ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹
        checkpoint_path = os.path.join(self.save_dir, 'checkpoint_latest.pth')
        torch.save(checkpoint, checkpoint_path)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if is_best:
            best_path = os.path.join(self.save_dir, 'checkpoint_best.pth')
            torch.save(checkpoint, best_path)
            print(f'âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: {best_path}')
    
    def load_checkpoint(self, checkpoint_path: str):
        """
        åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹
        
        Args:
            checkpoint_path: æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
        """
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.train_history = checkpoint.get('train_history', self.train_history)
        self.val_history = checkpoint.get('val_history', self.val_history)
        print(f'âœ… åŠ è½½æ£€æŸ¥ç‚¹: {checkpoint_path}')
        return checkpoint['epoch']
    
    def close(self):
        """å…³é—­TensorBoard writer"""
        self.writer.close()


def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    parser = argparse.ArgumentParser(description='è®­ç»ƒVAEæ¨¡å‹')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--csv_path', type=str, required=True,
                        help='CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--data_root_dir', type=str, required=True,
                        help='æ•°æ®æ ¹ç›®å½•')
    parser.add_argument('--label_filter', type=str, default='living',
                        help='è¦ä¿ç•™çš„æ ‡ç­¾ï¼ˆé»˜è®¤: livingï¼‰ã€‚å¦‚æœè®¾ç½®ä¸ºNoneæˆ–ç©ºå­—ç¬¦ä¸²ï¼Œåˆ™ä½¿ç”¨å…¨éƒ¨æ•°æ®')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--input_dim', type=int, default=None,
                        help='è¾“å…¥ç‰¹å¾ç»´åº¦ï¼ˆå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨æ¨æ–­ï¼‰')
    parser.add_argument('--hidden_dims', type=int, nargs='+', default=[512, 256],
                        help='éšè—å±‚ç»´åº¦åˆ—è¡¨ï¼ˆé»˜è®¤: [512, 256]ï¼‰')
    parser.add_argument('--latent_dim', type=int, default=128,
                        help='æ½œåœ¨ç©ºé—´ç»´åº¦ï¼ˆé»˜è®¤: 128ï¼‰')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--batch_size', type=int, default=32,
                        help='æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤: 32ï¼‰')
    parser.add_argument('--epochs', type=int, default=100,
                        help='è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤: 100ï¼‰')
    parser.add_argument('--learning_rate', type=float, default=1e-4,
                        help='å­¦ä¹ ç‡ï¼ˆé»˜è®¤: 1e-4ï¼‰')
    # æ³¨æ„ï¼šbetaå‚æ•°å·²ç§»é™¤ï¼Œå› ä¸ºè®ºæ–‡ä¸­KLDé¡¹æ²¡æœ‰æƒé‡ï¼ˆL_VAE = L_MSE + L_KLDï¼‰
    parser.add_argument('--val_split', type=float, default=0.2,
                        help='éªŒè¯é›†æ¯”ä¾‹ï¼ˆé»˜è®¤: 0.2ï¼‰')
    parser.add_argument('--early_stop_patience', type=int, default=10,
                        help='Early stopping patienceï¼ˆé»˜è®¤: 10ï¼Œå³10ä¸ªepochæ²¡æœ‰æ”¹å–„åˆ™åœæ­¢ï¼‰')
    parser.add_argument('--early_stop_min_delta', type=float, default=1e-4,
                        help='Early stoppingæœ€å°æ”¹å–„é˜ˆå€¼ï¼ˆé»˜è®¤: 1e-4ï¼‰')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--device', type=str, default='cuda',
                        help='è®¾å¤‡ï¼ˆé»˜è®¤: cudaï¼‰')
    parser.add_argument('--save_dir', type=str, default='./checkpoints',
                        help='æ¨¡å‹ä¿å­˜ç›®å½•ï¼ˆé»˜è®¤: ./checkpointsï¼‰')
    parser.add_argument('--log_dir', type=str, default='./logs',
                        help='æ—¥å¿—ä¿å­˜ç›®å½•ï¼ˆé»˜è®¤: ./logsï¼‰')
    parser.add_argument('--resume', type=str, default=None,
                        help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„')
    
    args = parser.parse_args()
    
    # è®¾ç½®è®¾å¤‡
    device = args.device if torch.cuda.is_available() else 'cpu'
    print(f'ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}')
    
    # åˆ›å»ºæ•°æ®é›†
    print('ğŸ“‚ åŠ è½½æ•°æ®é›†...')
    full_dataset = WSIVAEDataset(
        csv_path=args.csv_path,
        data_root_dir=args.data_root_dir,
        label_filter=args.label_filter,
        print_info=True
    )
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    dataset_size = len(full_dataset)
    val_size = int(args.val_split * dataset_size)
    train_size = dataset_size - val_size
    train_dataset, val_dataset = torch.utils.data.random_split(
        full_dataset, [train_size, val_size],
        generator=torch.Generator().manual_seed(42)
    )
    
    print(f'ğŸ“Š æ•°æ®é›†åˆ’åˆ†: è®­ç»ƒé›† {train_size}, éªŒè¯é›† {val_size}')
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=4,
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    ) if val_size > 0 else None
    
    # è·å–è¾“å…¥ç»´åº¦
    if args.input_dim is None:
        sample = full_dataset[0]
        if sample.dim() == 2:
            input_dim = sample.shape[1]
        else:
            input_dim = sample.shape[0]
        print(f'ğŸ” è‡ªåŠ¨æ¨æ–­è¾“å…¥ç»´åº¦: {input_dim}')
    else:
        input_dim = args.input_dim
    
    # åˆ›å»ºæ¨¡å‹
    print('ğŸ—ï¸  æ„å»ºæ¨¡å‹...')
    encoder = Encoder(
        input_dim=input_dim,
        hidden_dims=args.hidden_dims,
        latent_dim=args.latent_dim
    )
    decoder = Decoder(
        latent_dim=args.latent_dim,
        hidden_dims=list(reversed(args.hidden_dims)),
        output_dim=input_dim
    )
    model = VAE(encoder, decoder, device=device)
    
    print(f'ğŸ“Š æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}')
    
    # åˆ›å»ºè®­ç»ƒå™¨
    timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')
    save_dir = os.path.join(args.save_dir, f'vae_{timestamp}')
    log_dir = os.path.join(args.log_dir, f'vae_{timestamp}')
    
    trainer = VAETrainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        device=device,
        learning_rate=args.learning_rate,
        save_dir=save_dir,
        log_dir=log_dir
    )
    
    # æ¢å¤è®­ç»ƒ
    start_epoch = 0
    if args.resume:
        start_epoch = trainer.load_checkpoint(args.resume)
    
    # è®­ç»ƒå¾ªç¯
    print('ğŸš€ å¼€å§‹è®­ç»ƒ...')
    best_val_loss = float('inf')
    patience_counter = 0
    best_epoch = 0
    
    for epoch in range(start_epoch, args.epochs):
        print(f'\n{"="*60}')
        print(f'Epoch {epoch+1}/{args.epochs}')
        print(f'{"="*60}')
        
        # è®­ç»ƒ
        train_metrics = trainer.train_epoch(epoch)
        print(f'è®­ç»ƒ - Loss: {train_metrics["loss"]:.4f}, '
              f'Recon: {train_metrics["recon_loss"]:.4f}, '
              f'KLD: {train_metrics["kld_loss"]:.4f}')
        
        # éªŒè¯
        if val_loader is not None:
            val_metrics = trainer.validate(epoch)
            print(f'éªŒè¯ - Loss: {val_metrics["loss"]:.4f}, '
                  f'Recon: {val_metrics["recon_loss"]:.4f}, '
                  f'KLD: {val_metrics["kld_loss"]:.4f}')
            
            # Early stoppingæ£€æŸ¥
            current_val_loss = val_metrics["loss"]
            improvement = best_val_loss - current_val_loss
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ”¹å–„
            if improvement > args.early_stop_min_delta:
                # æœ‰æ”¹å–„ï¼Œé‡ç½®patienceè®¡æ•°å™¨
                best_val_loss = current_val_loss
                best_epoch = epoch
                patience_counter = 0
                is_best = True
                print(f'âœ¨ éªŒè¯æŸå¤±æ”¹å–„: {improvement:.6f} (æœ€ä½³: {best_val_loss:.4f} @ Epoch {best_epoch+1})')
            else:
                # æ²¡æœ‰æ”¹å–„ï¼Œå¢åŠ patienceè®¡æ•°å™¨
                patience_counter += 1
                is_best = False
                print(f'â³ éªŒè¯æŸå¤±æœªæ”¹å–„ (patience: {patience_counter}/{args.early_stop_patience})')
            
            # Early stoppingæ£€æŸ¥
            if patience_counter >= args.early_stop_patience:
                print(f'\nğŸ›‘ Early stoppingè§¦å‘ï¼')
                print(f'   æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f} @ Epoch {best_epoch+1}')
                print(f'   å½“å‰éªŒè¯æŸå¤±: {current_val_loss:.4f}')
                print(f'   Patience: {patience_counter}/{args.early_stop_patience}')
                break
        else:
            # æ²¡æœ‰éªŒè¯é›†ï¼Œåªä¿å­˜æ£€æŸ¥ç‚¹
            is_best = False
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        trainer.save_checkpoint(epoch, is_best=is_best)
    
    # å…³é—­
    trainer.close()
    print(f'\nâœ… è®­ç»ƒå®Œæˆï¼')
    if val_loader is not None:
        print(f'   æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f} @ Epoch {best_epoch+1}')
    print(f'   æ€»è®­ç»ƒè½®æ•°: {epoch+1}/{args.epochs}')


if __name__ == '__main__':
    main()

