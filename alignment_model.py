"""
å¤šæ¨¡æ€å¯¹é½æ¨¡å—
ç›´æ¥è¯»å–å·²ç¼–ç çš„ç‰¹å¾æ•°æ®ï¼Œè¿›è¡Œçº¿æ€§å˜æ¢å’Œå¯¹é½è®­ç»ƒ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MultiModalAlignmentModel(nn.Module):
    """
    å¤šæ¨¡æ€å¯¹é½æ¨¡å‹ - ç›´æ¥å¯¹å·²ç¼–ç ç‰¹å¾è¿›è¡Œçº¿æ€§å˜æ¢å’Œå¯¹é½
    """
    
    def __init__(self, 
                 modality_names: List[str],
                 feature_dim: int = 1024,
                 num_layers: int = 1):
        """
        åˆå§‹åŒ–å¤šæ¨¡æ€å¯¹é½æ¨¡å‹
        
        Args:
            modality_names: æ¨¡æ€åç§°åˆ—è¡¨ï¼Œå¦‚ ['CD3', 'CD8', 'CD28']
            feature_dim: ç‰¹å¾ç»´åº¦ï¼ˆæ‰€æœ‰æ¨¡æ€ç»Ÿä¸€ç»´åº¦ï¼‰
            num_layers: å¯¹é½å±‚çš„å±‚æ•°ï¼Œé»˜è®¤ä¸º 1
        """
        super(MultiModalAlignmentModel, self).__init__()
        
        self.modality_names = modality_names
        self.num_modalities = len(modality_names)
        self.feature_dim = feature_dim
        self.num_layers = num_layers
        
        # ä¸ºæ¯ä¸ªæ¨¡æ€æ„å»ºå¯¹é½å±‚
        self.alignment_layers = nn.ModuleDict()
        # MLP predictor æ¥æ”¶æ‹¼æ¥åçš„ç‰¹å¾ (num_modalities * feature_dim)
        self.mlp_predictor = MLPMatchPredictor(feature_dim=self.num_modalities * feature_dim, hidden_dim=512)
        
        for modality_name in modality_names:
            self.alignment_layers[modality_name] = self._build_alignment_layer(
                feature_dim=feature_dim,
                num_layers=num_layers
            )
        
        logger.info(f"âœ… å¤šæ¨¡æ€å¯¹é½æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   - æ¨¡æ€æ•°é‡: {self.num_modalities}")
        logger.info(f"   - æ¨¡æ€åç§°: {modality_names}")
        logger.info(f"   - ç‰¹å¾ç»´åº¦: {feature_dim}")
        logger.info(f"   - å¯¹é½å±‚æ•°: {num_layers}")
    
    def _build_alignment_layer(self, 
                               feature_dim: int, 
                               num_layers: int = 1) -> nn.Module:
        """
        æ„å»ºå¯¹é½å±‚ - æ”¯æŒå¤šå±‚ç½‘ç»œç»“æ„ï¼ˆçº¯çº¿æ€§å±‚å åŠ ï¼‰
        
        Args:
            feature_dim: è¾“å…¥å’Œè¾“å‡ºç‰¹å¾ç»´åº¦
            num_layers: å±‚æ•°
            
        Returns:
            nn.Sequential: å¤šå±‚çº¿æ€§ç½‘ç»œæ¨¡å—
        """
        layers = []
        
        for i in range(num_layers):
            layers.append(nn.Linear(feature_dim, feature_dim))
        
        return nn.Sequential(*layers)
    
    def forward(self, modality_data: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­ - é«˜æ•ˆå¹¶è¡Œå¯¹å·²ç¼–ç ç‰¹å¾è¿›è¡Œçº¿æ€§å¯¹é½å˜æ¢
        
        Args:
            modality_data: å­—å…¸ï¼Œé”®ä¸ºæ¨¡æ€åç§°ï¼Œå€¼ä¸ºå·²ç¼–ç çš„ç‰¹å¾
                          ä¾‹å¦‚: {'CD3': CD3_features, 'CD8': CD8_features, 'CD28': CD28_features}
            
        Returns:
            å¯¹é½åçš„ç‰¹å¾å­—å…¸ï¼Œé”®ä¸ºæ¨¡æ€åç§°ï¼Œå€¼ä¸ºå¯¹é½åçš„ç‰¹å¾
        """
        aligned_features = {}
        
        # éªŒè¯æ‰€æœ‰æ¨¡æ€éƒ½åœ¨æ¨¡å‹ä¸­
        for modality_name in modality_data.keys():
            if modality_name not in self.modality_names:
                raise ValueError(f"æœªçŸ¥çš„æ¨¡æ€: {modality_name}")
        
        for modality_name, features in modality_data.items():
            aligned_features[modality_name] = self.alignment_layers[modality_name](features)
        
        return aligned_features


class MLPMatchPredictor(nn.Module):
    """
    MLPåŒ¹é…é¢„æµ‹å™¨ - é¢„æµ‹å¤šæ¨¡æ€ç‰¹å¾æ˜¯å¦åŒ¹é…
    ä¸¤å±‚MLPç½‘ç»œï¼Œç”¨äºåˆ¤æ–­ç‰¹å¾æ˜¯å¦æ¥è‡ªåŒä¸€ä¸ªæ ·æœ¬
    """
    
    def __init__(self, 
                 feature_dim: int = 1024,
                 hidden_dim: int = 512,
                 dropout: float = 0.1):
        super(MLPMatchPredictor, self).__init__()
        
        self.feature_dim = feature_dim
        self.hidden_dim = hidden_dim
        
        # ä¸¤å±‚MLPç½‘ç»œ
        self.mlp = nn.Sequential(
            nn.Linear(feature_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, 1),
            nn.Sigmoid()  # è¾“å‡º0-1ä¹‹é—´çš„æ¦‚ç‡
        )
    
    def forward(self, features: torch.Tensor) -> torch.Tensor:
        return self.mlp(features)
    

def main():
    """
    ä¸»å‡½æ•° - ç¤ºä¾‹ç”¨æ³•å’Œæ¨¡å‹æµ‹è¯•
    """
    # è®¾ç½®è®¾å¤‡
    device = "cuda" if torch.cuda.is_available() else "cpu"
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºå¤šæ¨¡æ€å¯¹é½æ¨¡å‹
    model = MultiModalAlignmentModel(
        modality_names=['CD3', 'CD8', 'CD28'],
        feature_dim=1024
    )
    
    logger.info("âœ… å¤šæ¨¡æ€å¯¹é½æ¨¡å—åˆå§‹åŒ–å®Œæˆ")
    
    # ğŸ§ª æµ‹è¯•MLPåŒ¹é…é¢„æµ‹å™¨
    logger.info("ğŸ§ª æµ‹è¯•MLPåŒ¹é…é¢„æµ‹å™¨...")
    
    # æ¨¡æ‹Ÿæ•°æ®
    batch_size = 32
    feature_dim = 1024
    
    # 1. æµ‹è¯•å•æ¨¡æ€MLPé¢„æµ‹å™¨
    mlp_predictor = MLPMatchPredictor(feature_dim=feature_dim, hidden_dim=512)
    test_features = torch.randn(batch_size, feature_dim, device=device)
    predictions = mlp_predictor(test_features)
    logger.info(f"   ğŸ“Š MLPé¢„æµ‹å™¨è¾“å‡ºå½¢çŠ¶: {predictions.shape}")
    logger.info(f"   ğŸ“Š é¢„æµ‹æ¦‚ç‡èŒƒå›´: [{predictions.min().item():.3f}, {predictions.max().item():.3f}]")
    
    # 2. æµ‹è¯•å¤šæ¨¡æ€MLPé¢„æµ‹å™¨
    multi_modal_predictor = MultiModalMatchPredictor(
        modality_names=['CD3', 'CD8', 'CD28'],
        feature_dim=feature_dim,
        fusion_method="concat"
    )
    
    test_modality_data = {
        'CD3': torch.randn(batch_size, feature_dim, device=device),
        'CD8': torch.randn(batch_size, feature_dim, device=device),
        'CD28': torch.randn(batch_size, feature_dim, device=device)
    }
    
    multi_predictions = multi_modal_predictor(test_modality_data)
    logger.info(f"   ğŸ“Š å¤šæ¨¡æ€MLPé¢„æµ‹å™¨è¾“å‡ºå½¢çŠ¶: {multi_predictions.shape}")
    logger.info(f"   ğŸ“Š å¤šæ¨¡æ€é¢„æµ‹æ¦‚ç‡èŒƒå›´: [{multi_predictions.min().item():.3f}, {multi_predictions.max().item():.3f}]")
    
    # 3. æµ‹è¯•äºŒåˆ†ç±»é¢„æµ‹
    binary_predictions = multi_modal_predictor.predict_match(test_modality_data, threshold=0.5)
    logger.info(f"   ğŸ“Š äºŒåˆ†ç±»é¢„æµ‹å½¢çŠ¶: {binary_predictions.shape}")
    logger.info(f"   ğŸ“Š åŒ¹é…æ ·æœ¬æ•°é‡: {binary_predictions.sum().item()}/{batch_size}")
    
    logger.info("âœ… æ‰€æœ‰æ¨¡å‹æµ‹è¯•å®Œæˆ")
    logger.info("ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹:")
    logger.info("   from Finetune_trainer import MultiModalAlignmentTrainer")
    logger.info("   trainer = MultiModalAlignmentTrainer(model, device)")
    logger.info("   history = trainer.train(train_loader, val_loader)")


if __name__ == "__main__":
    main()
