"""
TMAç‰¹å¾æå–æ¨¡å— - ä½¿ç”¨UNIæ¨¡å‹
æ”¯æŒå¯¹TMA_TumorCenter_Cores_oriç›®å½•ä¸­çš„PNGå›¾åƒè¿›è¡Œç‰¹å¾æå–
"""

import argparse
import os
from pathlib import Path
from typing import List, Dict
import logging

import numpy as np
from PIL import Image
from tqdm import tqdm
import torch
import timm
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def list_pngs(tile_dir: Path) -> List[Path]:
    """
    åˆ—å‡ºç›®å½•ä¸­çš„PNGæ–‡ä»¶ï¼ŒæŒ‰ç¡®å®šæ€§é¡ºåºæ’åº
    
    Args:
        tile_dir: åŒ…å«PNGç“¦ç‰‡çš„ç›®å½•
        
    Returns:
        æœ‰åºçš„PNGè·¯å¾„åˆ—è¡¨
    """
    return sorted([p for p in tile_dir.iterdir() if p.suffix.lower() == ".png"])


def build_uni_model(device: str = "cpu"):
    """
    é€šè¿‡timmä»HuggingFace hubåŠ è½½UNIç¼–ç å™¨
    
    Args:
        device: "cpu" æˆ– "cuda" (éœ€è¦å…¼å®¹çš„torch/CUDA)
        
    Returns:
        (model, transform)
    """
    if timm is None:
        raise RuntimeError("timm/torchä¸å¯ç”¨ã€‚è¯·å®‰è£… torch>=2.0, timm>=0.9.8")

    # ä»æœ¬åœ°æ–‡ä»¶è¯»å–å¹¶è®¾ç½®Hugging Face token
    try:
        token_file = Path("/home/zheng/zheng/bin/.commands/.env")
        if token_file.exists():
            with open(token_file, 'r') as f:
                content = f.read()
                for line in content.split('\n'):
                    if line.startswith('HF_TOKEN='):
                        token = line.split('=', 1)[1].strip()
                        if token:
                            os.environ['HF_TOKEN'] = token
                            logger.info("âœ… Hugging Face tokenå·²è®¾ç½®")
                            break
        else:
            logger.warning(f"Tokenæ–‡ä»¶ä¸å­˜åœ¨: {token_file}")
    except Exception as e:
        logger.warning(f"è¯»å–tokenæ–‡ä»¶å¤±è´¥: {e}")

    # åˆ›å»ºUNIæ¨¡å‹ - è¾“å‡ºç»´åº¦å›ºå®šä¸º1024
    model = timm.create_model(
        "hf-hub:MahmoodLab/uni",
        pretrained=True,
        init_values=1e-5,
        dynamic_img_size=True,
        num_classes=0,  # è®¾ç½®ä¸º0ä»¥è·å–ç‰¹å¾è€Œä¸æ˜¯åˆ†ç±»è¾“å‡º
    )
    
    # è·å–æ¨¡å‹é…ç½®å¹¶åˆ›å»ºtransform
    # UNIæ¨¡å‹ä¼šè‡ªåŠ¨å°†è¾“å…¥å›¾åƒè°ƒæ•´åˆ°224x224
    cfg = resolve_data_config(model.pretrained_cfg, model=model)
    transform = create_transform(**cfg)
    
    model.eval()
    model.to(device)
    
    logger.info(f"âœ… UNIæ¨¡å‹åŠ è½½å®Œæˆ - è¾“å‡ºç»´åº¦: 1024")
    return model, transform


def load_image(path: Path) -> Image.Image:
    """
    åŠ è½½RGB PILå›¾åƒ
    
    Args:
        path: å›¾åƒè·¯å¾„
        
    Returns:
        RGB PILå›¾åƒ
    """
    img = Image.open(path)
    if img.mode != "RGB":
        img = img.convert("RGB")
    return img


def extract_patches_from_image(
    img: Image.Image, 
    patch_size: int = 256, 
    stride: int = 128,
    white_threshold: float = None,
    min_content_ratio: float = None
) -> List[Image.Image]:
    """
    ä»å›¾åƒä¸­æå–patchesï¼Œå¯é€‰æ‹©è¿‡æ»¤æ‰åŒ…å«å¤ªå¤šç™½è‰²/ç©ºç™½åŒºåŸŸçš„patches
    
    Args:
        img: è¾“å…¥å›¾åƒ
        patch_size: patchå°ºå¯¸
        stride: æ­¥é•¿
        white_threshold: ç™½è‰²åƒç´ é˜ˆå€¼ (0-1)ï¼Œä¸ºNoneæ—¶ä¸è¿›è¡Œè¿‡æ»¤
        min_content_ratio: æœ€å°å†…å®¹æ¯”ä¾‹ï¼Œä¸ºNoneæ—¶ä¸è¿›è¡Œè¿‡æ»¤
        
    Returns:
        patchåˆ—è¡¨
    """
    width, height = img.size
    patches = []
    
    # å¦‚æœå›¾åƒå°ºå¯¸å°äºpatch_sizeï¼Œç›´æ¥è°ƒæ•´å›¾åƒå¤§å°
    if width < patch_size or height < patch_size:
        logger.info(f"å›¾åƒå°ºå¯¸ {width}x{height} å°äºpatchå°ºå¯¸ {patch_size}ï¼Œç›´æ¥è°ƒæ•´å›¾åƒå¤§å°")
        img_resized = img.resize((patch_size, patch_size), Image.Resampling.LANCZOS)
        patches.append(img_resized)
        return patches
    
    # è®¡ç®—å¯ä»¥æå–çš„patchæ•°é‡
    for y in range(0, height - patch_size + 1, stride):
        for x in range(0, width - patch_size + 1, stride):
            # æå–patch
            patch = img.crop((x, y, x + patch_size, y + patch_size))
            
            # å¦‚æœè®¾ç½®äº†thresholdå‚æ•°ï¼Œåˆ™è¿›è¡ŒpatchéªŒè¯
            if white_threshold is not None and min_content_ratio is not None:
                # æ£€æŸ¥patchæ˜¯å¦åŒ…å«è¶³å¤Ÿçš„å†…å®¹ï¼ˆéç™½è‰²åŒºåŸŸï¼‰
                if _is_patch_valid(patch, white_threshold, min_content_ratio):
                    patches.append(patch)
                else:
                    logger.debug(f"è·³è¿‡åŒ…å«å¤ªå¤šç©ºç™½åŒºåŸŸçš„patch: ({x}, {y})")
            else:
                # ä¸è¿›è¡ŒéªŒè¯ï¼Œç›´æ¥æ·»åŠ æ‰€æœ‰patches
                patches.append(patch)
    
    return patches


def _is_patch_valid(patch: Image.Image, white_threshold: float, min_content_ratio: float) -> bool:
    """
    æ£€æŸ¥patchæ˜¯å¦æœ‰æ•ˆï¼ˆä¸åŒ…å«å¤ªå¤šç™½è‰²/ç©ºç™½åŒºåŸŸï¼‰
    
    Args:
        patch: å›¾åƒpatch
        white_threshold: ç™½è‰²åƒç´ é˜ˆå€¼
        min_content_ratio: æœ€å°å†…å®¹æ¯”ä¾‹
        
    Returns:
        æ˜¯å¦æœ‰æ•ˆ
    """
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    img_array = np.array(patch)
    
    # è®¡ç®—ç™½è‰²åƒç´ æ¯”ä¾‹ï¼ˆRGBéƒ½æ¥è¿‘255ï¼‰
    white_pixels = np.all(img_array >= white_threshold * 255, axis=2)
    white_ratio = np.mean(white_pixels)
    
    # å†…å®¹æ¯”ä¾‹ = 1 - ç™½è‰²æ¯”ä¾‹
    content_ratio = 1 - white_ratio
    
    return content_ratio >= min_content_ratio

def extract_uni_features_from_patches(
    patches: List[Image.Image],
    model,
    transform,
    device: str = "cpu",
    batch_size: int = 32
) -> np.ndarray:
    """
    ä½¿ç”¨UNIä¸ºpatchåˆ—è¡¨æå–ç‰¹å¾
    
    Args:
        patches: patchå›¾åƒåˆ—è¡¨
        model: UNIæ¨¡å‹
        transform: æ¥è‡ªtimmé…ç½®çš„å›¾åƒå˜æ¢
        device: "cpu" æˆ– "cuda"
        batch_size: æ¨ç†çš„æ‰¹å¤§å°
        
    Returns:
        å½¢çŠ¶ä¸º (N, 1024) çš„æ•°ç»„ - UNIå›ºå®šè¾“å‡º1024ç»´
    """
    feats: List[np.ndarray] = []
    
    with torch.inference_mode():
        for i in tqdm(range(0, len(patches), batch_size), desc="æå–UNIç‰¹å¾", unit="batch"):
            batch_images = []
            for patch in patches[i : i + batch_size]:
                # åº”ç”¨å˜æ¢ - UNIä¼šè‡ªåŠ¨è°ƒæ•´åˆ°224x224
                transformed_img = transform(patch).unsqueeze(0)
                batch_images.append(transformed_img)
            
            # æ‹¼æ¥æ‰¹æ¬¡
            batch_t = torch.cat(batch_images, dim=0).to(device)
            
            # æå–ç‰¹å¾ - UNIè¾“å‡ºå›ºå®šä¸º1024ç»´
            emb = model(batch_t)  # [B, 1024]
            feats.append(emb.detach().cpu().numpy())
            
            # æ¸…ç†å†…å­˜
            del batch_t, emb, batch_images
            if device.startswith("cuda"):
                torch.cuda.empty_cache()
    
    return np.concatenate(feats, axis=0)


def extract_uni_features_from_image(
    img_path: Path,
    model,
    transform,
    device: str = "cpu",
    batch_size: int = 32,
    patch_size: int = 256,
    stride: int = 128,
    white_threshold: float = 0.8,
    min_content_ratio: float = 0.1,
) -> np.ndarray:
    """
    ä»å•ä¸ªå›¾åƒæå–UNIç‰¹å¾ï¼ˆé€šè¿‡patchesï¼‰
    
    Args:
        img_path: å›¾åƒè·¯å¾„
        model: UNIæ¨¡å‹
        transform: å›¾åƒå˜æ¢
        device: è®¾å¤‡
        batch_size: æ‰¹å¤§å°
        patch_size: patchå°ºå¯¸
        stride: æ­¥é•¿
        
    Returns:
        å½¢çŠ¶ä¸º (N, 1024) çš„æ•°ç»„ - UNIå›ºå®šè¾“å‡º1024ç»´
    """
    # åŠ è½½å›¾åƒ
    img = load_image(img_path)
    
    # æå–patches
    patches = extract_patches_from_image(img, patch_size, stride, white_threshold, min_content_ratio)
    
    if not patches:
        logger.warning(f"ä» {img_path} ä¸­æ²¡æœ‰æå–åˆ°patches")
        return np.zeros((0, 1024), dtype=np.float32)
    
    # æå–ç‰¹å¾
    features = extract_uni_features_from_patches(patches, model, transform, device, batch_size)
    
    return features


def extract_marker_features(
    marker_dir: Path,
    model,
    transform,
    device: str = "cpu",
    batch_size: int = 32,
    patch_size: int = 256,
    stride: int = 128,
    white_threshold: float = 0.8,
    min_content_ratio: float = 0.1,
) -> Dict[str, np.ndarray]:
    """
    ä¸ºå•ä¸ªæ ‡è®°ç›®å½•æå–ç‰¹å¾
    
    Args:
        marker_dir: æ ‡è®°ç›®å½•è·¯å¾„
        model: UNIæ¨¡å‹
        transform: å›¾åƒå˜æ¢
        device: è®¾å¤‡
        batch_size: æ‰¹å¤§å°
        patch_size: patchå°ºå¯¸
        stride: æ­¥é•¿
        
    Returns:
        ç‰¹å¾å­—å…¸ï¼Œé”®ä¸ºæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ï¼Œå€¼ä¸º1024ç»´ç‰¹å¾æ•°ç»„
    """
    pngs = list_pngs(marker_dir)
    if not pngs:
        logger.warning(f"åœ¨ {marker_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°PNGæ–‡ä»¶")
        return {}
    
    logger.info(f"å¤„ç†æ ‡è®°ç›®å½•: {marker_dir.name} | PNGæ•°é‡: {len(pngs)}")
    
    # æ„å»ºæ¯PNGå­—å…¸
    out_dict: Dict[str, np.ndarray] = {}
    
    # ä½¿ç”¨tqdmæ˜¾ç¤ºæ¯ä¸ªå›¾åƒçš„è¿›åº¦
    for png_path in tqdm(pngs, desc=f"å¤„ç† {marker_dir.name}", unit="image"):
        try:
            # ä»å•ä¸ªå›¾åƒæå–ç‰¹å¾
            features = extract_uni_features_from_image(
                png_path, model, transform, device, batch_size, 
                patch_size, stride, white_threshold, min_content_ratio
            )
            
            key = png_path.stem  # ä¸å«æ‰©å±•åçš„æ–‡ä»¶å
            out_dict[key] = features.astype(np.float32)
            
        except Exception as e:
            logger.error(f"å¤„ç†å›¾åƒ {png_path} æ—¶å‡ºé”™: {e}")
            continue
    
    return out_dict


def main() -> None:
    """
    ä¸»å‡½æ•°
    """
    parser = argparse.ArgumentParser(description="ä½¿ç”¨UNI (ViT-L/16) æå–TMA PNGç¼–ç ç‰¹å¾")
    parser.add_argument("png_root", type=str, help="åŒ…å«TMA PNGå­æ–‡ä»¶å¤¹çš„æ ¹ç›®å½•")
    parser.add_argument("dest_dir", type=str, help="NPZç‰¹å¾çš„è¾“å‡ºç›®å½•")
    parser.add_argument("--device", type=str, default="cpu", choices=["cpu", "cuda"], 
                       help="æ¨ç†è®¾å¤‡")
    parser.add_argument("--batch_size", type=int, default=32, help="ç‰¹å¾æå–çš„æ‰¹å¤§å°")
    parser.add_argument("--patch_size", type=int, default=256, help="patchå°ºå¯¸")
    parser.add_argument("--stride", type=int, default=128, help="patchæ­¥é•¿")
    # UNIæ¨¡å‹è¾“å‡ºç»´åº¦å›ºå®šä¸º1024ï¼Œä¸éœ€è¦å‚æ•°
    parser.add_argument("--markers", type=str, nargs="+", 
                       default=["CD3", "CD8", "CD56", "CD68", "CD163", "HE", "MHC1", "PDL1"],
                       help="è¦å¤„ç†çš„æ ‡è®°åˆ—è¡¨")
    parser.add_argument("--gpu_id", type=int, default=0, help="ä½¿ç”¨çš„GPU ID")
    parser.add_argument("--white_threshold", type=float, default=None, 
                       help="ç™½è‰²åƒç´ é˜ˆå€¼ (0-1)ï¼Œè¶…è¿‡æ­¤å€¼è®¤ä¸ºæ˜¯ç™½è‰²ã€‚ä¸è®¾ç½®åˆ™ä¸è¿›è¡Œpatchè¿‡æ»¤")
    parser.add_argument("--min_content_ratio", type=float, default=None,
                       help="æœ€å°å†…å®¹æ¯”ä¾‹ï¼Œä½äºæ­¤æ¯”ä¾‹çš„patchä¼šè¢«è¿‡æ»¤ã€‚ä¸è®¾ç½®åˆ™ä¸è¿›è¡Œpatchè¿‡æ»¤")
    
    args = parser.parse_args()

    png_root = Path(args.png_root)
    dest_dir = Path(args.dest_dir)
    dest_dir.mkdir(parents=True, exist_ok=True)

    # è®¾ç½®è®¾å¤‡
    if args.device == "cuda":
        if torch is None or not torch.cuda.is_available():
            logger.warning("CUDAä¸å¯ç”¨ï¼Œæ”¹ç”¨CPU")
            device = "cpu"
        else:
            device = f"cuda:{args.gpu_id}"
            # è®¾ç½®å¯è§çš„GPU
            os.environ["CUDA_VISIBLE_DEVICES"] = str(args.gpu_id)
    else:
        device = "cpu"

    logger.info(f"ğŸš€ å¼€å§‹ä½¿ç”¨UNIæå–TMA PNGç‰¹å¾...")
    logger.info(f"ğŸ“ PNGæ ¹ç›®å½•: {png_root}")
    logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {dest_dir}")
    logger.info(f"ğŸ–¥ è®¾å¤‡: {device}")
    logger.info(f"ğŸ”¢ æ‰¹å¤§å°: {args.batch_size}")
    logger.info(f"ğŸ“ Patchå°ºå¯¸: {args.patch_size}")
    logger.info(f"ğŸ‘£ æ­¥é•¿: {args.stride}")
    logger.info(f"ğŸ“Š è¾“å‡ºç»´åº¦: 1024 (UNIå›ºå®š)")
    logger.info(f"ğŸ· æ ‡è®°åˆ—è¡¨: {args.markers}")
    
    # æ˜¾ç¤ºpatchè¿‡æ»¤è®¾ç½®
    if args.white_threshold is not None and args.min_content_ratio is not None:
        logger.info(f"ğŸ” Patchè¿‡æ»¤: å¯ç”¨ (ç™½è‰²é˜ˆå€¼: {args.white_threshold}, æœ€å°å†…å®¹æ¯”ä¾‹: {args.min_content_ratio})")
    else:
        logger.info(f"ğŸ” Patchè¿‡æ»¤: ç¦ç”¨ (æå–æ‰€æœ‰patches)")
    
    logger.info("")

    # æ„å»ºæ¨¡å‹
    logger.info("ğŸ”§ æ„å»ºUNIæ¨¡å‹...")
    model, transform = build_uni_model(device=device)
    logger.info("âœ… æ¨¡å‹æ„å»ºå®Œæˆ")

    # å¤„ç†æ¯ä¸ªæ ‡è®°ç›®å½•
    processed_count = 0
    total_markers = len(args.markers)
    
    # ä½¿ç”¨tqdmæ˜¾ç¤ºæ€»ä½“è¿›åº¦
    for marker in tqdm(args.markers, desc="å¤„ç†æ ‡è®°", unit="marker"):
        marker_dir = png_root / f"tma_tumorcenter_{marker}"
        
        if not marker_dir.exists():
            logger.warning(f"æ ‡è®°ç›®å½•ä¸å­˜åœ¨: {marker_dir}")
            continue
        
        if not marker_dir.is_dir():
            logger.warning(f"ä¸æ˜¯ç›®å½•: {marker_dir}")
            continue
        
        try:
            # æå–ç‰¹å¾
            features_dict = extract_marker_features(
                marker_dir, model, transform, device, args.batch_size, 
                args.patch_size, args.stride, args.white_threshold, args.min_content_ratio
            )
            
            if not features_dict:
                logger.warning(f"æ²¡æœ‰æå–åˆ°ç‰¹å¾: {marker}")
                continue
            
            # ä¿å­˜ç‰¹å¾
            output_path = dest_dir / f"tma_uni_patch_{args.patch_size}_stride_{args.stride}_dim_1024_{marker}.npz"
            np.savez_compressed(output_path, **features_dict)
            
            # ç»Ÿè®¡ç‰¹å¾æ•°é‡
            total_features = sum(features.shape[0] for features in features_dict.values())
            logger.info(f"âœ… ä¿å­˜: {output_path} (å›¾åƒæ•°: {len(features_dict)}, æ€»ç‰¹å¾æ•°: {total_features})")
            processed_count += 1
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ ‡è®° {marker} æ—¶å‡ºé”™: {e}")
            continue

    logger.info("")
    logger.info(f"ğŸ‰ ç‰¹å¾æå–å®Œæˆï¼")
    logger.info(f"ğŸ“Š æˆåŠŸå¤„ç†: {processed_count}/{total_markers} ä¸ªæ ‡è®°")
    logger.info(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {dest_dir}")
    logger.info(f"ğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶:")
    
    # åˆ—å‡ºç”Ÿæˆçš„æ–‡ä»¶
    npz_files = list(dest_dir.glob("tma_uni_*.npz"))
    for npz_file in sorted(npz_files):
        logger.info(f"   {npz_file.name}")


if __name__ == "__main__":
    main()
