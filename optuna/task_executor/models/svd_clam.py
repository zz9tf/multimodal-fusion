import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from .base_model import BaseModel
from typing import Dict, Optional
from .alignment_model import MultiModalAlignmentModel

class Attn_Net(nn.Module):
    """æ³¨æ„åŠ›ç½‘ç»œï¼ˆæ— é—¨æ§ï¼‰"""
    
    def __init__(self, L=1024, D=256, dropout=False, n_classes=1):
        """
        åˆå§‹åŒ–æ³¨æ„åŠ›ç½‘ç»œ
        
        Args:
            L: è¾“å…¥ç‰¹å¾ç»´åº¦
            D: éšè—å±‚ç»´åº¦
            dropout: æ˜¯å¦ä½¿ç”¨dropout
            n_classes: è¾“å‡ºç±»åˆ«æ•°
        """
        super(Attn_Net, self).__init__()
        self.module = [
            nn.Linear(L, D),
            nn.Tanh()
        ]
        if dropout:
            self.module.append(nn.Dropout(0.25))
        self.module.append(nn.Linear(D, n_classes))
        self.module = nn.Sequential(*self.module)
    
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: è¾“å…¥ç‰¹å¾å¼ é‡
            
        Returns:
            attention_weights: æ³¨æ„åŠ›æƒé‡
            x: åŸå§‹è¾“å…¥ç‰¹å¾
        """
        return self.module(x), x

class Attn_Net_Gated(nn.Module):
    """é—¨æ§æ³¨æ„åŠ›ç½‘ç»œ"""
    
    def __init__(self, L=1024, D=256, dropout=False, n_classes=1):
        """
        åˆå§‹åŒ–é—¨æ§æ³¨æ„åŠ›ç½‘ç»œ
        
        Args:
            L: è¾“å…¥ç‰¹å¾ç»´åº¦
            D: éšè—å±‚ç»´åº¦
            dropout: æ˜¯å¦ä½¿ç”¨dropout
            n_classes: è¾“å‡ºç±»åˆ«æ•°
        """
        super(Attn_Net_Gated, self).__init__()
        self.attention_a = [
            nn.Linear(L, D),
            nn.Tanh()
        ]
        self.attention_b = [
            nn.Linear(L, D),
            nn.Sigmoid()
        ]
        if dropout:
            self.attention_a.append(nn.Dropout(0.25))
            self.attention_b.append(nn.Dropout(0.25))
        
        self.attention_a = nn.Sequential(*self.attention_a)
        self.attention_b = nn.Sequential(*self.attention_b)
        self.attention_c = nn.Linear(D, n_classes)

    def forward(self, x):
        """
        é—¨æ§æ³¨æ„åŠ›å‰å‘ä¼ æ’­
        
        Args:
            x: è¾“å…¥ç‰¹å¾å¼ é‡
            
        Returns:
            attention_weights: é—¨æ§æ³¨æ„åŠ›æƒé‡
            x: åŸå§‹è¾“å…¥ç‰¹å¾
        """
        a = self.attention_a(x)
        b = self.attention_b(x)
        A = a.mul(b)
        A = self.attention_c(A)
        return A, x

class SVD_CLAM(BaseModel):
    """
    SVD-CLAM æ¨¡å‹ï¼šç»“åˆSVDå¯¹é½å’ŒCLAMæ³¨æ„åŠ›çš„å¤šæ¨¡æ€ç”Ÿå­˜é¢„æµ‹æ¨¡å‹
    
    é…ç½®å‚æ•°ï¼š
    - n_classes: ç±»åˆ«æ•°é‡
    - input_dim: è¾“å…¥ç»´åº¦
    - model_size: æ¨¡å‹å¤§å° ('small', 'big', '128*64', '64*32', '32*16', '16*8', '8*4', '4*2', '2*1')
    - dropout: dropoutç‡
    - gate: æ˜¯å¦ä½¿ç”¨é—¨æ§æ³¨æ„åŠ›
    - inst_number: æ­£è´Ÿæ ·æœ¬é‡‡æ ·æ•°é‡
    - instance_loss_fn: å®ä¾‹æŸå¤±å‡½æ•°
    - subtyping: æ˜¯å¦ä¸ºå­ç±»å‹é—®é¢˜
    - alignment_layer_num: å¯¹é½å±‚æ•°é‡
    - alignment_channels: å¯¹é½é€šé“åˆ—è¡¨
    - tau1, tau2: æ¸©åº¦å‚æ•°
    - lambda1, lambda2: æŸå¤±æƒé‡å‚æ•°
    """
    
    def __init__(self, config):
        """
        åˆå§‹åŒ–SVD-CLAMæ¨¡å‹
        
        Args:
            config: æ¨¡å‹é…ç½®å­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„å‚æ•°
        """
        super().__init__(config)
        
        # éªŒè¯é…ç½®å®Œæ•´æ€§
        self._validate_config(config)
        
        # æ¨¡å‹å¤§å°é…ç½®
        self.size_dict = {
            "small": [self.input_dim, 512, 256], 
            "big": [self.input_dim, 512, 384], 
            "128*64": [self.input_dim, 128, 64], 
            "64*32": [self.input_dim, 64, 32], 
            "32*16": [self.input_dim, 32, 16],
            "16*8": [self.input_dim, 16, 8],
            "8*4": [self.input_dim, 8, 4],
            "4*2": [self.input_dim, 4, 2],
            "2*1": [self.input_dim, 2, 1]
        }
        
        self.gate = config.get('gate', True)
        self.base_weight = config.get('base_weight', 0.7)
        if config.get('inst_loss_fn') is None or config.get('inst_loss_fn') == 'ce':
            self.instance_loss_fn = nn.CrossEntropyLoss()
        elif config.get('inst_loss_fn') == 'svm':
            self.instance_loss_fn = nn.SmoothTop1SVM(n_classes=self.n_classes)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„instanceæŸå¤±å‡½æ•°: {config.get('inst_loss_fn')}")

        self.model_size = config['model_size']
        self.subtyping = config.get('subtyping', False)
        self.inst_number = config.get('inst_number', 8)
        self.channels_used_in_model = config['channels_used_in_model']
        self.return_features = config.get('return_features', False)
        self.attention_only = config.get('attention_only', False)
        size = self.size_dict[self.model_size]
        self.alignment_layer_num = config.get('alignment_layer_num', 2)
        self.alignment_channels = config.get('alignment_channels', ['tma_CD3', 'tma_CD8', 'tma_CD56', 'tma_CD68', 'tma_CD163', 'tma_HE', 'tma_MHC1', 'tma_PDL1'])
        self.tau1 = config.get('tau1', 0.1)
        self.tau2 = config.get('tau2', 0.1)
        self.lambda1 = config.get('lambda1', 1.0)
        self.lambda2 = config.get('lambda2', 0.1)
        self.loss2_chunk_size = config.get('loss2_chunk_size', None)
        
        self.alignment_layers = MultiModalAlignmentModel(
            modality_names=self.alignment_channels, 
            feature_dim=self.input_dim, 
            num_layers=self.alignment_layer_num
        )
        
        # æ„å»ºç‰¹å¾æå–å±‚
        fc = [nn.Linear(size[0], size[1]), nn.ReLU(), nn.Dropout(self.dropout)]
        
        # æ„å»ºæ³¨æ„åŠ›ç½‘ç»œï¼ˆå•åˆ†æ”¯ï¼šè¾“å‡º1ä¸ªæ³¨æ„åŠ›å€¼ï¼‰
        if self.gate:
            attention_net = Attn_Net_Gated(
                L=size[1], D=size[2], dropout=self.dropout, n_classes=1 if self.n_classes == 2 else self.n_classes
            )
        else:
            attention_net = Attn_Net(
                L=size[1], D=size[2], dropout=self.dropout, n_classes=1 if self.n_classes == 2 else self.n_classes
            )
        
        fc.append(attention_net)
        self.attention_net = nn.Sequential(*fc)
        
        # æ„å»ºåˆ†ç±»å™¨
        self.classifiers = None
        if self.n_classes == 2:
            self.classifiers = nn.Linear(size[1], self.n_classes)
        else:
            self.classifiers = nn.ModuleList([nn.Linear(size[1], 1) for _ in range(self.n_classes)])
        
        # å®ä¾‹åˆ†ç±»å™¨
        instance_classifiers = [nn.Linear(size[1], 2) for _ in range(self.n_classes)]
        self.instance_classifiers = nn.ModuleList(instance_classifiers)
 
    def _validate_config(self, config):
        """éªŒè¯é…ç½®å®Œæ•´æ€§"""
        required_params = ['n_classes', 'input_dim', 'model_size', 'dropout']
        missing_params = [param for param in required_params if param not in config]
        if missing_params:
            raise ValueError(f"CLAM_SBé…ç½®ç¼ºå°‘å¿…éœ€å‚æ•°: {missing_params}")
        
        # éªŒè¯æ¨¡å‹å¤§å°
        valid_sizes = ["small", "big", "128*64", "64*32", "32*32", "16*8", "8*4", "4*2", "2*1"]
        if config['model_size'] not in valid_sizes:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹å¤§å°: {config['model_size']}ï¼Œæ”¯æŒçš„å¤§å°: {valid_sizes}")
        
        # éªŒè¯ç±»åˆ«æ•°é‡
        if config['n_classes'] < 2:
            raise ValueError(f"ç±»åˆ«æ•°é‡å¿…é¡» >= 2ï¼Œå½“å‰: {config['n_classes']}")
        
        # éªŒè¯è¾“å…¥ç»´åº¦
        if config['input_dim'] <= 0:
            raise ValueError(f"è¾“å…¥ç»´åº¦å¿…é¡» > 0ï¼Œå½“å‰: {config['input_dim']}")
        
        # éªŒè¯dropoutç‡
        if not 0 <= config['dropout'] <= 1:
            raise ValueError(f"dropoutç‡å¿…é¡»åœ¨[0,1]èŒƒå›´å†…ï¼Œå½“å‰: {config['dropout']}")
    
    def _process_input_data(self, input_data: Dict[str, torch.Tensor]) -> torch.Tensor:
        """
        å¤„ç†è¾“å…¥æ•°æ®ï¼Œå°†å¤šæ¨¡æ€æ•°æ®è½¬æ¢ä¸ºç»Ÿä¸€çš„å¼ é‡æ ¼å¼
        """
        aligned_features = {}
        for key in input_data:
            if key in self.channels_used_in_model and key in self.alignment_layers.modality_names:
                aligned_features[key] = input_data[key]
        aligned_features = self.alignment_layers.forward(aligned_features)
        svd_loss, svd_values = self._compute_rank1_loss_with_metrics(aligned_features)
        h = []
        keys = []
        for channel in self.channels_used_in_model:
            if channel not in aligned_features:
                keys.append(channel)
                h.append(input_data[channel])
            else:
                keys.append(channel+'_aligned')
                h.append(aligned_features[channel])
        h = torch.cat(h, dim=1).squeeze(0)
        return h, svd_loss, svd_values
        
    @staticmethod
    def create_positive_targets(length, device):
        return torch.full((length, ), 1, device=device).long()
    
    @staticmethod
    def create_negative_targets(length, device):
        return torch.full((length, ), 0, device=device).long()
    
    def inst_eval(self, A, h, classifier):
        """å®ä¾‹çº§è¯„ä¼°ï¼ˆç±»å†…æ³¨æ„åŠ›åˆ†æ”¯ï¼‰"""
        device = h.device
        if len(A.shape) == 1:
            A = A.view(1, -1)
        top_p_ids = torch.topk(A, self.inst_number)[1][-1]
        top_p = torch.index_select(h, dim=0, index=top_p_ids)
        top_n_ids = torch.topk(-A, self.inst_number, dim=1)[1][-1]
        top_n = torch.index_select(h, dim=0, index=top_n_ids)
        p_targets = self.create_positive_targets(self.inst_number, device)
        n_targets = self.create_negative_targets(self.inst_number, device)
        
        all_targets = torch.cat([p_targets, n_targets], dim=0)
        all_instances = torch.cat([top_p, top_n], dim=0)
        logits = classifier(all_instances)
        all_preds = torch.topk(logits, 1, dim=1)[1].squeeze(1)
        instance_loss = self.instance_loss_fn(logits, all_targets)
        return instance_loss, all_preds, all_targets
    
    def inst_eval_out(self, A, h, classifier):
        """å®ä¾‹çº§è¯„ä¼°ï¼ˆç±»å¤–æ³¨æ„åŠ›åˆ†æ”¯ï¼‰"""
        device = h.device
        if len(A.shape) == 1:
            A = A.view(1, -1)
        top_p_ids = torch.topk(A, self.inst_number)[1][-1]
        top_p = torch.index_select(h, dim=0, index=top_p_ids)
        p_targets = self.create_negative_targets(self.inst_number, device)
        logits = classifier(top_p)
        p_preds = torch.topk(logits, 1, dim=1)[1].squeeze(1)
        instance_loss = self.instance_loss_fn(logits, p_targets)
        return instance_loss, p_preds, p_targets
    
    def forward(self, input_data, label):
        """
        ç»Ÿä¸€çš„å‰å‘ä¼ æ’­æ¥å£
        
        Args:
            input_data: è¾“å…¥æ•°æ®ï¼Œå¯ä»¥æ˜¯ï¼š
                - torch.Tensor: å•æ¨¡æ€ç‰¹å¾ [N, D]
                - Dict[str, torch.Tensor]: å¤šæ¨¡æ€æ•°æ®å­—å…¸
            **kwargs: å…¶ä»–å‚æ•°ï¼Œæ”¯æŒï¼š
                - label: æ ‡ç­¾ï¼ˆç”¨äºå®ä¾‹è¯„ä¼°ï¼‰
                - instance_eval: æ˜¯å¦è¿›è¡Œå®ä¾‹è¯„ä¼°
                - return_features: æ˜¯å¦è¿”å›ç‰¹å¾
                - attention_only: æ˜¯å¦åªè¿”å›æ³¨æ„åŠ›æƒé‡
                
        Returns:
            Dict[str, Any]: ç»Ÿä¸€æ ¼å¼çš„ç»“æœå­—å…¸
        """
        # å¤„ç†è¾“å…¥æ•°æ®ï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰
        # align the features
        h, svd_loss, svd_values = self._process_input_data(input_data)
        
        A, h = self.attention_net(h.detach())  # A: [N, 1], h: [N, D]
        A = torch.transpose(A, 1, 0)  # A: [1, N]
        
        if self.attention_only:
            return {'attention_weights': A}
        
        A_raw = A
        A = F.softmax(A, dim=1)  # A: [1, N]
        
        # è®¡ç®—åŠ æƒç‰¹å¾
        M = torch.mm(A, h)  # [1, D]
        
        # åˆ†ç±»
        # [1, n_classes]
        logits = torch.empty(1, self.n_classes).float().to(M.device)
        if self.n_classes == 2:
            logits = self.classifiers(M)  # [1, 2]
        else:
            for c in range(self.n_classes):
                logits[0, c] = self.classifiers[c](M)  # [1, 1] independent linear layer for each class
        Y_hat = torch.topk(logits, 1, dim = 1)[1]
        Y_prob = F.softmax(logits, dim = 1)
        # æ„å»ºåŸºç¡€ç»“æœå­—å…¸
        result_kwargs = {
            'attention_weights': A_raw,
            'svd_loss': svd_loss,
            'svd_values': svd_values
        }
        # æ·»åŠ ç‰¹å¾
        if self.return_features:
            result_kwargs['features'] = M
        
        # è®¡ç®—å®ä¾‹æŸå¤±ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if self.base_weight < 1:
            total_inst_loss = 0.0
            all_preds = []
            all_targets = []
            # inst_labels: [N], like [1, 0] or [0, 0, 1]
            inst_labels = F.one_hot(label, num_classes=self.n_classes).squeeze()
            for i in range(len(self.instance_classifiers)):
                inst_label = inst_labels[i].item()
                classifier = self.instance_classifiers[i]
                if inst_label == 1:  # in the class
                    instance_loss, preds, targets = self.inst_eval(A, h, classifier)
                    all_preds.extend(preds.cpu().numpy())
                    all_targets.extend(targets.cpu().numpy())
                else:  # out of the class
                    if self.subtyping:
                        instance_loss, preds, targets = self.inst_eval_out(A, h, classifier)
                        all_preds.extend(preds.cpu().numpy())
                        all_targets.extend(targets.cpu().numpy())
                    else:
                        continue
                total_inst_loss += instance_loss
            
            if self.subtyping:
                total_inst_loss /= len(self.instance_classifiers)
            
            # add the additional loss
            result_kwargs['total_inst_loss'] = total_inst_loss
            result_kwargs['inst_labels'] = np.array(all_targets)
            result_kwargs['inst_preds'] = np.array(all_preds)
        
        # æ„å»ºç»Ÿä¸€çš„ç»“æœå­—å…¸
        return self._create_result_dict(
            logits=logits,
            probabilities=Y_prob,
            predictions=Y_hat,
            **result_kwargs
        )
        
    def _compute_rank1_loss_with_metrics(self, aligned_features: Dict[str, torch.Tensor], 
                                          aligned_negatives: Optional[Dict[str, torch.Tensor]] = None):
        """
        è®¡ç®— rank1 æŸå¤±å¹¶è¿”å› SVD ç‰¹å¾å€¼ï¼ˆå¸¦è¯¦ç»†æ—¶é—´åˆ†æï¼‰
        
        Returns:
            loss: æŸå¤±å€¼
            svd_values: SVD ç‰¹å¾å€¼ Tensor[num_modalities]
        """
        # 1. SVD è®¡ç®—å’Œ loss1
        sorted_keys = sorted(aligned_features.keys())
        feature_list = [aligned_features[mod] for mod in sorted_keys]
        features = torch.stack(feature_list, dim=-1).squeeze(0)  # [batch_size, feature_dim, num_modalities]
        
        # L2 å½’ä¸€åŒ–ï¼šx <- x / (||x||_2 + Îµ)
        eps = 1e-8
        l2_norm = torch.norm(features, p=2, dim=1, keepdim=True)  # [batch_size, 1, num_modalities]
        features = features / (l2_norm + eps)
        
        # U: [batch_size, feature_dim, num_modalities]
        # S(diag): [batch_size, num_modalities]
        # _: [batch_size, feature_dim, num_modalities]
        U, S, _ = torch.linalg.svd(features)
        
        # ğŸ“Š è®°å½• SVD ç‰¹å¾å€¼ï¼šå¯¹ batch ç»´åº¦æ±‚å¹³å‡ï¼ˆç”¨äºè®°å½•å•ä¸ª batch çš„ä»£è¡¨å€¼ï¼‰
        svd_values = S.mean(dim=0).detach()  # [num_modalities]
        
        loss1 = F.cross_entropy(S / self.tau1, torch.zeros(S.shape[0]).to(S.device).long())
        
        # 2. loss2 è®¡ç®—
        U1 = U[:, :, 0] # dominate projection [batch_size, feature_dim]
        # ç»„å†…çŸ©é˜µè®¡ç®—ï¼šæŒ‰ loss2_chunk_size å°† batch åˆ†ç»„ï¼Œä»…ç»„å†…åš softmax/CE
        batch_count = U1.shape[0]
        if self.loss2_chunk_size is None or self.loss2_chunk_size >= batch_count:
            loss2 = F.cross_entropy((U1 @ U1.T) / self.tau2, torch.arange(batch_count, device=U1.device).long())
        else:
            c = max(1, int(self.loss2_chunk_size))
            full = (batch_count // c) * c
            loss2_sum = U1.new_tensor(0.0)
            if full > 0:
                groups = U1[:full].view(-1, c, U1.shape[1])  # [G, c, D]
                logits_gc = torch.einsum('gxd,gyd->gxy', groups, groups) / self.tau2  # [G, c, c]
                targets_gc = torch.arange(c, device=U1.device).expand(logits_gc.shape[0], c) # [G, c]
                loss2_sum = loss2_sum + F.cross_entropy(
                    logits_gc.reshape(-1, c), targets_gc.reshape(-1), reduction='sum'
                )
            if full < batch_count:
                tail = U1[full:]
                c_tail = tail.shape[0]
                logits_tail = (tail @ tail.T) / self.tau2
                targets_tail = torch.arange(c_tail, device=U1.device)
                loss2_sum = loss2_sum + F.cross_entropy(logits_tail, targets_tail, reduction='sum')
            loss2 = loss2_sum / batch_count

        if self.lambda2 == 0:
            return loss1 + self.lambda1 * loss2, svd_values

        # 3. loss3 (loss_IM) è®¡ç®—
        batch_size = feature_list[0].shape[0]
        positive_labels = torch.ones(batch_size, device=features.device)
        
        def fuse(feat_dict: Dict[str, torch.Tensor]) -> torch.Tensor:
            # å°†å¤šæ¨¡æ€ç‰¹å¾æ‹¼æ¥ä¸ºå•å‘é‡ [N, d*K]
            sorted_keys = sorted(feat_dict.keys())
            return torch.cat([feat_dict[mod] for mod in sorted_keys], dim=1)

        if aligned_negatives is None:
            raise RuntimeError("Negative features not provided by dataset. Ensure DataLoader yields 'features_neg' per batch.")
        neg_fused = fuse(aligned_negatives)

        pos_fused = fuse(aligned_features)
        all_features = torch.cat([pos_fused, neg_fused], dim=0)
        negative_labels = torch.zeros(neg_fused.shape[0], device=features.device)
        all_labels = torch.cat([positive_labels, negative_labels], dim=0)

        pred_M = self.alignment_layers.mlp_predictor(all_features)
        loss_IM = F.binary_cross_entropy(pred_M.squeeze(), all_labels)
        
        total_loss = loss1 + self.lambda1 * loss2 + self.lambda2 * loss_IM
        return total_loss, svd_values
    def loss_fn(self, logits: torch.Tensor, labels: torch.Tensor, result: Dict[str, torch.Tensor]) -> torch.Tensor:
        """
        è®¡ç®—æŸå¤±
        
        Args:
            logits: æ¨¡å‹è¾“å‡ºçš„logits
            labels: çœŸå®æ ‡ç­¾
            result: åŒ…å«é¢å¤–æŸå¤±çš„ç»“æœå­—å…¸
            
        Returns:
            æ€»æŸå¤±å€¼
        """
        if self.base_weight < 1:
            return (self.base_loss_fn(logits, labels) * self.base_weight + 
                   result['total_inst_loss'] * (1 - self.base_weight) + 
                   result['svd_loss'])
        else:
            return self.base_loss_fn(logits, labels)

